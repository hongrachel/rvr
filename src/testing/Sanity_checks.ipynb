{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.load('/Users/Frances/Documents/seas-fellowship/rvr/data/runp1_2/run_p1_2.npz')\n",
    "#data = np.load('/Users/Frances/Documents/seas-fellowship/rvr/data/runp1_2/run_p1_2_042219.npz')\n",
    "#data = np.load('/Users/Frances/Documents/seas-fellowship/rvr/data/runagree/run_agree_p1_2_042019.npz')\n",
    "#data = np.load('/Users/Frances/Documents/seas-fellowship/rvr/data/runagree/run_agree_interact_042919_prod_thresh.npz')\n",
    "\n",
    "data = np.load('/Users/Frances/Documents/seas-fellowship/rvr/data/runagree/run_agree_interact_050919_prod.npz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data['x_train'][data['train_inds']]\n",
    "y_train = data['y_train'][data['train_inds']]\n",
    "\n",
    "x_valid = data['x_train'][data['valid_inds']]\n",
    "y_valid = data['y_train'][data['valid_inds']]\n",
    "\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "yidx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelall = LogisticRegression()\n",
    "modelall.fit(x_train, y_train[:, yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10368750000000004\n",
      "0.11224999999999996\n",
      "0.20040000000000002\n"
     ]
    }
   ],
   "source": [
    "print(1 - modelall.score(x_train, y_train[:,yidx]))\n",
    "print(1 - modelall.score(x_valid, y_valid[:,yidx]))\n",
    "print(1 - modelall.score(x_test, y_test[:,yidx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27172979, -0.12886561, -0.15707084, -0.33562672,  0.05434694,\n",
       "        -0.11473164, -0.0934289 ,  0.01935156, -0.06823329, -0.02876349,\n",
       "        -0.33786971, -0.04331712, -0.0040002 ,  0.2134664 , -0.20045496,\n",
       "        -0.02272399,  0.41574095,  0.29293718, -0.32968168, -0.2296814 ,\n",
       "        -0.27669161,  0.23483602,  0.19862118, -0.17022299, -0.31908518,\n",
       "         0.22066462, -0.51181929, -0.01417286,  0.03113997, -0.31580949]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelall.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = LogisticRegression()\n",
    "model1 = LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.fit(x_train[:n, :], y_train[:n, yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.91628498, -1.42506881,  1.56488135,  2.98891865,  1.71552265,\n",
       "         1.74695572, -2.16221389,  0.98306163, -1.2708093 ,  2.02369533,\n",
       "         2.19710523, -2.07709028, -0.68861884,  0.90355319, -0.65265203,\n",
       "        -0.59577515,  1.98183885,  1.30805942,  2.15380522, -0.56604378,\n",
       "        -1.59911531, -2.42837439,  2.38934623, -0.39033674,  1.0966025 ,\n",
       "        -2.60248476,  0.48132315, -2.45358317,  1.03129185, -1.64417306]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train[n:2*n, :], y_train[n:2*n, yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.90205686, -2.11447326,  1.18435923,  2.38442298,  0.20505874,\n",
       "         1.85896637, -2.05388745,  0.86693443, -0.16057707,  1.79444242,\n",
       "         1.98731217, -1.94583352, -0.80810388,  1.3910351 , -0.71486058,\n",
       "        -0.94698966,  1.90083443,  1.54730408,  1.77946153, -0.67011745,\n",
       "        -2.65849144, -2.30079529,  2.40014367, -0.67432477,  0.0581066 ,\n",
       "        -1.86042119,  0.59453224, -2.29017489,  1.21538008, -1.56699043]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=LogisticRegression()\n",
    "model2.fit(x_train[2*n:3*n, :], y_train[2*n:3*n, yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=LogisticRegression()\n",
    "model3.fit(x_train[3*n:4*n, :], y_train[3*n:4*n, yidx])\n",
    "\n",
    "model4=LogisticRegression()\n",
    "model4.fit(x_train[4*n:5*n, :], y_train[4*n:5*n, yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8942"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model0.score(x_train[2*n:3*n, :], y_train[2*n:3*n, yidx]))\n",
    "model0.score(x_test, y_test[:,yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(x_test, y_test[:,yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'model0': model0.coef_[0], 'model1' : model1.coef_[0], 'model2': model2.coef_[0], 'model3': model3.coef_[0], 'model4': model4.coef_[0], 'modelall' : modelall.coef_[0]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model0</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>modelall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.157256</td>\n",
       "      <td>-1.265471</td>\n",
       "      <td>-2.986540</td>\n",
       "      <td>-1.033625</td>\n",
       "      <td>-1.413202</td>\n",
       "      <td>-0.517717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.049493</td>\n",
       "      <td>1.186508</td>\n",
       "      <td>1.494112</td>\n",
       "      <td>1.184767</td>\n",
       "      <td>1.391719</td>\n",
       "      <td>0.443307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.913955</td>\n",
       "      <td>-0.976421</td>\n",
       "      <td>-1.112448</td>\n",
       "      <td>-0.751973</td>\n",
       "      <td>-0.947623</td>\n",
       "      <td>-0.289375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.446023</td>\n",
       "      <td>2.056281</td>\n",
       "      <td>2.609376</td>\n",
       "      <td>2.015693</td>\n",
       "      <td>1.661778</td>\n",
       "      <td>0.802831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.922294</td>\n",
       "      <td>-2.343310</td>\n",
       "      <td>-1.646182</td>\n",
       "      <td>-2.160539</td>\n",
       "      <td>-1.417754</td>\n",
       "      <td>-0.357486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.877193</td>\n",
       "      <td>-1.985509</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>-2.676001</td>\n",
       "      <td>-1.370392</td>\n",
       "      <td>-0.660644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.016347</td>\n",
       "      <td>1.050752</td>\n",
       "      <td>0.877578</td>\n",
       "      <td>1.059801</td>\n",
       "      <td>0.881783</td>\n",
       "      <td>0.315481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.207220</td>\n",
       "      <td>0.599636</td>\n",
       "      <td>1.523612</td>\n",
       "      <td>1.026808</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.412457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.243076</td>\n",
       "      <td>-1.635569</td>\n",
       "      <td>-1.098240</td>\n",
       "      <td>-1.924484</td>\n",
       "      <td>-1.894604</td>\n",
       "      <td>-0.732040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.824103</td>\n",
       "      <td>-1.940112</td>\n",
       "      <td>-2.107938</td>\n",
       "      <td>-1.907415</td>\n",
       "      <td>-1.940553</td>\n",
       "      <td>-0.699948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.383822</td>\n",
       "      <td>-2.208405</td>\n",
       "      <td>-1.167493</td>\n",
       "      <td>-0.419752</td>\n",
       "      <td>-1.710749</td>\n",
       "      <td>-0.570504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.682932</td>\n",
       "      <td>-0.679177</td>\n",
       "      <td>-0.603008</td>\n",
       "      <td>-1.665721</td>\n",
       "      <td>-0.572460</td>\n",
       "      <td>-0.312818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.473534</td>\n",
       "      <td>-0.680636</td>\n",
       "      <td>-0.654010</td>\n",
       "      <td>-0.442560</td>\n",
       "      <td>-0.766281</td>\n",
       "      <td>-0.292533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.408405</td>\n",
       "      <td>3.212180</td>\n",
       "      <td>1.752316</td>\n",
       "      <td>1.904514</td>\n",
       "      <td>2.252874</td>\n",
       "      <td>0.744066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.954324</td>\n",
       "      <td>1.990873</td>\n",
       "      <td>2.389426</td>\n",
       "      <td>2.087300</td>\n",
       "      <td>2.186550</td>\n",
       "      <td>0.796212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.281840</td>\n",
       "      <td>-1.508549</td>\n",
       "      <td>-1.783722</td>\n",
       "      <td>-1.627115</td>\n",
       "      <td>-1.671246</td>\n",
       "      <td>-0.678837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.934185</td>\n",
       "      <td>2.288038</td>\n",
       "      <td>2.381226</td>\n",
       "      <td>2.256141</td>\n",
       "      <td>2.227727</td>\n",
       "      <td>0.869155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.417949</td>\n",
       "      <td>-0.259701</td>\n",
       "      <td>-0.829576</td>\n",
       "      <td>-0.511170</td>\n",
       "      <td>-0.823007</td>\n",
       "      <td>-0.495091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.237144</td>\n",
       "      <td>-1.351448</td>\n",
       "      <td>-1.393663</td>\n",
       "      <td>-1.200295</td>\n",
       "      <td>-1.244513</td>\n",
       "      <td>-0.288082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.105719</td>\n",
       "      <td>-1.169465</td>\n",
       "      <td>-1.646444</td>\n",
       "      <td>-1.398063</td>\n",
       "      <td>-1.410626</td>\n",
       "      <td>-0.568085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.155392</td>\n",
       "      <td>1.615917</td>\n",
       "      <td>1.352153</td>\n",
       "      <td>1.537629</td>\n",
       "      <td>1.137328</td>\n",
       "      <td>0.354503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.710973</td>\n",
       "      <td>1.608494</td>\n",
       "      <td>1.735613</td>\n",
       "      <td>1.412366</td>\n",
       "      <td>1.639462</td>\n",
       "      <td>0.427040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.037873</td>\n",
       "      <td>0.258398</td>\n",
       "      <td>0.115593</td>\n",
       "      <td>0.197402</td>\n",
       "      <td>0.099541</td>\n",
       "      <td>0.059584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.352728</td>\n",
       "      <td>0.094512</td>\n",
       "      <td>0.571540</td>\n",
       "      <td>0.074167</td>\n",
       "      <td>0.494420</td>\n",
       "      <td>0.202440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.513807</td>\n",
       "      <td>-0.513069</td>\n",
       "      <td>-1.137620</td>\n",
       "      <td>0.046312</td>\n",
       "      <td>-1.036968</td>\n",
       "      <td>-0.358975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.783294</td>\n",
       "      <td>2.595278</td>\n",
       "      <td>1.919843</td>\n",
       "      <td>2.280223</td>\n",
       "      <td>1.911105</td>\n",
       "      <td>0.674463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.475942</td>\n",
       "      <td>2.878759</td>\n",
       "      <td>2.538366</td>\n",
       "      <td>2.712320</td>\n",
       "      <td>2.301237</td>\n",
       "      <td>0.760306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.703904</td>\n",
       "      <td>-2.288160</td>\n",
       "      <td>-1.986771</td>\n",
       "      <td>-2.621254</td>\n",
       "      <td>-1.842226</td>\n",
       "      <td>-0.800346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.266376</td>\n",
       "      <td>-0.325488</td>\n",
       "      <td>0.875276</td>\n",
       "      <td>1.601524</td>\n",
       "      <td>0.022912</td>\n",
       "      <td>0.456415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.334030</td>\n",
       "      <td>0.784628</td>\n",
       "      <td>0.548734</td>\n",
       "      <td>0.341139</td>\n",
       "      <td>0.413898</td>\n",
       "      <td>0.067418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model0    model1    model2    model3    model4  modelall\n",
       "0  -2.157256 -1.265471 -2.986540 -1.033625 -1.413202 -0.517717\n",
       "1   1.049493  1.186508  1.494112  1.184767  1.391719  0.443307\n",
       "2  -0.913955 -0.976421 -1.112448 -0.751973 -0.947623 -0.289375\n",
       "3   2.446023  2.056281  2.609376  2.015693  1.661778  0.802831\n",
       "4  -1.922294 -2.343310 -1.646182 -2.160539 -1.417754 -0.357486\n",
       "5  -1.877193 -1.985509 -1.540184 -2.676001 -1.370392 -0.660644\n",
       "6   1.016347  1.050752  0.877578  1.059801  0.881783  0.315481\n",
       "7   2.207220  0.599636  1.523612  1.026808  0.864944  0.412457\n",
       "8  -0.243076 -1.635569 -1.098240 -1.924484 -1.894604 -0.732040\n",
       "9  -1.824103 -1.940112 -2.107938 -1.907415 -1.940553 -0.699948\n",
       "10 -2.383822 -2.208405 -1.167493 -0.419752 -1.710749 -0.570504\n",
       "11 -1.682932 -0.679177 -0.603008 -1.665721 -0.572460 -0.312818\n",
       "12 -0.473534 -0.680636 -0.654010 -0.442560 -0.766281 -0.292533\n",
       "13  3.408405  3.212180  1.752316  1.904514  2.252874  0.744066\n",
       "14  1.954324  1.990873  2.389426  2.087300  2.186550  0.796212\n",
       "15 -1.281840 -1.508549 -1.783722 -1.627115 -1.671246 -0.678837\n",
       "16  1.934185  2.288038  2.381226  2.256141  2.227727  0.869155\n",
       "17 -0.417949 -0.259701 -0.829576 -0.511170 -0.823007 -0.495091\n",
       "18 -1.237144 -1.351448 -1.393663 -1.200295 -1.244513 -0.288082\n",
       "19 -1.105719 -1.169465 -1.646444 -1.398063 -1.410626 -0.568085\n",
       "20  1.155392  1.615917  1.352153  1.537629  1.137328  0.354503\n",
       "21  1.710973  1.608494  1.735613  1.412366  1.639462  0.427040\n",
       "22  0.037873  0.258398  0.115593  0.197402  0.099541  0.059584\n",
       "23  0.352728  0.094512  0.571540  0.074167  0.494420  0.202440\n",
       "24  0.513807 -0.513069 -1.137620  0.046312 -1.036968 -0.358975\n",
       "25  1.783294  2.595278  1.919843  2.280223  1.911105  0.674463\n",
       "26  2.475942  2.878759  2.538366  2.712320  2.301237  0.760306\n",
       "27 -1.703904 -2.288160 -1.986771 -2.621254 -1.842226 -0.800346\n",
       "28  1.266376 -0.325488  0.875276  1.601524  0.022912  0.456415\n",
       "29  0.334030  0.784628  0.548734  0.341139  0.413898  0.067418"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0\n",
    "3?\n",
    "4\n",
    "5?\n",
    "7\n",
    "8\n",
    "10\n",
    "11\n",
    "13\n",
    "17?\n",
    "23?\n",
    "24\n",
    "25?\n",
    "28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#newx = x_train[:, [1,2,6,9,12,14,15,16,18,19,20,21,22,26,27,29] ] #  [1,2,3, 5, 6,9,12,14,15,16,17, 18,19,20,21,22,23, 25, 26,27,29]\n",
    "\n",
    "commons_in_r = [1,3,6,7,8,11,12,13,15,16,17,18,19,22,23,24,26,28,29,30]\n",
    "commons = [x - 1 for x in commons_in_r]\n",
    "\n",
    "newx = x_train[:, commons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Frances/anaconda3/envs/rvr-env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testm = LogisticRegression()\n",
    "testm.fit(newx, y_train[:,yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#newtestx = x_test[:, [1,2,6,9,12,14,15,16,18,19,20,21,22,26,27,29]]\n",
    "newtestx = x_test[:, commons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testm.score(newtestx, y_test[:, yidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1283603466930456"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model0.coef_[0, [1,2,6,9,12,14,15,16,18,19,20,21,22,26,27,29] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.293329694872702"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(model0.coef_[0, [0, 3 ,4,5,7,8,10,11,13,17,23,24,25,28] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6279396831206886\n",
      "2 0.5254375154620301\n",
      "3 -0.42717525120720645\n",
      "4 -0.7810646533477356\n",
      "5 -0.17737257779438756\n",
      "6 -0.9567401650638161\n",
      "7 0.8339878789359058\n",
      "8 -0.324242032112478\n",
      "9 0.20804226721294808\n",
      "10 -0.8067515705468277\n",
      "11 -0.5358812373482886\n",
      "12 0.5033566472796729\n",
      "13 0.45295785307660785\n",
      "14 -0.19867034171365408\n",
      "15 0.2633784060918376\n",
      "16 0.4733869391639459\n",
      "17 -0.5773601593710653\n",
      "18 -0.6780124417691262\n",
      "19 -0.7806454857223932\n",
      "20 0.47369716813376184\n",
      "21 0.6036914651443545\n",
      "22 0.7246702398252867\n",
      "23 -0.6437538450378665\n",
      "24 0.2625302279575319\n",
      "25 -0.2435986607435295\n",
      "26 0.5371255625242419\n",
      "27 -0.3243844104376237\n",
      "28 0.7777298664477355\n",
      "29 -0.5365463661966251\n",
      "30 0.46764856756716033\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(i+1, modelall.coef_[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
