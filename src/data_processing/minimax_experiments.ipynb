{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# infile = \"run_agree_interact_common_20_061619_prod_2_4.npz\"\n",
    "# het_infile = \"run_agree_interact_common_20_061619_prod_2_10.npz\"\n",
    "or_infile = \"run_orfunc_common_20_061420_9_same_1_diff.npz\"\n",
    "het_infile = \"run_agree_interact_common_20_061420_prod_1_9_same_1_diff_5_test.npz\"\n",
    "#outfile = \"../../data/balanced_adult_matched_pairs/balanced_adult_matched_pairs.npz\"\n",
    "\n",
    "random.seed(0)\n",
    "data = np.load(het_infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_1 = data[\"x_train\"][:5000]\n",
    "# study_2 = data[\"x_train\"][45000:]\n",
    "\n",
    "# dup = np.tile(study_2, (9,1))\n",
    "# data_x_train = np.concatenate((dup, study_1), axis=0)\n",
    "# data_x_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_1 = data[\"y_train\"][:5000]\n",
    "# study_2 = data[\"y_train\"][45000:]\n",
    "# dup = np.tile(study_2, (9, 1))\n",
    "# data_y_train = np.concatenate((dup, study_1), axis=0)\n",
    "# data_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data['x_train'][data['train_inds']]\n",
    "y_train = data['y_train'][data['train_inds']][:,1]\n",
    "attr_train = data['attr_train'][data['train_inds']]\n",
    "\n",
    "x_valid = data['x_train'][data['valid_inds']]\n",
    "y_valid = data['y_train'][data['valid_inds']][:,1]\n",
    "attr_valid = data['attr_train'][data['valid_inds']]\n",
    "\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test'][:,1]\n",
    "attr_test = data['attr_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nk = np.ones(15)*5000\n",
    "# ind = np.repeat(0, nk[0])\n",
    "# for i in range(1, 5):\n",
    "#     ind = np.concatenate((ind, np.repeat(i, nk[i])), axis=0)\n",
    "# attr_test = np.zeros((ind.size, 10))\n",
    "# attr_test[np.arange(ind.size), ind] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_test[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 30)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_valid = y_valid.reshape(y_valid.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planning\n",
    "# want to train a classifier f which minimizes loss of max over domain i of avg [L(f_i(x), y) for all x in domain i]\n",
    "# f is regular feed-forward MLP with 2 hidden layers, input dim 30, output dim 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first 3 PCA dimensions of the sampled data\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(x_train)\n",
    "ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y_train.ravel(),\n",
    "           cmap=plt.cm.Set1, edgecolor='k', s=40)\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the TF neural net\n",
    "# some hyperparams\n",
    "training_epochs = 50\n",
    "\n",
    "# n_neurons_in_h1 = 2\n",
    "# n_neurons_in_h2 = 2\n",
    "# learning_rate = 0.001\n",
    "\n",
    "n_features = len(x_train[0])\n",
    "labels_dim = 1\n",
    "attr_dim = attr_train.shape[1]\n",
    "attr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_loss(labels, logits):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_loss_plus_var(labels, logits, coeff=1.0):\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "    avg_loss = tf.reduce_mean(cross_entropy)\n",
    "    var = tf.math.reduce_std(cross_entropy)\n",
    "    return avg_loss + 1.0*var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_loss_plus_domain_var(labels, logits, coeff=0.1, study_ids=None):\n",
    "    avg_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits))\n",
    "    \n",
    "    avg_losses = []\n",
    "    for i in range(10):\n",
    "        study_mask = study_ids[:,i]\n",
    "        study_labels = tf.boolean_mask(labels, study_mask)\n",
    "        study_logits = tf.boolean_mask(logits, study_mask)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits)\n",
    "        avg_losses.append(tf.reduce_mean(loss))\n",
    "    domain_var = tf.math.reduce_std(avg_losses)\n",
    "    return tf.math.add(avg_loss, tf.math.multiply(tf.cast(coeff, dtype='float32'), tf.cast(domain_var, dtype='float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_10(labels, logits, study_ids):\n",
    "    # labels = truth, logits = f(x)\n",
    "    study_mask = study_ids[:,0]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss0 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,1]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "    \n",
    "    study_mask = study_ids[:,2]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,3]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss3 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,4]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss4 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,5]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss5 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,6]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss6 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,7]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss7 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,8]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss8 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "    study_mask = study_ids[:,9]\n",
    "    study_labels = tf.boolean_mask(labels, study_mask)\n",
    "    study_logits = tf.boolean_mask(logits, study_mask)\n",
    "    loss9 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "\n",
    "#     avg_losses = tf.stack([loss0, loss8, loss9])\n",
    "    avg_losses = tf.stack([loss0, loss1, loss2, loss3, loss4, loss5, loss6, loss7, loss8, loss9])\n",
    "    return tf.reduce_max(avg_losses)\n",
    "\n",
    "#     avg_losses = []\n",
    "#     for i in range(10):\n",
    "#         study_mask = study_ids[:,i]\n",
    "#         study_labels = tf.boolean_mask(labels, study_mask)\n",
    "#         study_logits = tf.boolean_mask(logits, study_mask)\n",
    "#         loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits)\n",
    "#         avg_losses.append(tf.reduce_mean(loss))\n",
    "#     return tf.reduce_max(avg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y = tf.constant(y_train[:50])\n",
    "sample_logits = tf.constant(np.random.random(50).reshape((50, 1)))\n",
    "sample_a = tf.constant(attr_train[:50])\n",
    "# print(sample_y.eval(session=tf.Session()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Add' Op has type float32 that does not match type float64 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-45afae0a5c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(compute_loss_10(sample_y, sample_logits, sample_a, False).eval(session=tf.Session()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_avg_loss_plus_domain_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoeff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-119-5002a746c6ef>\u001b[0m in \u001b[0;36mcompute_avg_loss_plus_domain_var\u001b[0;34m(labels, logits, coeff, study_ids)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mavg_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdomain_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 365\u001b[0;31m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m    366\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    545\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 547\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Add' Op has type float32 that does not match type float64 of argument 'x'."
     ]
    }
   ],
   "source": [
    "# print(compute_loss_10(sample_y, sample_logits, sample_a, False).eval(session=tf.Session()))\n",
    "print(compute_avg_loss_plus_domain_var(sample_y, sample_logits, coeff=0.1, study_ids=sample_a).eval(session=tf.Session()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_y.shape[0].value\n",
    "print(sample_a[0])\n",
    "a = tf.constant([[0., 1.],[0., 1.]])\n",
    "b = tf.constant([0., 1.])\n",
    "a_1 = a[:,1]\n",
    "filter_1 = tf.boolean_mask(sample_y[:2], 1.-a_1)\n",
    "print(filter_1.eval(session=tf.Session()))\n",
    "# tf.reduce_all(tf.math.equal(a, b)).eval(session=tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = sample_y, logits = sample_logits))\n",
    "print(mean.eval(session=tf.Session()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_domain(data, study_ids, domain): # domain between 0 and attr_dim-1\n",
    "    study_mask = study_ids[:, domain] == 1.\n",
    "    return data[study_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch_from_each_domain(batch_num, batch_size=5): # domain between 0 and attr_dim-1\n",
    "    start = batch_num*batch_size\n",
    "    end = min(len(x_train), (batch_num+1)*batch_size)\n",
    "    num_studies = attr_train.shape[1]\n",
    "    x_batch = None\n",
    "    y_batch = None\n",
    "    z_batch = None\n",
    "\n",
    "    for domain in range(num_studies):\n",
    "        study_mask = attr_train[:, domain] == 1.\n",
    "        x_study_batch = x_train[study_mask][start:end]\n",
    "        y_study_batch = y_train[study_mask][start:end]\n",
    "        attr_study_batch = attr_train[study_mask][start:end]\n",
    "        if domain == 0:\n",
    "            x_batch = x_study_batch\n",
    "            y_batch = y_study_batch\n",
    "            attr_batch = attr_study_batch\n",
    "        else:\n",
    "            x_batch = np.concatenate((x_batch, x_study_batch), axis=0)\n",
    "            y_batch = np.concatenate((y_batch, y_study_batch), axis=0)\n",
    "            attr_batch = np.concatenate((attr_batch, attr_study_batch), axis=0)\n",
    "    arr = np.arange(x_batch.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    np.take(x_batch,arr,axis=0,out=x_batch)\n",
    "    np.take(y_batch,arr,axis=0,out=y_batch)\n",
    "    np.take(attr_batch,arr,axis=0,out=attr_batch)\n",
    "    return x_batch, y_batch, attr_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_train_batch_from_each_domain(1)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21758162, -5.54948001,  3.95802967,  0.72904227, -3.2322578 ,\n",
       "        4.61219557, -0.71614761,  5.14493289,  1.33197976,  2.40294122,\n",
       "        3.94172396,  6.14069198, -6.55134302, -1.76202628, -2.50917197,\n",
       "       -3.63252995, -0.52091884, -0.69812576, -0.35137775,  6.06676912,\n",
       "        6.43400078,  0.50817979,  2.72505169, -1.19167835, -4.06174485,\n",
       "       -1.06524935, -3.21238991,  0.58080082, -3.96871179,  6.40948181])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21758162, -5.54948001,  3.95802967, ...,  0.58080082,\n",
       "        -3.96871179,  6.40948181],\n",
       "       [-3.69318584,  0.21332461,  5.17443867, ...,  4.00251485,\n",
       "         2.5173006 ,  0.44652525],\n",
       "       [-4.92168566, -3.08192211,  1.27627984, ...,  4.9615979 ,\n",
       "         1.53912614, -2.0835957 ],\n",
       "       ...,\n",
       "       [-8.15920622,  0.03244008, -0.73468327, ..., -1.85817595,\n",
       "         4.44559342, -2.92166208],\n",
       "       [ 1.78072944,  0.41237135,  3.45647094, ...,  1.1125281 ,\n",
       "         3.21177752, -0.64800583],\n",
       "       [ 2.65114675, -6.84370513,  1.65081029, ...,  2.67229731,\n",
       "        -2.50776515,  1.05288845]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_from_domain(x_test, attr_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = []\n",
    "# for index in range(attr_dim):\n",
    "#     study_labels = []\n",
    "#     study_logits = []\n",
    "#     study = np.zeros(attr_dim)\n",
    "#     study[index] = 1.0\n",
    "#     study = tf.constant(study)\n",
    "    \n",
    "#     for i in range(sample_a.shape[0].value):\n",
    "#         if tf.reduce_all(tf.math.equal(sample_a[i], study)).eval(session=tf.Session()):\n",
    "#             study_labels.append(sample_y[i])\n",
    "#             study_logits.append(sample_logits[i])\n",
    "#     study_labels = np.asarray(study_labels)\n",
    "#     study_logits = np.asarray(study_logits)\n",
    "#     study_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = study_labels, logits = study_logits))\n",
    "#     losses.append(study_loss)\n",
    "# max_loss = tf.reduce_max(losses)\n",
    "# print(max_loss.eval(session=tf.Session()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 30)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_neurons_in_h1, n_neurons_in_h2, avg_loss=True):\n",
    "    # basic 2 layer dense net (MLP) example adapted from\n",
    "    # https://becominghuman.ai/creating-your-own-neural-network-using-tensorflow-fa8ca7cc4d0e\n",
    "\n",
    "    # these placeholders serve as our input tensors\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name='input')\n",
    "    y = tf.placeholder(tf.float32, [None, labels_dim], name='labels')\n",
    "    a = tf.placeholder(tf.float32, [None, attr_dim], name='study_id')\n",
    "\n",
    "    # TF Variables are our neural net parameter tensors, we initialize them to random (gaussian) values in\n",
    "    # Layer1. Variables are allowed to be persistent across training epochs and updatable bt TF operations\n",
    "    W1 = tf.Variable(tf.truncated_normal([n_features, n_neurons_in_h1], mean=0, stddev=1 / np.sqrt(n_features)),\n",
    "                     name='weights1')\n",
    "    b1 = tf.Variable(tf.truncated_normal([n_neurons_in_h1], mean=0, stddev=1 / np.sqrt(n_features)), name='biases1')\n",
    "\n",
    "    # note the output tensor of the 1st layer is the activation applied to a\n",
    "    # linear transform of the layer 1 parameter tensors\n",
    "    # the matmul operation calculates the dot product between the tensors\n",
    "    y1 = tf.sigmoid((tf.matmul(x, W1) + b1), name='activationLayer1')\n",
    "\n",
    "    # network parameters(weights and biases) are set and initialized (Layer2)\n",
    "    W2 = tf.Variable(tf.random_normal([n_neurons_in_h1, n_neurons_in_h2], mean=0, stddev=1),\n",
    "                     name='weights2')\n",
    "    b2 = tf.Variable(tf.random_normal([n_neurons_in_h2], mean=0, stddev=1), name='biases2')\n",
    "    # activation function(sigmoid)\n",
    "    y2 = tf.sigmoid((tf.matmul(y1, W2) + b2), name='activationLayer2')\n",
    "\n",
    "    # output layer weights and biases\n",
    "    Wo = tf.Variable(tf.random_normal([n_neurons_in_h2, labels_dim], mean=0, stddev=1 ),\n",
    "                     name='weightsOut')\n",
    "    bo = tf.Variable(tf.random_normal([labels_dim], mean=0, stddev=1), name='biasesOut')\n",
    "\n",
    "    # the sigmoid (binary softmax) activation is absorbed into TF's sigmoid_cross_entropy_with_logits loss\n",
    "    logits = (tf.matmul(y2, Wo) + bo)\n",
    "    loss = compute_avg_loss_plus_var(labels = y, logits = logits, study_ids = a, avg=avg_loss)\n",
    "\n",
    "    # tap a separate output that applies softmax activation to the output layer\n",
    "    # for training accuracy readout\n",
    "    act = tf.nn.sigmoid(logits, name='activationOutputLayer')\n",
    "\n",
    "    # optimizer used to compute gradient of loss and apply the parameter updates.\n",
    "    # the train_step object returned is ran by a TF Session to train the net\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # prediction accuracy\n",
    "    # compare predicted value from network with the expected value/target\n",
    "\n",
    "    correct_prediction = tf.equal(tf.round(act), y)\n",
    "    # accuracy determination\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"Accuracy\")\n",
    "    \n",
    "    return train_step, accuracy, loss, act, x, y, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n_neurons_in_h1, n_neurons_in_h2, avg_loss=True, training_epochs=50, learning_rate = 0.1, b=5):\n",
    "    # basic 2 layer dense net (MLP) example adapted from\n",
    "    # https://becominghuman.ai/creating-your-own-neural-network-using-tensorflow-fa8ca7cc4d0e\n",
    "\n",
    "    # these placeholders serve as our input tensors\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name='input')\n",
    "    y = tf.placeholder(tf.float32, [None, labels_dim], name='labels')\n",
    "    a = tf.placeholder(tf.float32, [None, attr_dim], name='study_id')\n",
    "\n",
    "    # TF Variables are our neural net parameter tensors, we initialize them to random (gaussian) values in\n",
    "    # Layer1. Variables are allowed to be persistent across training epochs and updatable bt TF operations\n",
    "    W1 = tf.Variable(tf.truncated_normal([n_features, n_neurons_in_h1], mean=0, stddev=1 / np.sqrt(n_features)),\n",
    "                     name='weights1')\n",
    "    b1 = tf.Variable(tf.truncated_normal([n_neurons_in_h1], mean=0, stddev=1 / np.sqrt(n_features)), name='biases1')\n",
    "\n",
    "    # note the output tensor of the 1st layer is the activation applied to a\n",
    "    # linear transform of the layer 1 parameter tensors\n",
    "    # the matmul operation calculates the dot product between the tensors\n",
    "    y1 = tf.sigmoid((tf.matmul(x, W1) + b1), name='activationLayer1')\n",
    "\n",
    "    # network parameters(weights and biases) are set and initialized (Layer2)\n",
    "#     W2 = tf.Variable(tf.random_normal([n_neurons_in_h1, n_neurons_in_h2], mean=0, stddev=1),\n",
    "#                      name='weights2')\n",
    "#     b2 = tf.Variable(tf.random_normal([n_neurons_in_h2], mean=0, stddev=1), name='biases2')\n",
    "#     # activation function(sigmoid)\n",
    "#     y2 = tf.sigmoid((tf.matmul(y1, W2) + b2), name='activationLayer2')\n",
    "\n",
    "    # output layer weights and biases\n",
    "    Wo = tf.Variable(tf.random_normal([n_neurons_in_h1, labels_dim], mean=0, stddev=1 ),\n",
    "                     name='weightsOut')\n",
    "    bo = tf.Variable(tf.random_normal([labels_dim], mean=0, stddev=1), name='biasesOut')\n",
    "\n",
    "    # the sigmoid (binary softmax) activation is absorbed into TF's sigmoid_cross_entropy_with_logits loss\n",
    "    logits = (tf.matmul(y1, Wo) + bo)\n",
    "    if avg_loss:\n",
    "        loss = compute_avg_loss(labels = y, logits = logits)\n",
    "    else:\n",
    "        loss = compute_avg_loss_plus_domain_var(labels = y, logits = logits, coeff=0.0, study_ids = a)\n",
    "\n",
    "    # tap a separate output that applies softmax activation to the output layer\n",
    "    # for training accuracy readout\n",
    "    act = tf.nn.sigmoid(logits, name='activationOutputLayer')\n",
    "\n",
    "    # optimizer used to compute gradient of loss and apply the parameter updates.\n",
    "    # the train_step object returned is ran by a TF Session to train the net\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # prediction accuracy\n",
    "    # compare predicted value from network with the expected value/target\n",
    "\n",
    "    correct_prediction = tf.equal(tf.round(act), y)\n",
    "    # accuracy determination\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"Accuracy\")\n",
    "\n",
    "    # ***NOTE global_variables_initializer() must be called before creating a tf.Session()!***\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # create a session for training and feedforward (prediction). Sessions are TF's way to run\n",
    "    # feed data to placeholders and variables, obtain outputs and update neural net parameters\n",
    "    with tf.Session() as sess:\n",
    "        # ***initialization of all variables... NOTE this must be done before running any further sessions!***\n",
    "        sess.run(init_op)\n",
    "\n",
    "        # training loop over the number of epochs\n",
    "        batch_size = b*attr_dim\n",
    "        batches = int(len(x_train) / batch_size)\n",
    "\n",
    "        for epoch in range(1, training_epochs+1):\n",
    "            losses = 0\n",
    "            accs = 0\n",
    "            for j in range(batches-1, -1, -1):\n",
    "#             for j in range(1):\n",
    "                X_b, Y_b, A_b = get_train_batch_from_each_domain(j, batch_size=b)\n",
    "\n",
    "                # train the network, note the dictionary of inputs and labels\n",
    "                sess.run(train_step, feed_dict={x: X_b, y: Y_b, a: A_b})\n",
    "                # feedforwad the same data and labels, but grab the accuracy and loss as outputs\n",
    "                acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: X_b, y: Y_b, a: A_b})\n",
    "\n",
    "                losses = losses + np.sum(l)\n",
    "                accs = accs + np.sum(acc)\n",
    "\n",
    "                if epoch % 50 == 0:\n",
    "                    max_loss = -1.\n",
    "                    worst_accuracy = 0.\n",
    "                    worst_domain = -1\n",
    "                    for i in range(attr_dim-1, -1, -1):\n",
    "                        x_b_i = get_data_from_domain(X_b, A_b, i)\n",
    "                        y_b_i = get_data_from_domain(Y_b, A_b, i)\n",
    "                        attr_b_i = get_data_from_domain(A_b, A_b, i)\n",
    "                        acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_b_i, y: y_b_i, a: attr_b_i})\n",
    "                        if np.sum(l) > max_loss:\n",
    "                            max_loss = np.sum(l)\n",
    "                            worst_accuracy = acc\n",
    "                            worst_domain = i\n",
    "                    print(\"======WORST TRAINING DOMAIN %.8d \" % worst_domain, \"MAX training loss %.4f\" % (max_loss),\n",
    "                          \"WORST training acc %.4f\" % worst_accuracy)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Epoch %.8d \" % epoch, \"avg train loss over\", batches, \" batches \", \"%.4f\" % (losses/batches),\n",
    "                      \"avg train acc \", \"%.4f\" % (accs/batches))\n",
    "\n",
    "            # evaluate on the validation sets\n",
    "            acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_valid, y: y_valid, a: attr_valid})\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Epoch %.8d \" % epoch, \"valid loss %.4f\" % np.sum(l),\n",
    "                      \"valid acc %.4f\" % acc)\n",
    "\n",
    "                # evaluate for each domain on validation set and get worst domain\n",
    "                max_loss = -1.\n",
    "                worst_accuracy = 0.\n",
    "                worst_domain = -1\n",
    "                \n",
    "                worst_acc_loss = -1.\n",
    "                min_accuracy = 1.\n",
    "                worst_acc_domain = -1\n",
    "                for i in range(attr_dim-1, -1, -1):\n",
    "                    x_valid_i = get_data_from_domain(x_valid, attr_valid, i)\n",
    "                    y_valid_i = get_data_from_domain(y_valid, attr_valid, i)\n",
    "                    attr_valid_i = get_data_from_domain(attr_valid, attr_valid, i)\n",
    "                    acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_valid_i, y: y_valid_i, a: attr_valid_i})\n",
    "                    if np.sum(l) > max_loss:\n",
    "                        max_loss = np.sum(l)\n",
    "                        worst_accuracy = acc\n",
    "                        worst_domain = i\n",
    "                    if acc < min_accuracy:\n",
    "                        worst_acc_loss = np.sum(l)\n",
    "                        min_accuracy = acc\n",
    "                        worst_acc_domain = i\n",
    "                print(\"WORST DOMAIN %.8d \" % worst_domain, \"MAX valid loss %.4f\" % (max_loss),\n",
    "                      \"WORST valid acc %.4f\" % worst_accuracy)\n",
    "                print(\"WORST ACC DOMAIN %.8d \" % worst_acc_domain, \"WORST ACC valid loss %.4f\" % (worst_acc_loss),\n",
    "                      \"MIN valid acc %.4f\" % min_accuracy)\n",
    "                \n",
    "            # evaluate on the test set\n",
    "            acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_test, y: y_test, a: attr_test})\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Epoch %.8d \" % epoch, \"test loss %.4f\" % np.sum(l),\n",
    "                      \"test acc %.4f\" % acc)\n",
    "                # evaluate for each domain on test set and get worst domain\n",
    "                max_loss = -1.\n",
    "                worst_accuracy = 0.\n",
    "                worst_domain = -1\n",
    "                \n",
    "                worst_acc_loss = -1.\n",
    "                min_accuracy = 1.\n",
    "                worst_acc_domain = -1\n",
    "                for i in range(4, -1, -1):\n",
    "                    x_test_i = get_data_from_domain(x_test, attr_test, i)\n",
    "                    y_test_i = get_data_from_domain(y_test, attr_test, i)\n",
    "                    attr_test_i = get_data_from_domain(attr_test, attr_test, i)\n",
    "                    acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_test_i, y: y_test_i, a: attr_test_i})\n",
    "                    if np.sum(l) > max_loss:\n",
    "                        max_loss = np.sum(l)\n",
    "                        worst_accuracy = acc\n",
    "                        worst_domain = i\n",
    "                    if acc < min_accuracy:\n",
    "                        worst_acc_loss = np.sum(l)\n",
    "                        min_accuracy = acc\n",
    "                        worst_acc_domain = i\n",
    "                print(\"WORST DOMAIN %.8d \" % worst_domain, \"MAX test loss %.4f\" % (max_loss),\n",
    "                      \"WORST test acc %.4f\" % worst_accuracy)\n",
    "                print(\"WORST ACC DOMAIN %.8d \" % worst_acc_domain, \"WORST ACC test loss %.4f\" % (worst_acc_loss),\n",
    "                      \"MIN test acc %.4f\" % min_accuracy)\n",
    "\n",
    "        v_acc, v_l, v_soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_valid, y: y_valid, a: attr_valid})\n",
    "        t_acc, t_l, t_soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_test, y: y_test, a: attr_test})\n",
    "        # evaluate for each domain on validation set and get worst domain\n",
    "        max_v_loss = -1.\n",
    "        worst_v_accuracy = 0.\n",
    "        worst_v_domain = -1\n",
    "        \n",
    "        worst_v_acc_loss = -1.\n",
    "        min_v_accuracy = 1.\n",
    "        worst_v_acc_domain = -1\n",
    "        for i in range(attr_dim-1, -1, -1):\n",
    "            x_valid_i = get_data_from_domain(x_valid, attr_valid, i)\n",
    "            y_valid_i = get_data_from_domain(y_valid, attr_valid, i)\n",
    "            attr_valid_i = get_data_from_domain(attr_valid, attr_valid, i)\n",
    "            acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_valid_i, y: y_valid_i, a: attr_valid_i})\n",
    "            if np.sum(l) > max_v_loss:\n",
    "                max_v_loss = np.sum(l)\n",
    "                worst_v_accuracy = acc\n",
    "                worst_v_domain = i\n",
    "            if acc < min_v_accuracy:\n",
    "                worst_v_acc_loss = np.sum(l)\n",
    "                min_v_accuracy = acc\n",
    "                worst_v_acc_domain = i\n",
    "        # evaluate for each domain on test set and get worst domain\n",
    "        max_t_loss = -1.\n",
    "        worst_t_accuracy = 0.\n",
    "        worst_t_domain = -1\n",
    "        \n",
    "        worst_t_acc_loss = -1.\n",
    "        min_t_accuracy = 1.\n",
    "        worst_t_acc_domain = -1\n",
    "        for i in range(4, -1, -1):\n",
    "            x_test_i = get_data_from_domain(x_test, attr_test, i)\n",
    "            y_test_i = get_data_from_domain(y_test, attr_test, i)\n",
    "            attr_test_i = get_data_from_domain(attr_test, attr_test, i)\n",
    "            acc, l, soft_max_a = sess.run([accuracy, loss, act], feed_dict={x: x_test_i, y: y_test_i, a: attr_test_i})\n",
    "            if np.sum(l) > max_t_loss:\n",
    "                max_t_loss = np.sum(l)\n",
    "                worst_t_accuracy = acc\n",
    "                worst_t_domain = i\n",
    "            if acc < min_t_accuracy:\n",
    "                worst_t_acc_loss = np.sum(l)\n",
    "                min_t_accuracy = acc\n",
    "                worst_t_acc_domain = i\n",
    "        \n",
    "        return (\n",
    "            v_acc, np.sum(v_l),\n",
    "            t_acc, np.sum(t_l),\n",
    "            worst_v_accuracy, max_v_loss, worst_v_domain,\n",
    "            worst_t_accuracy, max_t_loss, worst_t_domain,\n",
    "            min_v_accuracy, worst_v_acc_loss, worst_v_acc_domain,\n",
    "            min_t_accuracy, worst_t_acc_loss, worst_t_acc_domain,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_step, accuracy, loss, act, x, y, a = initialize_network(1, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, nan, 0.0, nan, 0.0, -1.0, -1, 0.0, -1.0, -1, 0.0, nan, 9, 0.0, nan, 4)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiment(1, 1, avg_loss=False, training_epochs=5, learning_rate=0.001, b=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-011f4da57887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-133-88b49f99d091>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(n_neurons_in_h1, n_neurons_in_h2, avg_loss, training_epochs, learning_rate, b)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#             for j in range(1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_batch_from_each_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;31m# train the network, note the dictionary of inputs and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-98c87b70e346>\u001b[0m in \u001b[0;36mget_train_batch_from_each_domain\u001b[0;34m(batch_num, batch_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdomain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_studies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstudy_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx_study_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0my_study_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mattr_study_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_experiment(1, 1, avg_loss=True, training_epochs=50, learning_rate=0.1, b=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===AVERAGE LOSS FUNCTION===\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2400', 'avg train acc ', '0.9333')\n",
      "('Epoch 00000010 ', 'valid loss 0.2532', 'valid acc 0.9296')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5344', 'WORST valid acc 0.8195')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5344', 'MIN valid acc 0.8195')\n",
      "('Epoch 00000010 ', 'test loss 0.6970', 'test acc 0.7719')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7554', 'WORST test acc 0.7422')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7554', 'MIN test acc 0.7422')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2387', 'avg train acc ', '0.9331')\n",
      "('Epoch 00000020 ', 'valid loss 0.2554', 'valid acc 0.9309')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5078', 'WORST valid acc 0.8455')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5078', 'MIN valid acc 0.8455')\n",
      "('Epoch 00000020 ', 'test loss 0.7478', 'test acc 0.7640')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8213', 'WORST test acc 0.7496')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7889', 'MIN test acc 0.7446')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2346', 'avg train acc ', '0.9365')\n",
      "('Epoch 00000030 ', 'valid loss 0.2478', 'valid acc 0.9326')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5064', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5064', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000030 ', 'test loss 0.7110', 'test acc 0.7745')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7720', 'WORST test acc 0.7610')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7483', 'MIN test acc 0.7586')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2333', 'avg train acc ', '0.9357')\n",
      "('Epoch 00000040 ', 'valid loss 0.2408', 'valid acc 0.9324')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4604', 'WORST valid acc 0.8506')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4604', 'MIN valid acc 0.8506')\n",
      "('Epoch 00000040 ', 'test loss 0.7690', 'test acc 0.7579')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8822', 'WORST test acc 0.7388')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8822', 'MIN test acc 0.7388')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5457', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5510', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6901', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.0872', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6972', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5560', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7105', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7090', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1892', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.0570', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5396', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7184', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6965', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6918', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5505', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0407', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6952', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7126', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7044', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.3364', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7049', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1863', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7004', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0753', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0183', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.3905', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3492', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1926', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.0392', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6888', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6917', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.0481', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2895', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6672', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6537', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6350', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1763', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6102', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6054', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5949', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1316', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1951', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6349', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6484', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5720', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1959', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5791', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1442', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6057', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1546', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6399', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6491', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6698', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6848', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2097', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7281', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.0127', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7124', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.3821', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7044', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5273', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7167', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1723', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1748', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5483', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6531', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1582', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6400', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0673', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6254', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6225', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6169', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1383', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6135', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.0675', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.6694', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6127', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1120', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5792', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5704', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5727', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6806', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1810', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7029', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5554', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7142', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7214', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.2296', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1725', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9983', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7559', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9536', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.1029', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9554', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7638', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8436', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5215', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7853', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8207', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7849', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7993', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.9408', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5338', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8042', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9272', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4783', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5118', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5100', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5072', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4831', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7952', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4770', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8966', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4911', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1915', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4293', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4518', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8578', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7990', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8261', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8213', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1877', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4518', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5532', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4119', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7921', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1569', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8895', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4666', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4899', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7331', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7166', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7087', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5119', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1155', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6572', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6385', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1781', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6155', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6163', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.0999', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1001', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6058', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6122', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5606', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5459', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6472', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6516', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1472', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6945', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.0913', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9377', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1733', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7192', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7238', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.0959', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7291', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7571', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7586', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.9776', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7178', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5431', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1445', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6667', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5473', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.0198', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0743', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6596', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5357', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.2508', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6643', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6460', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6505', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5437', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6532', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1339', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6444', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1332', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6542', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5551', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6628', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6707', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6785', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6624', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6684', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.0363', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.0794', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2473', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6449', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6402', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5633', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6286', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6286', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1746', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6177', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5822', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6232', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.0749', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5644', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5463', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6684', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7112', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1643', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1679', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9706', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.3367', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1829', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1648', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4739', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8167', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4417', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8750', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5459', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8011', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1999', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8726', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7722', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1637', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1308', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1405', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1124', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5047', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4854', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.0985', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4647', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5018', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7126', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.3260', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0287', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4580', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3528', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.0674', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6669', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4677', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.2747', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4821', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7192', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7238', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7232', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7015', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6906', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6840', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6917', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6571', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5080', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5403', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6805', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1033', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6756', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5129', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6765', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0851', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6818', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5337', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5358', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1029', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1152', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6564', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6638', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1085', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6535', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5493', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.2343', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6499', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1099', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6620', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6462', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9956', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6503', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6541', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6643', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1263', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.9708', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6522', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1276', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6464', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6397', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6298', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6214', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5418', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6204', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5562', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1619', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.0131', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6210', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6552', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5247', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6699', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.0849', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2999', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1166', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5086', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5188', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4812', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7184', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1489', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4315', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4795', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7628', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7698', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7736', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4932', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1770', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8366', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8375', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8124', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8632', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.1198', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8284', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7739', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7658', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4215', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4844', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1389', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3927', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6996', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2934', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.6062', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6450', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6442', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5627', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.0649', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6299', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1746', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6150', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6102', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1340', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5950', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1039', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5847', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5914', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5916', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5910', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5939', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5983', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6064', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6172', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1688', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6321', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.0560', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.0425', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6963', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1691', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.9818', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.3954', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5097', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9378', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7760', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5100', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7695', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8058', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4908', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4913', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7806', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5111', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7815', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8891', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1837', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.0532', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4330', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8091', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4713', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4680', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4410', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8066', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4674', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.5579', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7976', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8113', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.2068', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7971', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7532', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7470', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9244', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3037', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5208', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5117', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.9535', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.2690', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.9844', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9696', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1214', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6800', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.2412', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6450', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8217', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.9755', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9724', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0798', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6405', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5218', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5379', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6597', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6681', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1004', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0993', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5120', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4872', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6737', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6918', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6597', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7042', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4987', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4967', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7166', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5119', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6909', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7117', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9091', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3416', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1251', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4867', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5033', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0941', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8629', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4369', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5196', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4519', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1662', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7478', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4957', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1541', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8032', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2089', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4983', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5940', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7701', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8876', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4644', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7672', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7850', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1628', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.3076', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7557', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7705', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9120', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4517', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7442', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7734', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7312', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7397', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7471', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.9403', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4963', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5267', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7306', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.6022', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7318', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5146', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5150', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4852', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.0916', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7613', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7366', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.9676', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5192', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5130', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7555', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5147', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4173', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5352', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7657', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7353', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.0735', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 2.0988', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7136', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1764', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7300', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.6317', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5289', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1360', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1377', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6711', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5294', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6768', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5152', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6934', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5216', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4928', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7025', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7178', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7293', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6841', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6805', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7130', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6934', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1500', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.2656', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5481', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1284', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6351', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5607', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5708', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.0120', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5504', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6501', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0110', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6604', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6854', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6726', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6896', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9919', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5362', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5055', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7440', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7366', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.0781', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1949', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5129', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1960', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7590', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.3883', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 2.4536', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6953', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6839', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5548', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7025', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.0319', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5475', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6245', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5475', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1856', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5459', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6362', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6482', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6436', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5205', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.2449', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5151', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6626', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.9577', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3932', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.3050', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0705', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5043', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7197', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5146', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.9206', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8994', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4911', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5064', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7485', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4787', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5193', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8637', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8433', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8368', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8352', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4202', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.2173', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.2190', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.4794', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8556', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8797', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.6015', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4792', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1544', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1997', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8036', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.8454', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7125', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4763', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7560', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4718', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2595', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5169', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6486', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6549', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6392', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1991', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5185', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6234', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.0865', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.0894', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6578', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5118', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6606', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1024', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4920', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.9027', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7107', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4983', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7148', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4911', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7384', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7684', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8741', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4793', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8170', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8024', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4490', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7683', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7954', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7819', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1961', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8086', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5001', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4583', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8527', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7902', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1626', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5172', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7308', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.4065', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1447', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9443', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1576', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.7532', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6599', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6491', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5381', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2020', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6390', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5466', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6453', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9792', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5294', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6419', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7853', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6480', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6411', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9362', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6682', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4900', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5016', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6901', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6905', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.2509', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5239', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0984', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9406', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9485', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4969', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6735', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6675', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6710', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6923', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.3115', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9049', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4877', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1198', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0834', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7430', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1261', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1253', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.1214', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4753', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8721', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7293', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4983', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4783', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8322', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0913', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4755', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1279', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1171', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.3813', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1091', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7477', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7000', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7130', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.0893', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6914', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6649', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6572', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6513', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0556', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5045', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6611', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6625', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6726', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6774', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.2027', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1747', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9701', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6006', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5378', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6057', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6083', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6012', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6024', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6125', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0672', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6110', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1302', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5959', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5964', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6051', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1078', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5845', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.0838', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5813', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.0831', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0844', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5823', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.0790', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0876', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5782', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1044', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5941', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.0938', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0925', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6088', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5500', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6191', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5534', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6340', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0257', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1048', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6365', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6376', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1845', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5433', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5542', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6407', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6314', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5472', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1061', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1969', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5428', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0076', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0919', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6483', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2235', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0874', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6549', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0992', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6770', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9157', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6774', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.7002', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6921', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6723', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8924', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0686', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6695', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6752', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6767', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5132', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6772', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6893', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.9098', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5027', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0648', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.2486', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.1048', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5092', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5085', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5082', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6606', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.0885', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1081', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9161', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9070', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5394', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7515', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8967', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7514', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1555', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4807', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4988', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7410', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6933', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7091', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.3179', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7027', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6998', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 2.2981', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.2068', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.0796', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5667', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.0623', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5718', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6229', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5531', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5453', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1411', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2716', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5495', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6724', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1587', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.0111', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7025', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5548', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7123', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6924', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7050', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7182', 'WORST training acc 0.8000')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2341', 'avg train acc ', '0.9348')\n",
      "('Epoch 00000050 ', 'valid loss 0.2434', 'valid acc 0.9323')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4347', 'WORST valid acc 0.8586')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4347', 'MIN valid acc 0.8586')\n",
      "('Epoch 00000050 ', 'test loss 0.7394', 'test acc 0.7586')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8512', 'WORST test acc 0.7400')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8512', 'MIN test acc 0.7400')\n",
      "('Epoch 00000060 ', 'avg train loss over', 800, ' batches ', '0.2398', 'avg train acc ', '0.9326')\n",
      "('Epoch 00000060 ', 'valid loss 0.2491', 'valid acc 0.9284')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4651', 'WORST valid acc 0.8546')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4651', 'MIN valid acc 0.8546')\n",
      "('Epoch 00000060 ', 'test loss 0.7093', 'test acc 0.7690')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8487', 'WORST test acc 0.7426')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8487', 'MIN test acc 0.7426')\n",
      "('Epoch 00000070 ', 'avg train loss over', 800, ' batches ', '0.2369', 'avg train acc ', '0.9353')\n",
      "('Epoch 00000070 ', 'valid loss 0.2389', 'valid acc 0.9350')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4757', 'WORST valid acc 0.8536')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4757', 'MIN valid acc 0.8536')\n",
      "('Epoch 00000070 ', 'test loss 0.7846', 'test acc 0.7492')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8527', 'WORST test acc 0.7350')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.8379', 'MIN test acc 0.7212')\n",
      "('Epoch 00000080 ', 'avg train loss over', 800, ' batches ', '0.2306', 'avg train acc ', '0.9370')\n",
      "('Epoch 00000080 ', 'valid loss 0.2380', 'valid acc 0.9347')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4809', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4809', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000080 ', 'test loss 0.7431', 'test acc 0.7633')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8489', 'WORST test acc 0.7488')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7426', 'MIN test acc 0.7448')\n",
      "('Epoch 00000090 ', 'avg train loss over', 800, ' batches ', '0.2342', 'avg train acc ', '0.9353')\n",
      "('Epoch 00000090 ', 'valid loss 0.2370', 'valid acc 0.9352')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5034', 'WORST valid acc 0.8395')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5034', 'MIN valid acc 0.8395')\n",
      "('Epoch 00000090 ', 'test loss 0.7301', 'test acc 0.7610')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8058', 'WORST test acc 0.7448')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8058', 'MIN test acc 0.7448')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5402', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7224', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7225', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.0839', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7179', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5647', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.2163', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7166', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2122', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.0535', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5504', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7210', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5532', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7012', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5551', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.2215', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7053', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7239', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7134', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5590', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.2035', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7110', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7320', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.2124', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7237', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7111', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.2068', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.0416', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7036', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7089', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.0436', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3287', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6893', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1805', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.2616', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2474', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6492', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6313', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6254', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1575', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1640', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6217', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5876', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6297', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1825', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5898', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1483', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6095', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6134', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6212', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6289', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6331', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5883', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1862', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6665', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6668', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6557', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.2538', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6533', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6452', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.2097', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1561', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1505', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6102', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5951', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1325', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6314', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.0800', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.0737', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5712', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.6864', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.0884', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5848', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1684', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5960', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6047', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5929', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1002', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5768', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6995', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1886', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7129', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7451', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7204', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6850', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7486', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1953', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7148', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7234', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9776', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1841', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7148', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3342', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7032', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5494', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0007', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7142', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7015', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6860', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.7799', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5338', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.2807', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0316', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2466', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5582', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6474', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5393', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0657', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.0840', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5243', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1386', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1407', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1564', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9278', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5057', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9195', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7205', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.3159', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7469', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1709', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4883', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.8735', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7719', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.1281', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7677', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7424', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9209', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4779', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7469', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1542', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.3321', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7000', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.0874', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1145', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6326', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6125', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6028', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5949', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5939', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0802', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1011', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5687', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1665', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5537', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5341', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6682', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6747', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1642', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7335', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4827', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8828', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1961', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8127', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7368', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.1046', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7691', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7794', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7780', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.9564', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7358', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5088', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1516', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6863', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5378', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.0019', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5282', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6779', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9962', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6911', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1383', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6666', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0759', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5242', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.0862', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1415', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0758', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1464', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6827', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5404', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6903', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7012', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7103', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6873', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6942', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6988', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.0815', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2746', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5547', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6513', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6441', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6436', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6377', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1877', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6198', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5930', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1446', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5894', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6240', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6364', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.2342', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5685', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1521', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1605', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.1682', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.4960', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1697', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6947', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5169', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7443', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5047', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4988', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4636', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.4715', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3253', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7652', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7607', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7539', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1479', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7296', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.3711', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5188', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5054', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7137', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4960', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5242', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6748', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.9389', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0859', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4944', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2914', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1011', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9133', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4784', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1061', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4980', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4751', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7279', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7348', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7384', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7397', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7195', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7168', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1435', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1418', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5121', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5896', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7010', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6956', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5464', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5210', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6878', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0784', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7001', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6767', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5383', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1423', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1549', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6903', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.0746', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1472', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7014', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5427', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0010', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7051', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5166', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7285', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7168', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4273', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7055', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5105', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7302', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9721', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6423', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7274', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1950', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.3715', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7162', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4926', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4946', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.3317', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5360', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.9823', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9782', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5074', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7148', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1390', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7077', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6823', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3387', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1350', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5187', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5296', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7044', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7059', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5280', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3506', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6601', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5234', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7298', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7142', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5212', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.1555', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9225', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7592', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4622', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7517', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9197', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7611', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.1226', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7944', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7360', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3716', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7153', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6738', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9802', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6730', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.7271', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.6133', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6316', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6477', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6209', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5639', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0493', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6308', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6276', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6161', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6256', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6232', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6140', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6119', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.0801', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6134', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5659', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6321', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6373', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6442', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.2447', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.2405', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6564', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6547', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.0406', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6481', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6748', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1497', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5383', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9761', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5253', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9716', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7157', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5401', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7088', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7367', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5087', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5079', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7245', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5225', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7641', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9205', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7236', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8796', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0881', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4766', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4806', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4764', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8054', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8543', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4724', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.5387', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7924', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7901', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.2124', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7932', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7714', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7683', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4876', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3402', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5144', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5044', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.9432', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.3036', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6736', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9648', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6839', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6933', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6800', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.9578', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6708', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.9752', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5271', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1145', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6713', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5224', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5418', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5114', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.3198', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1325', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1293', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5559', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5025', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6723', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6828', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1002', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6858', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5181', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5158', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.0609', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6748', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6923', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5080', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1274', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9274', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7465', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7554', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.0893', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8866', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4288', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8620', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4649', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1693', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7361', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4655', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4858', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7825', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.9000', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8730', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.6246', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7833', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1909', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7565', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5135', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8750', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1470', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.7191', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4629', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.4564', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8830', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4291', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7635', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8054', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1598', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1330', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7848', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8658', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8634', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4999', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7570', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1256', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7522', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4813', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4823', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8499', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.1133', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5023', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4594', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8877', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4802', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4791', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7959', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4768', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4878', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5005', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4567', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0911', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4796', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2839', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7801', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1945', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4609', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.6115', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4842', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7745', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7895', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7611', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4956', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7496', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5188', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7630', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1683', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4801', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5137', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7529', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7391', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6902', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6809', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7047', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6904', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1708', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.2780', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5574', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1527', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6560', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5626', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.0293', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.0204', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9770', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7027', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7276', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.5977', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5038', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7309', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7601', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1580', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4999', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4494', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8269', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8105', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.1002', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7936', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7949', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.2074', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4355', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.2057', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4636', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.5123', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.8799', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7718', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7699', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5106', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.3257', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.9512', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4887', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4880', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9282', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.3325', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5009', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6885', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7122', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6895', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5117', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.3350', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4753', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7021', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8914', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3038', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8833', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4855', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7587', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7437', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8818', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8798', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8568', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4758', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4961', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8697', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4691', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4177', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8503', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4352', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8203', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8413', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4305', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3839', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1999', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5854', 'WORST training acc 0.4000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.3070', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8198', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.5450', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5934', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.1747', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7775', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8814', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1735', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7643', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1482', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7495', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7155', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.3168', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4832', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6543', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5328', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6391', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6482', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5008', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.2014', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5123', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6305', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.0892', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4881', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7052', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4842', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6730', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1008', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7303', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8876', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4799', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4780', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9096', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4880', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7374', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5003', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8554', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4696', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4902', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8306', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.1275', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8202', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8219', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8187', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8349', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8240', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7917', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8025', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8764', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7723', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1630', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5320', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7021', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.3398', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1415', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6752', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.7338', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.7111', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6296', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5514', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5615', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1549', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6113', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6076', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6000', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6103', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5619', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 1.1047', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6188', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6331', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6504', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6600', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5167', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6925', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6868', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6889', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.7344', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5355', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1391', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9600', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9613', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6775', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7153', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7085', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1376', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7337', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.3893', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.3145', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4861', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1503', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8795', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7765', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.1492', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7125', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7822', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4636', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8388', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7383', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4838', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4575', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7723', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.4593', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4519', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7618', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4767', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8312', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1356', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7958', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7855', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8077', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0934', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4906', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7186', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7111', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0843', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4823', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5026', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4841', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7365', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9002', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 1.3357', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.3108', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6796', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5225', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5113', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6670', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6741', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6574', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6534', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6598', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5480', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6404', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.0814', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0732', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.0846', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5963', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1123', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.0821', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5914', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5898', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5802', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 1.1133', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6135', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6187', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6350', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5719', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2243', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6469', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1541', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5725', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6550', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5560', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6580', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5648', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6681', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1656', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.6589', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6614', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6595', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.8129', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5631', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6479', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1444', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6312', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5734', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1349', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1919', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5713', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6356', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1253', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 1.1303', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.2456', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6489', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6640', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6821', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6910', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9388', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7003', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3387', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7175', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4793', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8963', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1060', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4701', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7135', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5036', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4629', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7478', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7672', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7632', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4827', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1104', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.3905', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.1091', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.0894', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9078', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5007', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5014', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.0853', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5018', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5005', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.9122', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.5833', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7766', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9142', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7615', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1962', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5016', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4859', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.1664', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.1100', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7450', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7383', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7456', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7472', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 2.4479', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.3015', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.0764', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5627', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 1.0571', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5710', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6583', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5516', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5607', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 1.1774', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.3276', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.0680', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6919', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.1893', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 1.0266', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7233', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7394', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7315', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7115', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7440', 'WORST training acc 0.8000')\n",
      "('Epoch 00000100 ', 'avg train loss over', 800, ' batches ', '0.2301', 'avg train acc ', '0.9363')\n",
      "('Epoch 00000100 ', 'valid loss 0.2367', 'valid acc 0.9342')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4774', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4774', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000100 ', 'test loss 0.7574', 'test acc 0.7586')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8724', 'WORST test acc 0.7398')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7647', 'MIN test acc 0.7394')\n",
      "===FINAL RESULTS WITH BATCH SIZE 5===\n",
      "('VALID: acc 0.9342', 'accs sd 0.0000', 'loss 0.2367', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7586', 'accs sd 0.0000', 'loss 0.7574', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8435', 'accs sd 0.0000', 'loss 0.4774', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7398', 'accs sd 0.0000', 'loss 0.8724', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8435', 'accs sd 0.0000', 'loss 0.4774', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7394', 'accs sd 0.0000', 'loss 0.7647', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [0]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 125, ' batches ', '0.2255', 'avg train acc ', '0.9355')\n",
      "('Epoch 00000010 ', 'valid loss 0.2348', 'valid acc 0.9300')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4723', 'WORST valid acc 0.8315')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4723', 'MIN valid acc 0.8315')\n",
      "('Epoch 00000010 ', 'test loss 0.7353', 'test acc 0.7528')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8088', 'WORST test acc 0.7422')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7350', 'MIN test acc 0.7338')\n",
      "('Epoch 00000020 ', 'avg train loss over', 125, ' batches ', '0.2198', 'avg train acc ', '0.9392')\n",
      "('Epoch 00000020 ', 'valid loss 0.2308', 'valid acc 0.9358')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5162', 'WORST valid acc 0.8315')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5162', 'MIN valid acc 0.8315')\n",
      "('Epoch 00000020 ', 'test loss 0.7659', 'test acc 0.7444')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8305', 'WORST test acc 0.7270')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8305', 'MIN test acc 0.7270')\n",
      "('Epoch 00000030 ', 'avg train loss over', 125, ' batches ', '0.2237', 'avg train acc ', '0.9380')\n",
      "('Epoch 00000030 ', 'valid loss 0.2350', 'valid acc 0.9333')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4954', 'WORST valid acc 0.8335')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4954', 'MIN valid acc 0.8335')\n",
      "('Epoch 00000030 ', 'test loss 0.7315', 'test acc 0.7550')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8145', 'WORST test acc 0.7366')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8145', 'MIN test acc 0.7366')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 125, ' batches ', '0.2230', 'avg train acc ', '0.9386')\n",
      "('Epoch 00000040 ', 'valid loss 0.2281', 'valid acc 0.9365')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5136', 'WORST valid acc 0.8295')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5136', 'MIN valid acc 0.8295')\n",
      "('Epoch 00000040 ', 'test loss 0.7593', 'test acc 0.7448')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8174', 'WORST test acc 0.7302')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8174', 'MIN test acc 0.7302')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3263', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5004', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3923', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4679', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4096', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7296', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4257', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5935', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4110', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7012', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4116', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4896', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3254', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4189', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5145', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4078', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4169', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3620', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7617', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4778', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5334', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.2924', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4093', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5569', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4325', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4699', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3740', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3334', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4375', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5314', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4250', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4079', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7198', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6533', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6596', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3763', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6482', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2522', 'WORST training acc 0.9375')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5245', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3751', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3461', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5357', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5403', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4317', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4436', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6783', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5962', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4643', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3507', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9378', 'WORST training acc 0.6875')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5649', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5345', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4135', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4306', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4705', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5081', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4753', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4353', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8013', 'WORST training acc 0.7188')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5728', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4320', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4299', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4310', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6419', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4099', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6836', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5006', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7240', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6930', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4616', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3393', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5222', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4290', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4362', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4162', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4283', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3028', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7617', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6001', 'WORST training acc 0.7812')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4035', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4081', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5358', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3421', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3755', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4470', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3820', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4463', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4308', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4898', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5717', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4424', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.2950', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4190', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3560', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3949', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4189', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6151', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4040', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4170', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3700', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6013', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5721', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3838', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6369', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4799', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4789', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4058', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4151', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4739', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3758', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4438', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4477', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6725', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5898', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4349', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4585', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7556', 'WORST training acc 0.7188')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3866', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6514', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3607', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5477', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4266', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.2904', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7491', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3203', 'WORST training acc 0.9062')\n",
      "('Epoch 00000050 ', 'avg train loss over', 125, ' batches ', '0.2217', 'avg train acc ', '0.9385')\n",
      "('Epoch 00000050 ', 'valid loss 0.2389', 'valid acc 0.9331')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5250', 'WORST valid acc 0.8215')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5250', 'MIN valid acc 0.8215')\n",
      "('Epoch 00000050 ', 'test loss 0.7490', 'test acc 0.7498')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7944', 'WORST test acc 0.7274')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7944', 'MIN test acc 0.7274')\n",
      "('Epoch 00000060 ', 'avg train loss over', 125, ' batches ', '0.2232', 'avg train acc ', '0.9392')\n",
      "('Epoch 00000060 ', 'valid loss 0.2340', 'valid acc 0.9351')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4812', 'WORST valid acc 0.8365')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4812', 'MIN valid acc 0.8365')\n",
      "('Epoch 00000060 ', 'test loss 0.7428', 'test acc 0.7504')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8300', 'WORST test acc 0.7308')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8300', 'MIN test acc 0.7308')\n",
      "('Epoch 00000070 ', 'avg train loss over', 125, ' batches ', '0.2213', 'avg train acc ', '0.9394')\n",
      "('Epoch 00000070 ', 'valid loss 0.2444', 'valid acc 0.9328')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5536', 'WORST valid acc 0.8175')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5536', 'MIN valid acc 0.8175')\n",
      "('Epoch 00000070 ', 'test loss 0.7639', 'test acc 0.7460')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8115', 'WORST test acc 0.7262')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.8115', 'MIN test acc 0.7262')\n",
      "('Epoch 00000080 ', 'avg train loss over', 125, ' batches ', '0.2191', 'avg train acc ', '0.9410')\n",
      "('Epoch 00000080 ', 'valid loss 0.2244', 'valid acc 0.9389')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4927', 'WORST valid acc 0.8395')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4927', 'MIN valid acc 0.8395')\n",
      "('Epoch 00000080 ', 'test loss 0.7304', 'test acc 0.7549')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7823', 'WORST test acc 0.7438')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7717', 'MIN test acc 0.7330')\n",
      "('Epoch 00000090 ', 'avg train loss over', 125, ' batches ', '0.2190', 'avg train acc ', '0.9407')\n",
      "('Epoch 00000090 ', 'valid loss 0.2248', 'valid acc 0.9386')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5038', 'WORST valid acc 0.8355')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5038', 'MIN valid acc 0.8355')\n",
      "('Epoch 00000090 ', 'test loss 0.7610', 'test acc 0.7483')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8235', 'WORST test acc 0.7330')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.8050', 'MIN test acc 0.7256')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3198', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5719', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4304', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4677', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4929', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7903', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3311', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4611', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4104', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6980', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4280', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4534', 'WORST training acc 0.8438')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3160', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3978', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5835', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4088', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4161', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3256', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6493', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4991', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4695', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3104', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4550', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5556', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4454', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4715', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3801', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.2999', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3706', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5203', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3474', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4041', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5629', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6564', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6598', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4628', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6823', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4952', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5494', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3732', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4297', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5299', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4613', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4285', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3733', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7226', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4993', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4603', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3621', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8502', 'WORST training acc 0.7188')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4292', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5832', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4905', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4687', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4750', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4979', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5702', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3884', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9425', 'WORST training acc 0.6875')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5827', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4557', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4198', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3800', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6357', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4043', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6010', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4916', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7614', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5593', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4597', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4231', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5233', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4020', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6202', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7944', 'WORST training acc 0.7188')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7221', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3510', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7683', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5352', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3374', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4085', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7292', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4036', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3875', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3886', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4865', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3917', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6526', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4792', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6711', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5338', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3155', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4063', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.2834', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4872', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3849', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5719', 'WORST training acc 0.8125')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4241', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5903', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5149', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5645', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6428', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4843', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5869', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4679', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3350', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3235', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4393', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6538', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4333', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4908', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5895', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6405', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5796', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4426', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4861', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4111', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5625', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5921', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3200', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4925', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4934', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.2361', 'WORST training acc 0.9375')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7524', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3170', 'WORST training acc 0.9062')\n",
      "('Epoch 00000100 ', 'avg train loss over', 125, ' batches ', '0.2240', 'avg train acc ', '0.9395')\n",
      "('Epoch 00000100 ', 'valid loss 0.2310', 'valid acc 0.9373')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5336', 'WORST valid acc 0.8265')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5336', 'MIN valid acc 0.8265')\n",
      "('Epoch 00000100 ', 'test loss 0.7567', 'test acc 0.7473')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8118', 'WORST test acc 0.7248')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.8118', 'MIN test acc 0.7248')\n",
      "===FINAL RESULTS WITH BATCH SIZE 32===\n",
      "('VALID: acc 0.9373', 'accs sd 0.0000', 'loss 0.2310', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7473', 'accs sd 0.0000', 'loss 0.7567', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8265', 'accs sd 0.0000', 'loss 0.5336', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7248', 'accs sd 0.0000', 'loss 0.8118', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [0]\n",
      "('MIN VALID: acc 0.8265', 'accs sd 0.0000', 'loss 0.5336', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7248', 'accs sd 0.0000', 'loss 0.8118', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [0]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 62, ' batches ', '0.2156', 'avg train acc ', '0.9359')\n",
      "('Epoch 00000010 ', 'valid loss 0.2182', 'valid acc 0.9339')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4490', 'WORST valid acc 0.8405')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4490', 'MIN valid acc 0.8405')\n",
      "('Epoch 00000010 ', 'test loss 0.7178', 'test acc 0.7534')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8542', 'WORST test acc 0.7252')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8542', 'MIN test acc 0.7252')\n",
      "('Epoch 00000020 ', 'avg train loss over', 62, ' batches ', '0.2171', 'avg train acc ', '0.9356')\n",
      "('Epoch 00000020 ', 'valid loss 0.2214', 'valid acc 0.9358')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4807', 'WORST valid acc 0.8285')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4807', 'MIN valid acc 0.8285')\n",
      "('Epoch 00000020 ', 'test loss 0.7122', 'test acc 0.7556')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8502', 'WORST test acc 0.7278')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8502', 'MIN test acc 0.7278')\n",
      "('Epoch 00000030 ', 'avg train loss over', 62, ' batches ', '0.2178', 'avg train acc ', '0.9376')\n",
      "('Epoch 00000030 ', 'valid loss 0.2278', 'valid acc 0.9341')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4821', 'WORST valid acc 0.8345')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4821', 'MIN valid acc 0.8345')\n",
      "('Epoch 00000030 ', 'test loss 0.7157', 'test acc 0.7574')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8520', 'WORST test acc 0.7300')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8520', 'MIN test acc 0.7300')\n",
      "('Epoch 00000040 ', 'avg train loss over', 62, ' batches ', '0.2163', 'avg train acc ', '0.9390')\n",
      "('Epoch 00000040 ', 'valid loss 0.2265', 'valid acc 0.9342')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4649', 'WORST valid acc 0.8415')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4649', 'MIN valid acc 0.8415')\n",
      "('Epoch 00000040 ', 'test loss 0.6998', 'test acc 0.7604')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8408', 'WORST test acc 0.7258')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8408', 'MIN test acc 0.7258')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4191', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3394', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5521', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3589', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4905', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3078', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4369', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3812', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5225', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4445', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.2423', 'WORST training acc 0.9375')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5426', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4409', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3249', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4176', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3654', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6830', 'WORST training acc 0.7656')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5240', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4553', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.2904', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3911', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3813', 'WORST training acc 0.8750')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6420', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4371', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6796', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4383', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4198', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6102', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4973', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4297', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3627', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5312', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5272', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6479', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3237', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4297', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6364', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3880', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5594', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3311', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4524', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3503', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3965', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4147', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6110', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.2981', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3177', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4265', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3919', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4827', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5072', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4897', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3257', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3879', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3255', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6142', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5903', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5383', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4349', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3821', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2827', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3966', 'WORST training acc 0.8750')\n",
      "('Epoch 00000050 ', 'avg train loss over', 62, ' batches ', '0.2181', 'avg train acc ', '0.9389')\n",
      "('Epoch 00000050 ', 'valid loss 0.2314', 'valid acc 0.9331')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4682', 'WORST valid acc 0.8355')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4682', 'MIN valid acc 0.8355')\n",
      "('Epoch 00000050 ', 'test loss 0.7080', 'test acc 0.7581')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8271', 'WORST test acc 0.7322')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8271', 'MIN test acc 0.7322')\n",
      "('Epoch 00000060 ', 'avg train loss over', 62, ' batches ', '0.2164', 'avg train acc ', '0.9395')\n",
      "('Epoch 00000060 ', 'valid loss 0.2323', 'valid acc 0.9348')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4942', 'WORST valid acc 0.8285')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4942', 'MIN valid acc 0.8285')\n",
      "('Epoch 00000060 ', 'test loss 0.7184', 'test acc 0.7552')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8320', 'WORST test acc 0.7270')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8320', 'MIN test acc 0.7270')\n",
      "('Epoch 00000070 ', 'avg train loss over', 62, ' batches ', '0.2195', 'avg train acc ', '0.9393')\n",
      "('Epoch 00000070 ', 'valid loss 0.2245', 'valid acc 0.9364')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4743', 'WORST valid acc 0.8355')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4743', 'MIN valid acc 0.8355')\n",
      "('Epoch 00000070 ', 'test loss 0.7339', 'test acc 0.7539')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8831', 'WORST test acc 0.7208')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8831', 'MIN test acc 0.7208')\n",
      "('Epoch 00000080 ', 'avg train loss over', 62, ' batches ', '0.2174', 'avg train acc ', '0.9403')\n",
      "('Epoch 00000080 ', 'valid loss 0.2238', 'valid acc 0.9363')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4814', 'WORST valid acc 0.8345')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4814', 'MIN valid acc 0.8345')\n",
      "('Epoch 00000080 ', 'test loss 0.7365', 'test acc 0.7532')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8730', 'WORST test acc 0.7254')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8730', 'MIN test acc 0.7254')\n",
      "('Epoch 00000090 ', 'avg train loss over', 62, ' batches ', '0.2164', 'avg train acc ', '0.9402')\n",
      "('Epoch 00000090 ', 'valid loss 0.2253', 'valid acc 0.9367')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4785', 'WORST valid acc 0.8325')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4785', 'MIN valid acc 0.8325')\n",
      "('Epoch 00000090 ', 'test loss 0.7442', 'test acc 0.7500')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8741', 'WORST test acc 0.7240')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8741', 'MIN test acc 0.7240')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4705', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3517', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5272', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4283', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5033', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3654', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3556', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3650', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5980', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4088', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.2839', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4519', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4325', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3376', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4220', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5023', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6699', 'WORST training acc 0.7656')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5557', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3351', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3283', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4961', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4006', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6563', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3864', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7769', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4242', 'WORST training acc 0.8750')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4259', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5059', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5655', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4456', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3294', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5292', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5322', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6386', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.2975', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4743', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4820', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3039', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6170', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3289', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3875', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3996', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3434', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4537', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5423', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3165', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3012', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4837', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4229', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4604', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4313', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5430', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3556', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3408', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3127', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6112', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5072', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6104', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4756', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3879', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2886', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4664', 'WORST training acc 0.8438')\n",
      "('Epoch 00000100 ', 'avg train loss over', 62, ' batches ', '0.2181', 'avg train acc ', '0.9393')\n",
      "('Epoch 00000100 ', 'valid loss 0.2312', 'valid acc 0.9344')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4814', 'WORST valid acc 0.8305')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4814', 'MIN valid acc 0.8305')\n",
      "('Epoch 00000100 ', 'test loss 0.7464', 'test acc 0.7523')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8810', 'WORST test acc 0.7292')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8810', 'MIN test acc 0.7292')\n",
      "===FINAL RESULTS WITH BATCH SIZE 64===\n",
      "('VALID: acc 0.9344', 'accs sd 0.0000', 'loss 0.2312', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7523', 'accs sd 0.0000', 'loss 0.7464', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8305', 'accs sd 0.0000', 'loss 0.4814', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7292', 'accs sd 0.0000', 'loss 0.8810', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8305', 'accs sd 0.0000', 'loss 0.4814', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7292', 'accs sd 0.0000', 'loss 0.8810', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 31, ' batches ', '0.2140', 'avg train acc ', '0.9379')\n",
      "('Epoch 00000010 ', 'valid loss 0.2274', 'valid acc 0.9330')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4850', 'WORST valid acc 0.8265')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4850', 'MIN valid acc 0.8265')\n",
      "('Epoch 00000010 ', 'test loss 0.7362', 'test acc 0.7536')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8331', 'WORST test acc 0.7372')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7501', 'MIN test acc 0.7332')\n",
      "('Epoch 00000020 ', 'avg train loss over', 31, ' batches ', '0.2133', 'avg train acc ', '0.9387')\n",
      "('Epoch 00000020 ', 'valid loss 0.2211', 'valid acc 0.9347')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4837', 'WORST valid acc 0.8325')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4837', 'MIN valid acc 0.8325')\n",
      "('Epoch 00000020 ', 'test loss 0.7244', 'test acc 0.7582')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8506', 'WORST test acc 0.7346')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8506', 'MIN test acc 0.7346')\n",
      "('Epoch 00000030 ', 'avg train loss over', 31, ' batches ', '0.2156', 'avg train acc ', '0.9379')\n",
      "('Epoch 00000030 ', 'valid loss 0.2198', 'valid acc 0.9378')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4456', 'WORST valid acc 0.8475')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4456', 'MIN valid acc 0.8475')\n",
      "('Epoch 00000030 ', 'test loss 0.7092', 'test acc 0.7611')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8524', 'WORST test acc 0.7252')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8524', 'MIN test acc 0.7252')\n",
      "('Epoch 00000040 ', 'avg train loss over', 31, ' batches ', '0.2151', 'avg train acc ', '0.9385')\n",
      "('Epoch 00000040 ', 'valid loss 0.2228', 'valid acc 0.9359')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4829', 'WORST valid acc 0.8335')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4829', 'MIN valid acc 0.8335')\n",
      "('Epoch 00000040 ', 'test loss 0.7236', 'test acc 0.7562')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8738', 'WORST test acc 0.7172')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8738', 'MIN test acc 0.7172')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3328', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4635', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4158', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3844', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4323', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3442', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3201', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4076', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5564', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3243', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3749', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4848', 'WORST training acc 0.8359')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4794', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5136', 'WORST training acc 0.8203')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4436', 'WORST training acc 0.8516')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4442', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6059', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3542', 'WORST training acc 0.8828')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5043', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4412', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3608', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4172', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4221', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3390', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4515', 'WORST training acc 0.8516')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5075', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3215', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4079', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5575', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4373', 'WORST training acc 0.8516')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3567', 'WORST training acc 0.8906')\n",
      "('Epoch 00000050 ', 'avg train loss over', 31, ' batches ', '0.2123', 'avg train acc ', '0.9392')\n",
      "('Epoch 00000050 ', 'valid loss 0.2188', 'valid acc 0.9350')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4833', 'WORST valid acc 0.8275')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4833', 'MIN valid acc 0.8275')\n",
      "('Epoch 00000050 ', 'test loss 0.7281', 'test acc 0.7593')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8952', 'WORST test acc 0.7252')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8952', 'MIN test acc 0.7252')\n",
      "('Epoch 00000060 ', 'avg train loss over', 31, ' batches ', '0.2135', 'avg train acc ', '0.9389')\n",
      "('Epoch 00000060 ', 'valid loss 0.2173', 'valid acc 0.9376')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4636', 'WORST valid acc 0.8395')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4636', 'MIN valid acc 0.8395')\n",
      "('Epoch 00000060 ', 'test loss 0.7324', 'test acc 0.7560')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8926', 'WORST test acc 0.7208')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8926', 'MIN test acc 0.7208')\n",
      "('Epoch 00000070 ', 'avg train loss over', 31, ' batches ', '0.2151', 'avg train acc ', '0.9385')\n",
      "('Epoch 00000070 ', 'valid loss 0.2206', 'valid acc 0.9366')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4671', 'WORST valid acc 0.8415')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4671', 'MIN valid acc 0.8415')\n",
      "('Epoch 00000070 ', 'test loss 0.7254', 'test acc 0.7584')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8835', 'WORST test acc 0.7230')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8835', 'MIN test acc 0.7230')\n",
      "('Epoch 00000080 ', 'avg train loss over', 31, ' batches ', '0.2122', 'avg train acc ', '0.9404')\n",
      "('Epoch 00000080 ', 'valid loss 0.2190', 'valid acc 0.9370')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4798', 'WORST valid acc 0.8365')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4798', 'MIN valid acc 0.8365')\n",
      "('Epoch 00000080 ', 'test loss 0.7227', 'test acc 0.7597')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8558', 'WORST test acc 0.7314')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8558', 'MIN test acc 0.7314')\n",
      "('Epoch 00000090 ', 'avg train loss over', 31, ' batches ', '0.2152', 'avg train acc ', '0.9390')\n",
      "('Epoch 00000090 ', 'valid loss 0.2167', 'valid acc 0.9391')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4509', 'WORST valid acc 0.8506')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4509', 'MIN valid acc 0.8506')\n",
      "('Epoch 00000090 ', 'test loss 0.7251', 'test acc 0.7556')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8688', 'WORST test acc 0.7214')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8688', 'MIN test acc 0.7214')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3526', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4505', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4299', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4013', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4445', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3722', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3381', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4146', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5645', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3469', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3658', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4902', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5223', 'WORST training acc 0.8359')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4927', 'WORST training acc 0.8359')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4583', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4335', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6133', 'WORST training acc 0.7969')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3606', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5002', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4292', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3601', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4252', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4177', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3373', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4504', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4982', 'WORST training acc 0.8359')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3085', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3755', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5542', 'WORST training acc 0.8203')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3982', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3391', 'WORST training acc 0.8906')\n",
      "('Epoch 00000100 ', 'avg train loss over', 31, ' batches ', '0.2124', 'avg train acc ', '0.9403')\n",
      "('Epoch 00000100 ', 'valid loss 0.2206', 'valid acc 0.9376')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4714', 'WORST valid acc 0.8375')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4714', 'MIN valid acc 0.8375')\n",
      "('Epoch 00000100 ', 'test loss 0.7417', 'test acc 0.7509')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8795', 'WORST test acc 0.7196')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8795', 'MIN test acc 0.7196')\n",
      "===FINAL RESULTS WITH BATCH SIZE 128===\n",
      "('VALID: acc 0.9376', 'accs sd 0.0000', 'loss 0.2206', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7509', 'accs sd 0.0000', 'loss 0.7417', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8375', 'accs sd 0.0000', 'loss 0.4714', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7196', 'accs sd 0.0000', 'loss 0.8795', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8375', 'accs sd 0.0000', 'loss 0.4714', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7196', 'accs sd 0.0000', 'loss 0.8795', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===ITERATION 1===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000010 ', 'avg train loss over', 4, ' batches ', '0.2220', 'avg train acc ', '0.9366')\n",
      "('Epoch 00000010 ', 'valid loss 0.2261', 'valid acc 0.9341')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4053', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4053', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000010 ', 'test loss 0.6333', 'test acc 0.7513')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7411', 'WORST test acc 0.7308')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6523', 'MIN test acc 0.7188')\n",
      "('Epoch 00000020 ', 'avg train loss over', 4, ' batches ', '0.2030', 'avg train acc ', '0.9391')\n",
      "('Epoch 00000020 ', 'valid loss 0.2102', 'valid acc 0.9358')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4326', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4326', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000020 ', 'test loss 0.7152', 'test acc 0.7527')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8215', 'WORST test acc 0.7362')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7206', 'MIN test acc 0.7304')\n",
      "('Epoch 00000030 ', 'avg train loss over', 4, ' batches ', '0.1977', 'avg train acc ', '0.9366')\n",
      "('Epoch 00000030 ', 'valid loss 0.2046', 'valid acc 0.9341')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4199', 'WORST valid acc 0.8495')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4199', 'MIN valid acc 0.8495')\n",
      "('Epoch 00000030 ', 'test loss 0.7101', 'test acc 0.7570')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7987', 'WORST test acc 0.7410')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7987', 'MIN test acc 0.7410')\n",
      "('Epoch 00000040 ', 'avg train loss over', 4, ' batches ', '0.1936', 'avg train acc ', '0.9348')\n",
      "('Epoch 00000040 ', 'valid loss 0.2048', 'valid acc 0.9313')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4103', 'WORST valid acc 0.8506')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4103', 'MIN valid acc 0.8506')\n",
      "('Epoch 00000040 ', 'test loss 0.6921', 'test acc 0.7568')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8563', 'WORST test acc 0.7250')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8563', 'MIN test acc 0.7250')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3448', 'WORST training acc 0.8710')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3976', 'WORST training acc 0.8470')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3916', 'WORST training acc 0.8490')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3600', 'WORST training acc 0.8660')\n",
      "('Epoch 00000050 ', 'avg train loss over', 4, ' batches ', '0.1802', 'avg train acc ', '0.9354')\n",
      "('Epoch 00000050 ', 'valid loss 0.1836', 'valid acc 0.9360')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3849', 'WORST valid acc 0.8556')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3849', 'MIN valid acc 0.8556')\n",
      "('Epoch 00000050 ', 'test loss 0.6873', 'test acc 0.7602')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9579', 'WORST test acc 0.7096')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9579', 'MIN test acc 0.7096')\n",
      "('Epoch 00000060 ', 'avg train loss over', 4, ' batches ', '0.1784', 'avg train acc ', '0.9350')\n",
      "('Epoch 00000060 ', 'valid loss 0.1829', 'valid acc 0.9331')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3750', 'WORST valid acc 0.8546')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3750', 'MIN valid acc 0.8546')\n",
      "('Epoch 00000060 ', 'test loss 0.6891', 'test acc 0.7610')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9511', 'WORST test acc 0.7134')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9511', 'MIN test acc 0.7134')\n",
      "('Epoch 00000070 ', 'avg train loss over', 4, ' batches ', '0.1800', 'avg train acc ', '0.9333')\n",
      "('Epoch 00000070 ', 'valid loss 0.1811', 'valid acc 0.9334')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3782', 'WORST valid acc 0.8536')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3782', 'MIN valid acc 0.8536')\n",
      "('Epoch 00000070 ', 'test loss 0.6952', 'test acc 0.7593')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9261', 'WORST test acc 0.7202')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9261', 'MIN test acc 0.7202')\n",
      "('Epoch 00000080 ', 'avg train loss over', 4, ' batches ', '0.1753', 'avg train acc ', '0.9348')\n",
      "('Epoch 00000080 ', 'valid loss 0.1779', 'valid acc 0.9344')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3816', 'WORST valid acc 0.8516')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3816', 'MIN valid acc 0.8516')\n",
      "('Epoch 00000080 ', 'test loss 0.6862', 'test acc 0.7623')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8785', 'WORST test acc 0.7286')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8785', 'MIN test acc 0.7286')\n",
      "('Epoch 00000090 ', 'avg train loss over', 4, ' batches ', '0.1743', 'avg train acc ', '0.9356')\n",
      "('Epoch 00000090 ', 'valid loss 0.1764', 'valid acc 0.9349')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3797', 'WORST valid acc 0.8526')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3797', 'MIN valid acc 0.8526')\n",
      "('Epoch 00000090 ', 'test loss 0.6857', 'test acc 0.7620')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8699', 'WORST test acc 0.7286')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8699', 'MIN test acc 0.7286')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3457', 'WORST training acc 0.8760')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3988', 'WORST training acc 0.8500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3887', 'WORST training acc 0.8490')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3523', 'WORST training acc 0.8640')\n",
      "('Epoch 00000100 ', 'avg train loss over', 4, ' batches ', '0.1756', 'avg train acc ', '0.9344')\n",
      "('Epoch 00000100 ', 'valid loss 0.1814', 'valid acc 0.9325')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3740', 'WORST valid acc 0.8536')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3740', 'MIN valid acc 0.8536')\n",
      "('Epoch 00000100 ', 'test loss 0.6864', 'test acc 0.7624')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8828', 'WORST test acc 0.7266')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8828', 'MIN test acc 0.7266')\n",
      "===FINAL RESULTS WITH BATCH SIZE 1000===\n",
      "('VALID: acc 0.9325', 'accs sd 0.0000', 'loss 0.1814', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7624', 'accs sd 0.0000', 'loss 0.6864', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8536', 'accs sd 0.0000', 'loss 0.3740', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7266', 'accs sd 0.0000', 'loss 0.8828', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8536', 'accs sd 0.0000', 'loss 0.3740', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7266', 'accs sd 0.0000', 'loss 0.8828', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 1, ' batches ', '0.4920', 'avg train acc ', '0.8767')\n",
      "('Epoch 00000010 ', 'valid loss 0.4945', 'valid acc 0.8752')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5572', 'WORST valid acc 0.7703')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5572', 'MIN valid acc 0.7703')\n",
      "('Epoch 00000010 ', 'test loss 0.6272', 'test acc 0.7180')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6652', 'WORST test acc 0.7252')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6311', 'MIN test acc 0.6792')\n",
      "('Epoch 00000020 ', 'avg train loss over', 1, ' batches ', '0.3642', 'avg train acc ', '0.9269')\n",
      "('Epoch 00000020 ', 'valid loss 0.3658', 'valid acc 0.9255')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4650', 'WORST valid acc 0.8175')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4650', 'MIN valid acc 0.8175')\n",
      "('Epoch 00000020 ', 'test loss 0.5770', 'test acc 0.7426')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6378', 'WORST test acc 0.7046')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6378', 'MIN test acc 0.7046')\n",
      "('Epoch 00000030 ', 'avg train loss over', 1, ' batches ', '0.2876', 'avg train acc ', '0.9315')\n",
      "('Epoch 00000030 ', 'valid loss 0.2910', 'valid acc 0.9302')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3920', 'WORST valid acc 0.8485')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3920', 'MIN valid acc 0.8485')\n",
      "('Epoch 00000030 ', 'test loss 0.5708', 'test acc 0.7544')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6706', 'WORST test acc 0.7168')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6706', 'MIN test acc 0.7168')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 1, ' batches ', '0.2469', 'avg train acc ', '0.9347')\n",
      "('Epoch 00000040 ', 'valid loss 0.2517', 'valid acc 0.9322')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3941', 'WORST valid acc 0.8355')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3941', 'MIN valid acc 0.8355')\n",
      "('Epoch 00000040 ', 'test loss 0.5783', 'test acc 0.7588')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7033', 'WORST test acc 0.7216')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7033', 'MIN test acc 0.7216')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3807', 'WORST training acc 0.8530')\n",
      "('Epoch 00000050 ', 'avg train loss over', 1, ' batches ', '0.2261', 'avg train acc ', '0.9376')\n",
      "('Epoch 00000050 ', 'valid loss 0.2321', 'valid acc 0.9345')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4037', 'WORST valid acc 0.8385')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4037', 'MIN valid acc 0.8385')\n",
      "('Epoch 00000050 ', 'test loss 0.6034', 'test acc 0.7578')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7204', 'WORST test acc 0.7278')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7204', 'MIN test acc 0.7278')\n",
      "('Epoch 00000060 ', 'avg train loss over', 1, ' batches ', '0.2150', 'avg train acc ', '0.9377')\n",
      "('Epoch 00000060 ', 'valid loss 0.2217', 'valid acc 0.9348')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4085', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4085', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000060 ', 'test loss 0.6322', 'test acc 0.7560')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7446', 'WORST test acc 0.7302')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6454', 'MIN test acc 0.7290')\n",
      "('Epoch 00000070 ', 'avg train loss over', 1, ' batches ', '0.2089', 'avg train acc ', '0.9390')\n",
      "('Epoch 00000070 ', 'valid loss 0.2160', 'valid acc 0.9364')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4148', 'WORST valid acc 0.8455')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4148', 'MIN valid acc 0.8455')\n",
      "('Epoch 00000070 ', 'test loss 0.6621', 'test acc 0.7526')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7709', 'WORST test acc 0.7300')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6695', 'MIN test acc 0.7278')\n",
      "('Epoch 00000080 ', 'avg train loss over', 1, ' batches ', '0.2050', 'avg train acc ', '0.9391')\n",
      "('Epoch 00000080 ', 'valid loss 0.2116', 'valid acc 0.9366')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4123', 'WORST valid acc 0.8465')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4123', 'MIN valid acc 0.8465')\n",
      "('Epoch 00000080 ', 'test loss 0.6801', 'test acc 0.7529')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7843', 'WORST test acc 0.7334')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6768', 'MIN test acc 0.7310')\n",
      "('Epoch 00000090 ', 'avg train loss over', 1, ' batches ', '0.2022', 'avg train acc ', '0.9390')\n",
      "('Epoch 00000090 ', 'valid loss 0.2093', 'valid acc 0.9361')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4153', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4153', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000090 ', 'test loss 0.6994', 'test acc 0.7498')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8007', 'WORST test acc 0.7324')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6906', 'MIN test acc 0.7284')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3857', 'WORST training acc 0.8612')\n",
      "('Epoch 00000100 ', 'avg train loss over', 1, ' batches ', '0.1994', 'avg train acc ', '0.9385')\n",
      "('Epoch 00000100 ', 'valid loss 0.2062', 'valid acc 0.9360')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4133', 'WORST valid acc 0.8485')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4133', 'MIN valid acc 0.8485')\n",
      "('Epoch 00000100 ', 'test loss 0.7027', 'test acc 0.7504')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8064', 'WORST test acc 0.7316')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8064', 'MIN test acc 0.7316')\n",
      "===FINAL RESULTS WITH BATCH SIZE 4000===\n",
      "('VALID: acc 0.9360', 'accs sd 0.0000', 'loss 0.2062', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7504', 'accs sd 0.0000', 'loss 0.7027', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8485', 'accs sd 0.0000', 'loss 0.4133', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7316', 'accs sd 0.0000', 'loss 0.8064', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8485', 'accs sd 0.0000', 'loss 0.4133', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7316', 'accs sd 0.0000', 'loss 0.8064', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===MAXIMUM LOSS FUNCTION===\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6130', 'avg train acc ', '0.9155')\n",
      "('Epoch 00000010 ', 'valid loss 0.4783', 'valid acc 0.8882')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4783', 'WORST valid acc 0.7964')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4783', 'MIN valid acc 0.7964')\n",
      "('Epoch 00000010 ', 'test loss 0.6074', 'test acc 0.7613')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6074', 'WORST test acc 0.7252')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6074', 'MIN test acc 0.7252')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6054', 'avg train acc ', '0.9249')\n",
      "('Epoch 00000020 ', 'valid loss 0.4559', 'valid acc 0.9216')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4559', 'WORST valid acc 0.8556')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4559', 'MIN valid acc 0.8556')\n",
      "('Epoch 00000020 ', 'test loss 0.5744', 'test acc 0.7543')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.5744', 'WORST test acc 0.7410')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5744', 'MIN test acc 0.7410')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6017', 'avg train acc ', '0.9226')\n",
      "('Epoch 00000030 ', 'valid loss 0.4837', 'valid acc 0.9229')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4837', 'WORST valid acc 0.8305')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4837', 'MIN valid acc 0.8305')\n",
      "('Epoch 00000030 ', 'test loss 0.5866', 'test acc 0.7455')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5866', 'WORST test acc 0.7270')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5866', 'MIN test acc 0.7270')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5877', 'avg train acc ', '0.9315')\n",
      "('Epoch 00000040 ', 'valid loss 0.4425', 'valid acc 0.9310')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4425', 'WORST valid acc 0.8556')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4425', 'MIN valid acc 0.8556')\n",
      "('Epoch 00000040 ', 'test loss 0.5770', 'test acc 0.7589')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5770', 'WORST test acc 0.7364')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5702', 'MIN test acc 0.7354')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4911', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5284', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3790', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5262', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7736', 'WORST training acc 0.5000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7034', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5275', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8640', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5455', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5356', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5243', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6943', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5257', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5018', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7091', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6370', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5672', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5278', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4892', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7007', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6711', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5648', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7265', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6998', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5971', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6453', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6968', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5550', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5347', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6919', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6958', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6979', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6982', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5180', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6692', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5508', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5518', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5499', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6858', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5649', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5344', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5253', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3505', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6431', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3476', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7038', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6330', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6368', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5594', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5647', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5684', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5703', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8511', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6838', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9063', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5488', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8506', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5939', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5488', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5458', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6988', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6782', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5689', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5309', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6818', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7921', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4644', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6052', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5365', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5009', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7501', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6490', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5267', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7421', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5303', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5131', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4728', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5473', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5082', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6017', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5376', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5817', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6643', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5416', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7967', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5367', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5359', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5596', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5508', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6249', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7133', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5396', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7370', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5264', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5116', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5146', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7125', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7072', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5144', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8804', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5605', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5517', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7205', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6954', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5186', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5082', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5042', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3357', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4921', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6929', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5735', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7110', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5540', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4783', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6830', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6815', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7561', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7816', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7125', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5005', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8183', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5755', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4392', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5706', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5341', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8659', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4580', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5033', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6501', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5642', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5335', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4581', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6953', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5927', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5592', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5539', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5293', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7367', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5158', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6970', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5294', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6791', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5545', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5629', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5439', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5295', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6994', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5252', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4915', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7867', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7263', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4447', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5005', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4017', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5993', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8898', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5477', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6300', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5906', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7071', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5810', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4746', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7040', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4392', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7394', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6009', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6697', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6993', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5303', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4916', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4667', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5531', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6973', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3470', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8666', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6404', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5166', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5296', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5298', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6573', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6232', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5646', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6468', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5520', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7839', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4840', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5642', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3784', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5539', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7358', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7375', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5271', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5326', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5243', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6885', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7731', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5869', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5576', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5226', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5287', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7021', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7016', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6970', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8255', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7009', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6743', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4796', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5762', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4278', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4662', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0898', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 1.0432', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7498', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6322', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5832', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5783', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8984', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8121', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6877', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5360', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6598', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6829', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5382', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6998', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5550', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6493', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5261', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5046', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7305', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6782', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5576', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5115', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6778', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5238', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6304', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6027', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5759', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5777', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5776', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5446', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5440', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5732', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6797', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6757', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8181', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7260', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5599', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5536', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5395', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5383', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5432', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5376', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5369', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6860', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6873', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6701', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5248', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6720', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5506', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5287', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5737', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5523', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6680', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5123', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5325', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5521', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5311', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6410', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5706', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5017', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6708', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5511', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7316', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5442', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6936', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5364', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5256', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6879', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5302', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5263', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6997', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6969', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5213', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5303', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6973', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5194', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7029', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8719', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5300', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5333', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5248', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5250', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5215', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8766', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5275', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5267', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5223', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6990', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5186', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6989', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6587', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5619', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4459', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7268', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6168', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5685', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6038', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6685', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5364', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7581', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4454', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5632', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4813', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7792', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7640', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8643', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5084', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5724', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3532', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6827', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6919', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5301', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5269', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5269', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6979', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5274', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6978', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5276', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5266', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6883', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5306', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6925', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7008', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5248', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5246', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5254', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6901', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7063', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5365', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6917', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8714', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5322', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6969', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5179', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6497', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4991', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6527', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5708', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6154', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6993', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6198', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5398', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5391', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7835', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5188', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5590', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6324', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5302', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5292', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5282', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5025', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4825', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4979', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4941', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5527', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6981', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5305', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7657', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5289', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5279', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7183', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5418', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5361', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5353', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5143', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7016', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7014', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6811', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7188', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5226', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4896', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7361', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5511', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7257', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5381', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5221', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7100', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7105', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8707', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5212', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5211', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5289', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5243', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7166', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6970', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6967', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8482', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4774', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5519', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7184', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5061', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5782', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5301', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5295', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6934', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7105', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5282', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5398', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5128', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7036', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6841', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5346', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5417', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5236', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6832', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7038', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6993', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5239', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6924', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5565', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5189', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5181', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5420', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0529', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5461', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6815', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6895', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6928', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5334', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5334', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5360', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6795', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8064', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5344', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7390', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5086', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5387', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6012', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5694', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6550', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6863', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6078', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5988', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5310', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6380', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6413', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6050', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4801', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4778', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3971', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4539', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6721', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4376', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8628', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6211', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5667', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6028', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4982', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9178', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5229', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5310', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5318', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5373', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7234', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5372', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7012', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5353', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.8769', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5164', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5230', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5368', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5394', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5545', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5498', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5018', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5325', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5101', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5281', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5243', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5206', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5259', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5393', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5417', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5168', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9010', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6853', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5348', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7066', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5207', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5121', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7134', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5628', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5389', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5659', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7617', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4773', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5265', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5521', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6667', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5014', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5004', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8239', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5481', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3090', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5198', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5177', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7257', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4902', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7152', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5019', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7150', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1280', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5123', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5190', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7064', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7068', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5240', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5068', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7343', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4911', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5193', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7412', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5194', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4829', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7416', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5068', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5196', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6707', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6616', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6483', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4819', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5895', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5622', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7395', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6524', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6132', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4711', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5796', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6376', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4654', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6219', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4642', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4144', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9705', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6272', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5514', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3468', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7151', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8778', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8480', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7451', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7885', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7497', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5441', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5414', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5996', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7269', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5701', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8972', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5737', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7060', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6806', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5642', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7330', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5637', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5748', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5639', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6890', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7472', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5493', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5249', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7002', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5112', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6272', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5419', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5419', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6815', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6282', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5858', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5698', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5398', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6828', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5045', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5386', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5022', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6133', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8740', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5402', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5727', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4613', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5052', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5410', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5762', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5730', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5682', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5867', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5528', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6282', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5457', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6765', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5252', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7041', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7068', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6919', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5324', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8413', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8286', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5921', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5571', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5549', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6972', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5557', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6865', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5338', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6664', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5306', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5696', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5323', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7253', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4656', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5656', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5660', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3613', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7874', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5526', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5449', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7070', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5248', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6957', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7066', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5385', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5254', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5287', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5227', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5437', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5349', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7066', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.8487', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5039', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5429', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6678', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5661', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7149', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5589', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4868', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5015', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6691', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5271', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5648', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3613', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6314', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6786', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5486', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6109', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7018', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5872', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7019', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5831', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5519', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5461', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6995', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5353', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5179', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7000', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7003', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6996', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5212', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5216', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5218', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6894', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5295', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6954', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6798', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5476', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5421', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5253', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7000', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5376', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5413', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5596', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7021', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7444', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8632', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5081', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5080', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5076', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7389', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5093', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5470', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5225', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6768', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6989', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5280', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5225', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5313', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5204', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6974', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5394', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6740', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5291', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5267', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7012', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5232', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5245', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5205', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5208', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5193', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5202', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5212', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8955', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5150', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5178', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5173', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5142', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7078', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7107', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5154', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5161', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7073', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8964', 'WORST training acc 0.4000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7159', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5135', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5173', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5203', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5184', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7008', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5173', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7098', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5179', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5139', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6950', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6952', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5196', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5322', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5521', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5124', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5311', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5375', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7203', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7003', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5213', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7000', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5031', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5422', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5353', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5298', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5286', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5170', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7078', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6850', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6663', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8702', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6147', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5794', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6758', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4626', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5492', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6706', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6860', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6382', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6345', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6218', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5369', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 1.0111', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7567', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6460', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5058', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7055', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5214', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5258', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5265', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7056', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6986', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6946', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5258', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6938', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6954', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6824', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7177', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5475', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5364', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5192', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5349', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5326', 'WORST training acc 0.8000')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6033', 'avg train acc ', '0.9266')\n",
      "('Epoch 00000050 ', 'valid loss 0.4678', 'valid acc 0.9215')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4678', 'WORST valid acc 0.8646')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4678', 'MIN valid acc 0.8646')\n",
      "('Epoch 00000050 ', 'test loss 0.5922', 'test acc 0.7445')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5922', 'WORST test acc 0.7192')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5922', 'MIN test acc 0.7192')\n",
      "('Epoch 00000060 ', 'avg train loss over', 800, ' batches ', '0.5952', 'avg train acc ', '0.9256')\n",
      "('Epoch 00000060 ', 'valid loss 0.4624', 'valid acc 0.9210')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4624', 'WORST valid acc 0.8255')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4624', 'MIN valid acc 0.8255')\n",
      "('Epoch 00000060 ', 'test loss 0.6308', 'test acc 0.7300')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6308', 'WORST test acc 0.7518')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6137', 'MIN test acc 0.7066')\n",
      "('Epoch 00000070 ', 'avg train loss over', 800, ' batches ', '0.6006', 'avg train acc ', '0.9274')\n",
      "('Epoch 00000070 ', 'valid loss 0.4469', 'valid acc 0.9238')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4469', 'WORST valid acc 0.8576')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4469', 'MIN valid acc 0.8576')\n",
      "('Epoch 00000070 ', 'test loss 0.5886', 'test acc 0.7436')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5886', 'WORST test acc 0.7500')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5841', 'MIN test acc 0.7244')\n",
      "('Epoch 00000080 ', 'avg train loss over', 800, ' batches ', '0.5986', 'avg train acc ', '0.9250')\n",
      "('Epoch 00000080 ', 'valid loss 0.4516', 'valid acc 0.9222')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4516', 'WORST valid acc 0.8596')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4516', 'MIN valid acc 0.8596')\n",
      "('Epoch 00000080 ', 'test loss 0.6209', 'test acc 0.7322')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6209', 'WORST test acc 0.7496')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6081', 'MIN test acc 0.7086')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000090 ', 'avg train loss over', 800, ' batches ', '0.5894', 'avg train acc ', '0.9235')\n",
      "('Epoch 00000090 ', 'valid loss 0.4639', 'valid acc 0.9212')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4639', 'WORST valid acc 0.8415')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4639', 'MIN valid acc 0.8415')\n",
      "('Epoch 00000090 ', 'test loss 0.6002', 'test acc 0.7406')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6002', 'WORST test acc 0.7538')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5850', 'MIN test acc 0.7184')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4684', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4870', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5171', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3244', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5138', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5059', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7301', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7208', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7210', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5229', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5153', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5096', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7139', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5114', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5123', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7283', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5132', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5282', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5122', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5116', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5137', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7190', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5100', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5018', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5241', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5029', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5213', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7230', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7258', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5106', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5120', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7068', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7343', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7210', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7201', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5224', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7381', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5202', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5130', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5149', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6943', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5491', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5287', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5393', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5200', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7077', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5214', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7258', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5170', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6997', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5203', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5036', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5436', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5227', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6489', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5710', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7964', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5204', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7611', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5217', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5135', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6830', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7169', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6963', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5909', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5222', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6913', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6143', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4358', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6114', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7943', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4038', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5978', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5579', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5660', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7473', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5162', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6987', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4591', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5474', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5007', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8549', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7251', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5770', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6476', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7586', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7837', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7721', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5367', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5275', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5145', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7128', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5069', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5241', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5471', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5558', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5437', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6853', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7066', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5205', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8928', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5386', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6851', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.9110', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7267', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5180', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5175', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5171', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3147', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3353', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5045', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6939', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7898', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7098', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6175', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4786', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7996', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7136', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7229', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8026', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6002', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5020', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8537', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5983', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4424', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5816', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5368', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8655', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4587', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5788', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6634', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7208', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5510', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5258', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5271', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6978', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5276', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6962', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5261', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6931', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6943', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6937', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5270', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5345', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5148', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4979', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5278', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5447', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7111', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5096', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5620', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6278', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7152', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4722', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5309', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3788', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5731', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7333', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5286', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7576', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5478', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5210', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6982', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5330', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5356', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7051', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3439', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7033', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5293', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7063', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6951', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5299', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5150', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5350', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5137', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7048', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5259', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5238', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5218', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5160', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5193', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5330', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5487', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7317', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5322', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7085', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5359', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7219', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5155', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5186', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3310', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5057', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5392', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6824', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5412', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5251', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5137', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.9209', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5014', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5076', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5154', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5477', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4931', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7180', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.9427', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5273', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8641', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7153', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7294', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5034', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7531', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3159', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5475', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7229', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7005', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8780', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5454', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5743', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5773', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8739', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7391', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7135', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5721', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5583', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5450', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7010', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3437', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5355', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7447', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4699', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4573', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8124', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7055', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5639', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5324', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7883', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4759', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6664', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5780', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6489', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6018', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5605', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5284', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4694', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7006', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5244', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5485', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7004', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7089', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5215', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5266', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5264', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3361', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7116', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5165', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5248', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7105', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7045', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5239', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5217', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7058', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5174', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5138', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6810', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5437', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7224', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5438', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5165', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5356', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5166', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5359', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4956', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6946', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6501', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6885', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5615', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5651', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5970', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5621', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5295', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5779', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5037', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7661', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4914', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5275', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7198', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5136', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5105', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5267', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6962', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5123', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7173', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7026', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3630', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4972', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5486', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8616', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5484', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5399', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5298', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5131', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5089', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.9330', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6752', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5532', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4385', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5496', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6642', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5610', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5920', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5305', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5295', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7705', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5479', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5407', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5186', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7393', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7180', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7136', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5382', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5265', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5503', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7017', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5272', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6795', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5564', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5338', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6892', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6836', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6929', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5143', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5284', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5052', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7210', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6982', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5374', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5201', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7097', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7091', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5170', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5172', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8985', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5686', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5169', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7103', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3887', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6915', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5259', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5252', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5216', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8624', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5336', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6952', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5339', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5074', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.8527', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6930', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6648', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7562', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5542', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5522', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5741', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5131', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5362', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5189', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5311', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5361', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5534', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5240', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7419', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5231', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5354', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7129', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5341', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5217', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7142', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7072', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7119', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7087', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6997', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5182', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5566', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5305', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7139', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5245', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5175', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7303', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5318', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8830', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5067', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6852', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6941', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7244', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5413', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7181', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7048', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7032', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8832', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5141', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5314', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7084', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5106', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7506', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6948', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5275', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5570', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5216', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6859', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5371', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6799', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7037', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6820', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5394', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5324', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3638', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6975', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6870', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6818', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5476', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6968', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5437', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5333', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6910', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5273', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7135', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7023', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5402', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5428', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6830', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7070', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5273', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6841', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7058', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7184', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5472', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6782', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5424', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5299', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5279', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5449', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5277', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5405', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7319', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5154', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5358', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5251', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6866', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5328', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5239', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3450', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5156', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3455', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5279', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5098', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7080', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7062', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5173', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5197', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5066', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7288', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5009', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7488', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5222', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5068', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9001', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7181', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5168', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5189', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7131', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5314', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5201', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5161', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5177', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5251', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5256', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5149', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7219', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4981', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7141', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5178', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5159', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5196', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5214', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5118', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9224', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5134', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5115', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5114', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5131', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5119', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5031', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9240', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7289', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5133', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5144', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7286', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5201', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5118', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5141', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7228', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5183', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5107', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5164', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5142', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3037', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5114', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5110', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5106', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5013', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7251', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5157', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7222', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 1.1251', 'WORST training acc 0.2000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5161', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6636', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5821', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6882', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8110', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7467', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7710', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5471', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6768', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5307', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5149', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7214', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7112', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4856', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7488', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4723', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5232', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5248', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8188', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.7889', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3516', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5953', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5647', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5612', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8045', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6372', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4869', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5497', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7016', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5254', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5558', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5023', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5417', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5266', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6978', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5249', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3478', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5236', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7190', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.8659', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5215', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7169', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7119', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5163', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6829', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7153', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5418', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.9050', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5121', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7194', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7086', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6968', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6894', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6977', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5566', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5542', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5458', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6819', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6936', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6926', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6904', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5275', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5364', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5308', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5401', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5306', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5565', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6554', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7121', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6896', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6895', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5206', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5304', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5400', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6627', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5527', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5263', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5396', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3715', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5337', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5269', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5254', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5306', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6569', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5484', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7304', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6830', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7097', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6960', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5310', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6876', 'WORST training acc 0.6000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7052', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6988', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8825', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8794', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5249', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5242', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5264', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.8646', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5265', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5402', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6973', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7070', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5137', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5428', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5292', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6705', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5319', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7534', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6652', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5598', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7699', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5509', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.8471', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7038', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5382', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6909', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5402', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6950', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5412', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5341', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5339', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6874', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5407', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6955', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6737', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5165', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5484', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7057', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5607', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6983', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6957', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5411', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6911', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5331', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5324', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6653', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6760', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5473', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6156', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7155', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7560', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6892', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7823', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6838', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5586', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6327', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.7329', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5347', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5345', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5344', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6726', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5323', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5444', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5417', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6946', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6896', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.8099', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.6609', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6745', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6082', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.6359', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7009', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5720', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5234', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5235', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5603', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6940', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5373', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6969', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6896', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5255', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5443', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7220', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5140', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7483', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5318', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6428', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6887', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5329', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.7116', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5920', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5068', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7365', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6894', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.7006', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.6891', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5374', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5415', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5335', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5281', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5341', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5291', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5286', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7017', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5381', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7128', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5070', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5404', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.6942', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5311', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5267', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.6967', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6850', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5410', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5331', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7030', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5257', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6970', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5279', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5232', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5290', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5288', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6776', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5323', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7139', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5304', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5215', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.8398', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5220', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5221', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5317', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5501', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5213', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5284', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7077', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6870', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.7019', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5302', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5264', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3404', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5241', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5259', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.5145', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5217', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5168', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5168', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6828', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4935', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8763', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.8022', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5516', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5748', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5479', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4845', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4841', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6892', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5851', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5553', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7433', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5268', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5132', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.8575', 'WORST training acc 0.4000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.6566', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6379', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5806', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.6614', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6156', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.6309', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5983', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5484', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5188', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.7202', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5074', 'WORST training acc 0.8000')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5477', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.7644', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.6800', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.7747', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.7537', 'WORST training acc 0.6000')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3080', 'WORST training acc 1.0000')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.5024', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5338', 'WORST training acc 0.8000')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.7287', 'WORST training acc 0.6000')\n",
      "('Epoch 00000100 ', 'avg train loss over', 800, ' batches ', '0.6017', 'avg train acc ', '0.9284')\n",
      "('Epoch 00000100 ', 'valid loss 0.4296', 'valid acc 0.9226')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4296', 'WORST valid acc 0.8666')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4296', 'MIN valid acc 0.8666')\n",
      "('Epoch 00000100 ', 'test loss 0.5701', 'test acc 0.7611')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5701', 'WORST test acc 0.7358')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5701', 'MIN test acc 0.7358')\n",
      "===FINAL RESULTS WITH BATCH SIZE 5===\n",
      "('VALID: acc 0.9226', 'accs sd 0.0000', 'loss 0.4296', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7611', 'accs sd 0.0000', 'loss 0.5701', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8666', 'accs sd 0.0000', 'loss 0.4296', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7358', 'accs sd 0.0000', 'loss 0.5701', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [0]\n",
      "('MIN VALID: acc 0.8666', 'accs sd 0.0000', 'loss 0.4296', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7358', 'accs sd 0.0000', 'loss 0.5701', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [0]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 125, ' batches ', '0.4456', 'avg train acc ', '0.9068')\n",
      "('Epoch 00000010 ', 'valid loss 0.3932', 'valid acc 0.9012')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3932', 'WORST valid acc 0.8516')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3932', 'MIN valid acc 0.8516')\n",
      "('Epoch 00000010 ', 'test loss 0.6798', 'test acc 0.7473')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6798', 'WORST test acc 0.7248')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6425', 'MIN test acc 0.7100')\n",
      "('Epoch 00000020 ', 'avg train loss over', 125, ' batches ', '0.4324', 'avg train acc ', '0.9237')\n",
      "('Epoch 00000020 ', 'valid loss 0.3785', 'valid acc 0.9209')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3785', 'WORST valid acc 0.8696')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3785', 'MIN valid acc 0.8696')\n",
      "('Epoch 00000020 ', 'test loss 0.5850', 'test acc 0.7796')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5850', 'WORST test acc 0.7404')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5850', 'MIN test acc 0.7404')\n",
      "('Epoch 00000030 ', 'avg train loss over', 125, ' batches ', '0.4179', 'avg train acc ', '0.9253')\n",
      "('Epoch 00000030 ', 'valid loss 0.3663', 'valid acc 0.9211')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3663', 'WORST valid acc 0.8676')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3663', 'MIN valid acc 0.8676')\n",
      "('Epoch 00000030 ', 'test loss 0.6933', 'test acc 0.7442')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6933', 'WORST test acc 0.7204')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6576', 'MIN test acc 0.7050')\n",
      "('Epoch 00000040 ', 'avg train loss over', 125, ' batches ', '0.4127', 'avg train acc ', '0.9298')\n",
      "('Epoch 00000040 ', 'valid loss 0.3634', 'valid acc 0.9274')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3634', 'WORST valid acc 0.8806')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3634', 'MIN valid acc 0.8806')\n",
      "('Epoch 00000040 ', 'test loss 0.6154', 'test acc 0.7774')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6154', 'WORST test acc 0.7430')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6154', 'MIN test acc 0.7430')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5696', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3771', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3443', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3577', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4824', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5546', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4100', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.5174', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3674', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5155', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3913', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4303', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.2793', 'WORST training acc 0.9375')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4306', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4340', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4348', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3858', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3324', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5262', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3449', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4172', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4184', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4985', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4272', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3907', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3776', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3791', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4165', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4102', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4399', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4762', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3647', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4026', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4152', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5154', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4171', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4795', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3824', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3767', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3463', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3811', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3919', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4644', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4401', 'WORST training acc 0.8438')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4283', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4332', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3271', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4283', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3167', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4322', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3793', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4371', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3880', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3872', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3975', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4397', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4171', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3240', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3987', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3713', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4902', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4395', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3768', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4611', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3892', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4572', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4334', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3882', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4389', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4131', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3409', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3896', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4052', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4099', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4383', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3043', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4021', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5192', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3652', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.2726', 'WORST training acc 0.9375')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3213', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4729', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4149', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4476', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3649', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4234', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5313', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4622', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4354', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4317', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3703', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3822', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3799', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3801', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3801', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4288', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5386', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3887', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4400', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3319', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4695', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4280', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4748', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4468', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3825', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3727', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4789', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4648', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4391', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3990', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4624', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3684', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4199', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4262', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4732', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3869', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3336', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3842', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4201', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4734', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3789', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4540', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4157', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4890', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3250', 'WORST training acc 0.9062')\n",
      "('Epoch 00000050 ', 'avg train loss over', 125, ' batches ', '0.4148', 'avg train acc ', '0.9269')\n",
      "('Epoch 00000050 ', 'valid loss 0.3557', 'valid acc 0.9262')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3557', 'WORST valid acc 0.8826')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3557', 'MIN valid acc 0.8826')\n",
      "('Epoch 00000050 ', 'test loss 0.6436', 'test acc 0.7664')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6436', 'WORST test acc 0.7276')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6436', 'MIN test acc 0.7276')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000060 ', 'avg train loss over', 125, ' batches ', '0.4242', 'avg train acc ', '0.9274')\n",
      "('Epoch 00000060 ', 'valid loss 0.3576', 'valid acc 0.9242')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3576', 'WORST valid acc 0.8847')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3576', 'MIN valid acc 0.8847')\n",
      "('Epoch 00000060 ', 'test loss 0.6460', 'test acc 0.7559')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6460', 'WORST test acc 0.7294')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6460', 'MIN test acc 0.7294')\n",
      "('Epoch 00000070 ', 'avg train loss over', 125, ' batches ', '0.4199', 'avg train acc ', '0.9291')\n",
      "('Epoch 00000070 ', 'valid loss 0.4006', 'valid acc 0.9264')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4006', 'WORST valid acc 0.8485')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4006', 'MIN valid acc 0.8485')\n",
      "('Epoch 00000070 ', 'test loss 0.6911', 'test acc 0.7564')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6911', 'WORST test acc 0.7130')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6911', 'MIN test acc 0.7130')\n",
      "('Epoch 00000080 ', 'avg train loss over', 125, ' batches ', '0.4166', 'avg train acc ', '0.9253')\n",
      "('Epoch 00000080 ', 'valid loss 0.3843', 'valid acc 0.9142')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3843', 'WORST valid acc 0.8596')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3843', 'MIN valid acc 0.8596')\n",
      "('Epoch 00000080 ', 'test loss 0.7013', 'test acc 0.7682')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7013', 'WORST test acc 0.7270')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7013', 'MIN test acc 0.7270')\n",
      "('Epoch 00000090 ', 'avg train loss over', 125, ' batches ', '0.4252', 'avg train acc ', '0.9255')\n",
      "('Epoch 00000090 ', 'valid loss 0.3860', 'valid acc 0.9230')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3860', 'WORST valid acc 0.8656')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3860', 'MIN valid acc 0.8656')\n",
      "('Epoch 00000090 ', 'test loss 0.6523', 'test acc 0.7617')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6523', 'WORST test acc 0.7142')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6523', 'MIN test acc 0.7142')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3164', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3742', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3236', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3447', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.5025', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5346', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.5721', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4054', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3699', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5426', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4287', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4816', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3777', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4687', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3946', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4245', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4155', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4167', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6182', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4511', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.5434', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3278', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4876', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4861', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3815', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3863', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3935', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3845', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3893', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3882', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4921', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4343', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4921', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4287', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5450', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3819', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5499', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3750', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4384', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3822', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3283', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3814', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4353', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4373', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4802', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4359', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3423', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.5446', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3461', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.6136', 'WORST training acc 0.7500')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3984', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4555', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4463', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4440', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4131', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4393', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4215', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3684', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4942', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4295', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4303', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4890', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3808', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4762', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3326', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4353', 'WORST training acc 0.8438')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4324', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4378', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5276', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4241', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3706', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.5212', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4115', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4119', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4370', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4704', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4839', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4146', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4159', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.2807', 'WORST training acc 0.9375')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3917', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.5146', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3857', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4464', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3715', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3814', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4797', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4275', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4373', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4359', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4311', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3842', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3332', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.5347', 'WORST training acc 0.7812')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3836', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4237', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.4858', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4841', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4348', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3614', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4847', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4213', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3834', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4247', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4370', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4376', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4461', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4395', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4865', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3835', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.4339', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3812', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3842', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4324', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4310', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3352', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3335', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3810', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4339', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3807', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3740', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4549', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3751', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4950', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3689', 'WORST training acc 0.8750')\n",
      "('Epoch 00000100 ', 'avg train loss over', 125, ' batches ', '0.4285', 'avg train acc ', '0.9276')\n",
      "('Epoch 00000100 ', 'valid loss 0.3778', 'valid acc 0.9259')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3778', 'WORST valid acc 0.8716')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3778', 'MIN valid acc 0.8716')\n",
      "('Epoch 00000100 ', 'test loss 0.6733', 'test acc 0.7558')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6733', 'WORST test acc 0.7214')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6733', 'MIN test acc 0.7214')\n",
      "===FINAL RESULTS WITH BATCH SIZE 32===\n",
      "('VALID: acc 0.9259', 'accs sd 0.0000', 'loss 0.3778', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7558', 'accs sd 0.0000', 'loss 0.6733', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8716', 'accs sd 0.0000', 'loss 0.3778', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7214', 'accs sd 0.0000', 'loss 0.6733', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8716', 'accs sd 0.0000', 'loss 0.3778', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7214', 'accs sd 0.0000', 'loss 0.6733', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 62, ' batches ', '0.3689', 'avg train acc ', '0.9183')\n",
      "('Epoch 00000010 ', 'valid loss 0.3377', 'valid acc 0.9251')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3377', 'WORST valid acc 0.8877')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3377', 'MIN valid acc 0.8877')\n",
      "('Epoch 00000010 ', 'test loss 0.6061', 'test acc 0.7764')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6061', 'WORST test acc 0.7502')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6061', 'MIN test acc 0.7502')\n",
      "('Epoch 00000020 ', 'avg train loss over', 62, ' batches ', '0.3811', 'avg train acc ', '0.9232')\n",
      "('Epoch 00000020 ', 'valid loss 0.3679', 'valid acc 0.9273')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3679', 'WORST valid acc 0.8676')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3679', 'MIN valid acc 0.8676')\n",
      "('Epoch 00000020 ', 'test loss 0.6980', 'test acc 0.7571')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6980', 'WORST test acc 0.7204')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6980', 'MIN test acc 0.7204')\n",
      "('Epoch 00000030 ', 'avg train loss over', 62, ' batches ', '0.3673', 'avg train acc ', '0.9220')\n",
      "('Epoch 00000030 ', 'valid loss 0.3464', 'valid acc 0.9279')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3464', 'WORST valid acc 0.8776')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3464', 'MIN valid acc 0.8776')\n",
      "('Epoch 00000030 ', 'test loss 0.6781', 'test acc 0.7724')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6781', 'WORST test acc 0.7402')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6781', 'MIN test acc 0.7402')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 62, ' batches ', '0.3779', 'avg train acc ', '0.9164')\n",
      "('Epoch 00000040 ', 'valid loss 0.3470', 'valid acc 0.9130')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3470', 'WORST valid acc 0.8806')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3470', 'MIN valid acc 0.8806')\n",
      "('Epoch 00000040 ', 'test loss 0.6923', 'test acc 0.7709')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6923', 'WORST test acc 0.7324')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6923', 'MIN test acc 0.7324')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3632', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3641', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3540', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3199', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3891', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3052', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3216', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3622', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3743', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3546', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3860', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4097', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3328', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3333', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3596', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3583', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4166', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3957', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3894', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3658', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3728', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3771', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4143', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3814', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4699', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3750', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3783', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4575', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4250', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3761', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3489', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3691', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4163', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3998', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3295', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3237', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3762', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3682', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4698', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3132', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3962', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3215', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3526', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.4238', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3732', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3369', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3715', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4100', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3462', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3613', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3669', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3853', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3715', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3139', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3122', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3809', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4677', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3896', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2855', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3523', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3626', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3096', 'WORST training acc 0.9062')\n",
      "('Epoch 00000050 ', 'avg train loss over', 62, ' batches ', '0.3708', 'avg train acc ', '0.9289')\n",
      "('Epoch 00000050 ', 'valid loss 0.3694', 'valid acc 0.9297')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3694', 'WORST valid acc 0.8726')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3694', 'MIN valid acc 0.8726')\n",
      "('Epoch 00000050 ', 'test loss 0.6330', 'test acc 0.7630')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6330', 'WORST test acc 0.7418')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6330', 'MIN test acc 0.7418')\n",
      "('Epoch 00000060 ', 'avg train loss over', 62, ' batches ', '0.3690', 'avg train acc ', '0.9261')\n",
      "('Epoch 00000060 ', 'valid loss 0.3536', 'valid acc 0.9293')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3536', 'WORST valid acc 0.8837')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3536', 'MIN valid acc 0.8837')\n",
      "('Epoch 00000060 ', 'test loss 0.6573', 'test acc 0.7661')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6573', 'WORST test acc 0.7292')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6573', 'MIN test acc 0.7292')\n",
      "('Epoch 00000070 ', 'avg train loss over', 62, ' batches ', '0.3688', 'avg train acc ', '0.9268')\n",
      "('Epoch 00000070 ', 'valid loss 0.3571', 'valid acc 0.9268')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3571', 'WORST valid acc 0.8746')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3571', 'MIN valid acc 0.8746')\n",
      "('Epoch 00000070 ', 'test loss 0.6726', 'test acc 0.7755')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6726', 'WORST test acc 0.7424')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6726', 'MIN test acc 0.7424')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000080 ', 'avg train loss over', 62, ' batches ', '0.3680', 'avg train acc ', '0.9282')\n",
      "('Epoch 00000080 ', 'valid loss 0.3679', 'valid acc 0.9266')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3679', 'WORST valid acc 0.8776')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3679', 'MIN valid acc 0.8776')\n",
      "('Epoch 00000080 ', 'test loss 0.6414', 'test acc 0.7570')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6414', 'WORST test acc 0.7312')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6414', 'MIN test acc 0.7312')\n",
      "('Epoch 00000090 ', 'avg train loss over', 62, ' batches ', '0.3677', 'avg train acc ', '0.9238')\n",
      "('Epoch 00000090 ', 'valid loss 0.3527', 'valid acc 0.9247')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3527', 'WORST valid acc 0.8696')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3527', 'MIN valid acc 0.8696')\n",
      "('Epoch 00000090 ', 'test loss 0.6561', 'test acc 0.7744')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6561', 'WORST test acc 0.7554')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6015', 'MIN test acc 0.7550')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3087', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3570', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4582', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3549', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.4603', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3062', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3464', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3898', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3231', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3206', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3792', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3784', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3262', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3734', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3659', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3527', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4180', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3851', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4087', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3598', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3538', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4631', 'WORST training acc 0.8125')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3363', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3675', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4248', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4069', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4360', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4182', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3421', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.4381', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.4053', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3965', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3784', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4409', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3660', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3238', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3245', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3702', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4261', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3222', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3765', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3417', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3381', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3680', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3865', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3211', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3441', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3631', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3580', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3615', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3649', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3458', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.4740', 'WORST training acc 0.8281')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3389', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3456', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.4006', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4497', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3659', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.2787', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3309', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3228', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3105', 'WORST training acc 0.9062')\n",
      "('Epoch 00000100 ', 'avg train loss over', 62, ' batches ', '0.3710', 'avg train acc ', '0.9220')\n",
      "('Epoch 00000100 ', 'valid loss 0.3575', 'valid acc 0.9244')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3575', 'WORST valid acc 0.8756')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3575', 'MIN valid acc 0.8756')\n",
      "('Epoch 00000100 ', 'test loss 0.6539', 'test acc 0.7746')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6539', 'WORST test acc 0.7518')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6089', 'MIN test acc 0.7472')\n",
      "===FINAL RESULTS WITH BATCH SIZE 64===\n",
      "('VALID: acc 0.9244', 'accs sd 0.0000', 'loss 0.3575', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7746', 'accs sd 0.0000', 'loss 0.6539', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8756', 'accs sd 0.0000', 'loss 0.3575', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7518', 'accs sd 0.0000', 'loss 0.6539', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8756', 'accs sd 0.0000', 'loss 0.3575', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7472', 'accs sd 0.0000', 'loss 0.6089', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [0]\n",
      "===ITERATION 1===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000010 ', 'avg train loss over', 31, ' batches ', '0.3329', 'avg train acc ', '0.9267')\n",
      "('Epoch 00000010 ', 'valid loss 0.3457', 'valid acc 0.9261')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3457', 'WORST valid acc 0.8857')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3457', 'MIN valid acc 0.8857')\n",
      "('Epoch 00000010 ', 'test loss 0.7023', 'test acc 0.7564')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7023', 'WORST test acc 0.7194')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7023', 'MIN test acc 0.7194')\n",
      "('Epoch 00000020 ', 'avg train loss over', 31, ' batches ', '0.3484', 'avg train acc ', '0.9219')\n",
      "('Epoch 00000020 ', 'valid loss 0.3448', 'valid acc 0.9211')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3448', 'WORST valid acc 0.8867')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3448', 'MIN valid acc 0.8867')\n",
      "('Epoch 00000020 ', 'test loss 0.6980', 'test acc 0.7529')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6980', 'WORST test acc 0.7190')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6980', 'MIN test acc 0.7190')\n",
      "('Epoch 00000030 ', 'avg train loss over', 31, ' batches ', '0.3334', 'avg train acc ', '0.9242')\n",
      "('Epoch 00000030 ', 'valid loss 0.3305', 'valid acc 0.9237')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3305', 'WORST valid acc 0.8867')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3305', 'MIN valid acc 0.8867')\n",
      "('Epoch 00000030 ', 'test loss 0.7334', 'test acc 0.7533')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7334', 'WORST test acc 0.7242')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7334', 'MIN test acc 0.7242')\n",
      "('Epoch 00000040 ', 'avg train loss over', 31, ' batches ', '0.3362', 'avg train acc ', '0.9230')\n",
      "('Epoch 00000040 ', 'valid loss 0.3183', 'valid acc 0.9181')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3183', 'WORST valid acc 0.8907')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3183', 'MIN valid acc 0.8907')\n",
      "('Epoch 00000040 ', 'test loss 0.6887', 'test acc 0.7638')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6887', 'WORST test acc 0.7400')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6222', 'MIN test acc 0.7396')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3025', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3337', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3028', 'WORST training acc 0.9141')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3499', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3160', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.2676', 'WORST training acc 0.9297')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3322', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3388', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4174', 'WORST training acc 0.8516')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.2798', 'WORST training acc 0.9219')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3221', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3529', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4467', 'WORST training acc 0.8438')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3462', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3455', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3505', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3627', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3097', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3248', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3564', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3570', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3346', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3487', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.3610', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3362', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3123', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3039', 'WORST training acc 0.9141')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3120', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3115', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3064', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2990', 'WORST training acc 0.9062')\n",
      "('Epoch 00000050 ', 'avg train loss over', 31, ' batches ', '0.3336', 'avg train acc ', '0.9286')\n",
      "('Epoch 00000050 ', 'valid loss 0.3540', 'valid acc 0.9249')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3540', 'WORST valid acc 0.8786')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3540', 'MIN valid acc 0.8786')\n",
      "('Epoch 00000050 ', 'test loss 0.7086', 'test acc 0.7529')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7086', 'WORST test acc 0.7218')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7086', 'MIN test acc 0.7218')\n",
      "('Epoch 00000060 ', 'avg train loss over', 31, ' batches ', '0.3325', 'avg train acc ', '0.9243')\n",
      "('Epoch 00000060 ', 'valid loss 0.3258', 'valid acc 0.9207')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3258', 'WORST valid acc 0.8927')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3258', 'MIN valid acc 0.8927')\n",
      "('Epoch 00000060 ', 'test loss 0.6882', 'test acc 0.7644')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6882', 'WORST test acc 0.7320')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6882', 'MIN test acc 0.7320')\n",
      "('Epoch 00000070 ', 'avg train loss over', 31, ' batches ', '0.3406', 'avg train acc ', '0.9231')\n",
      "('Epoch 00000070 ', 'valid loss 0.3796', 'valid acc 0.9214')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3796', 'WORST valid acc 0.8676')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3796', 'MIN valid acc 0.8676')\n",
      "('Epoch 00000070 ', 'test loss 0.6909', 'test acc 0.7544')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6909', 'WORST test acc 0.7302')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6768', 'MIN test acc 0.7242')\n",
      "('Epoch 00000080 ', 'avg train loss over', 31, ' batches ', '0.3318', 'avg train acc ', '0.9244')\n",
      "('Epoch 00000080 ', 'valid loss 0.3339', 'valid acc 0.9224')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3339', 'WORST valid acc 0.8887')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3339', 'MIN valid acc 0.8887')\n",
      "('Epoch 00000080 ', 'test loss 0.6698', 'test acc 0.7688')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6698', 'WORST test acc 0.7470')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6271', 'MIN test acc 0.7452')\n",
      "('Epoch 00000090 ', 'avg train loss over', 31, ' batches ', '0.3345', 'avg train acc ', '0.9263')\n",
      "('Epoch 00000090 ', 'valid loss 0.3485', 'valid acc 0.9274')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3485', 'WORST valid acc 0.8867')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3485', 'MIN valid acc 0.8867')\n",
      "('Epoch 00000090 ', 'test loss 0.6904', 'test acc 0.7552')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6904', 'WORST test acc 0.7280')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6904', 'MIN test acc 0.7280')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3097', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.2986', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3013', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.3246', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3223', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.2917', 'WORST training acc 0.9141')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3449', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3054', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.4085', 'WORST training acc 0.8594')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.2994', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3800', 'WORST training acc 0.8672')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3169', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.4099', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3694', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3307', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3156', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3112', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.2959', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3143', 'WORST training acc 0.9141')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3337', 'WORST training acc 0.8984')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3241', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.3687', 'WORST training acc 0.8672')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.3391', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000003 ', 'MAX training loss 0.3499', 'WORST training acc 0.8828')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3259', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3080', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000007 ', 'MAX training loss 0.3059', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.3406', 'WORST training acc 0.8906')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.3763', 'WORST training acc 0.8750')\n",
      "('======WORST TRAINING DOMAIN 00000000 ', 'MAX training loss 0.3064', 'WORST training acc 0.9062')\n",
      "('======WORST TRAINING DOMAIN 00000002 ', 'MAX training loss 0.3376', 'WORST training acc 0.8906')\n",
      "('Epoch 00000100 ', 'avg train loss over', 31, ' batches ', '0.3312', 'avg train acc ', '0.9267')\n",
      "('Epoch 00000100 ', 'valid loss 0.3335', 'valid acc 0.9271')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3335', 'WORST valid acc 0.8937')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3335', 'MIN valid acc 0.8937')\n",
      "('Epoch 00000100 ', 'test loss 0.6868', 'test acc 0.7550')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6868', 'WORST test acc 0.7352')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6868', 'MIN test acc 0.7352')\n",
      "===FINAL RESULTS WITH BATCH SIZE 128===\n",
      "('VALID: acc 0.9271', 'accs sd 0.0000', 'loss 0.3335', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7550', 'accs sd 0.0000', 'loss 0.6868', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.8937', 'accs sd 0.0000', 'loss 0.3335', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7352', 'accs sd 0.0000', 'loss 0.6868', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.8937', 'accs sd 0.0000', 'loss 0.3335', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7352', 'accs sd 0.0000', 'loss 0.6868', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 4, ' batches ', '0.6703', 'avg train acc ', '0.6337')\n",
      "('Epoch 00000010 ', 'valid loss 0.6705', 'valid acc 0.6313')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.6705', 'WORST valid acc 0.6071')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.6705', 'MIN valid acc 0.6071')\n",
      "('Epoch 00000010 ', 'test loss 0.7670', 'test acc 0.5137')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.7670', 'WORST test acc 0.3448')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.7670', 'MIN test acc 0.3448')\n",
      "('Epoch 00000020 ', 'avg train loss over', 4, ' batches ', '0.4151', 'avg train acc ', '0.8758')\n",
      "('Epoch 00000020 ', 'valid loss 0.3965', 'valid acc 0.8799')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.3965', 'WORST valid acc 0.8712')\n",
      "('WORST ACC DOMAIN 00000007 ', 'WORST ACC valid loss 0.3929', 'MIN valid acc 0.8655')\n",
      "('Epoch 00000020 ', 'test loss 0.6739', 'test acc 0.7426')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6739', 'WORST test acc 0.7200')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6047', 'MIN test acc 0.6744')\n",
      "('Epoch 00000030 ', 'avg train loss over', 4, ' batches ', '0.2861', 'avg train acc ', '0.9161')\n",
      "('Epoch 00000030 ', 'valid loss 0.2993', 'valid acc 0.9133')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2993', 'WORST valid acc 0.9015')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2909', 'MIN valid acc 0.9007')\n",
      "('Epoch 00000030 ', 'test loss 0.8252', 'test acc 0.7616')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8252', 'WORST test acc 0.7242')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8252', 'MIN test acc 0.7242')\n",
      "('Epoch 00000040 ', 'avg train loss over', 4, ' batches ', '0.2778', 'avg train acc ', '0.9189')\n",
      "('Epoch 00000040 ', 'valid loss 0.2951', 'valid acc 0.9215')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2951', 'WORST valid acc 0.9057')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2951', 'MIN valid acc 0.9057')\n",
      "('Epoch 00000040 ', 'test loss 0.8012', 'test acc 0.7676')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8012', 'WORST test acc 0.7256')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8012', 'MIN test acc 0.7256')\n",
      "('======WORST TRAINING DOMAIN 00000004 ', 'MAX training loss 0.2616', 'WORST training acc 0.9140')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.2646', 'WORST training acc 0.9200')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.2762', 'WORST training acc 0.9140')\n",
      "('======WORST TRAINING DOMAIN 00000008 ', 'MAX training loss 0.2815', 'WORST training acc 0.9080')\n",
      "('Epoch 00000050 ', 'avg train loss over', 4, ' batches ', '0.2710', 'avg train acc ', '0.9213')\n",
      "('Epoch 00000050 ', 'valid loss 0.3015', 'valid acc 0.9202')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3015', 'WORST valid acc 0.9017')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3015', 'MIN valid acc 0.9017')\n",
      "('Epoch 00000050 ', 'test loss 0.8267', 'test acc 0.7622')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8267', 'WORST test acc 0.7214')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8267', 'MIN test acc 0.7214')\n",
      "('Epoch 00000060 ', 'avg train loss over', 4, ' batches ', '0.2708', 'avg train acc ', '0.9224')\n",
      "('Epoch 00000060 ', 'valid loss 0.3094', 'valid acc 0.9218')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3094', 'WORST valid acc 0.8997')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3094', 'MIN valid acc 0.8997')\n",
      "('Epoch 00000060 ', 'test loss 0.7974', 'test acc 0.7647')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7974', 'WORST test acc 0.7320')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7974', 'MIN test acc 0.7320')\n",
      "('Epoch 00000070 ', 'avg train loss over', 4, ' batches ', '0.2754', 'avg train acc ', '0.9212')\n",
      "('Epoch 00000070 ', 'valid loss 0.3022', 'valid acc 0.9252')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3022', 'WORST valid acc 0.9037')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3022', 'MIN valid acc 0.9037')\n",
      "('Epoch 00000070 ', 'test loss 0.7880', 'test acc 0.7656')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7880', 'WORST test acc 0.7304')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7880', 'MIN test acc 0.7304')\n",
      "('Epoch 00000080 ', 'avg train loss over', 4, ' batches ', '0.2738', 'avg train acc ', '0.9230')\n",
      "('Epoch 00000080 ', 'valid loss 0.2944', 'valid acc 0.9205')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2944', 'WORST valid acc 0.9017')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2944', 'MIN valid acc 0.9017')\n",
      "('Epoch 00000080 ', 'test loss 0.7690', 'test acc 0.7702')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7690', 'WORST test acc 0.7336')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7690', 'MIN test acc 0.7336')\n",
      "('Epoch 00000090 ', 'avg train loss over', 4, ' batches ', '0.2676', 'avg train acc ', '0.9212')\n",
      "('Epoch 00000090 ', 'valid loss 0.2949', 'valid acc 0.9214')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2949', 'WORST valid acc 0.9027')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2949', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000090 ', 'test loss 0.7798', 'test acc 0.7664')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7798', 'WORST test acc 0.7364')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7798', 'MIN test acc 0.7364')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('======WORST TRAINING DOMAIN 00000001 ', 'MAX training loss 0.2606', 'WORST training acc 0.9205')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2633', 'WORST training acc 0.9190')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2750', 'WORST training acc 0.9090')\n",
      "('======WORST TRAINING DOMAIN 00000009 ', 'MAX training loss 0.2742', 'WORST training acc 0.9160')\n",
      "('Epoch 00000100 ', 'avg train loss over', 4, ' batches ', '0.2683', 'avg train acc ', '0.9218')\n",
      "('Epoch 00000100 ', 'valid loss 0.3016', 'valid acc 0.9203')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3016', 'WORST valid acc 0.9007')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3016', 'MIN valid acc 0.9007')\n",
      "('Epoch 00000100 ', 'test loss 0.8051', 'test acc 0.7650')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8051', 'WORST test acc 0.7292')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8051', 'MIN test acc 0.7292')\n",
      "===FINAL RESULTS WITH BATCH SIZE 1000===\n",
      "('VALID: acc 0.9203', 'accs sd 0.0000', 'loss 0.3016', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7650', 'accs sd 0.0000', 'loss 0.8051', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.9007', 'accs sd 0.0000', 'loss 0.3016', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [9]\n",
      "('WORST TEST: acc 0.7292', 'accs sd 0.0000', 'loss 0.8051', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.9007', 'accs sd 0.0000', 'loss 0.3016', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [9]\n",
      "('MIN TEST: acc 0.7292', 'accs sd 0.0000', 'loss 0.8051', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 1, ' batches ', '0.4587', 'avg train acc ', '0.6337')\n",
      "('Epoch 00000010 ', 'valid loss 0.4611', 'valid acc 0.6313')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4611', 'WORST valid acc 0.6071')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.4611', 'MIN valid acc 0.6071')\n",
      "('Epoch 00000010 ', 'test loss 0.6928', 'test acc 0.5137')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6928', 'WORST test acc 0.3616')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6560', 'MIN test acc 0.3448')\n",
      "('Epoch 00000020 ', 'avg train loss over', 1, ' batches ', '0.3446', 'avg train acc ', '0.9155')\n",
      "('Epoch 00000020 ', 'valid loss 0.3581', 'valid acc 0.9145')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3581', 'WORST valid acc 0.8947')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3581', 'MIN valid acc 0.8947')\n",
      "('Epoch 00000020 ', 'test loss 0.6174', 'test acc 0.7607')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6174', 'WORST test acc 0.7214')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6174', 'MIN test acc 0.7214')\n",
      "('Epoch 00000030 ', 'avg train loss over', 1, ' batches ', '0.2888', 'avg train acc ', '0.9203')\n",
      "('Epoch 00000030 ', 'valid loss 0.3067', 'valid acc 0.9212')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.3067', 'WORST valid acc 0.9062')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2992', 'MIN valid acc 0.8997')\n",
      "('Epoch 00000030 ', 'test loss 0.6492', 'test acc 0.7707')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6492', 'WORST test acc 0.7344')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6492', 'MIN test acc 0.7344')\n",
      "('Epoch 00000040 ', 'avg train loss over', 1, ' batches ', '0.2659', 'avg train acc ', '0.9193')\n",
      "('Epoch 00000040 ', 'valid loss 0.2850', 'valid acc 0.9197')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2850', 'WORST valid acc 0.9053')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2842', 'MIN valid acc 0.9017')\n",
      "('Epoch 00000040 ', 'test loss 0.6703', 'test acc 0.7741')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6703', 'WORST test acc 0.7436')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5711', 'MIN test acc 0.7416')\n",
      "('======WORST TRAINING DOMAIN 00000005 ', 'MAX training loss 0.2565', 'WORST training acc 0.9195')\n",
      "('Epoch 00000050 ', 'avg train loss over', 1, ' batches ', '0.2565', 'avg train acc ', '0.9208')\n",
      "('Epoch 00000050 ', 'valid loss 0.2797', 'valid acc 0.9232')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2797', 'WORST valid acc 0.9081')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.2797', 'MIN valid acc 0.9081')\n",
      "('Epoch 00000050 ', 'test loss 0.7072', 'test acc 0.7728')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7072', 'WORST test acc 0.7414')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7072', 'MIN test acc 0.7414')\n",
      "('Epoch 00000060 ', 'avg train loss over', 1, ' batches ', '0.2517', 'avg train acc ', '0.9209')\n",
      "('Epoch 00000060 ', 'valid loss 0.2759', 'valid acc 0.9234')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2759', 'WORST valid acc 0.9091')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2727', 'MIN valid acc 0.9077')\n",
      "('Epoch 00000060 ', 'test loss 0.7294', 'test acc 0.7715')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7294', 'WORST test acc 0.7372')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7294', 'MIN test acc 0.7372')\n",
      "('Epoch 00000070 ', 'avg train loss over', 1, ' batches ', '0.2606', 'avg train acc ', '0.9252')\n",
      "('Epoch 00000070 ', 'valid loss 0.2885', 'valid acc 0.9268')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2885', 'WORST valid acc 0.9027')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2885', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000070 ', 'test loss 0.7237', 'test acc 0.7714')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7237', 'WORST test acc 0.7440')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7237', 'MIN test acc 0.7440')\n",
      "('Epoch 00000080 ', 'avg train loss over', 1, ' batches ', '0.2546', 'avg train acc ', '0.9187')\n",
      "('Epoch 00000080 ', 'valid loss 0.2850', 'valid acc 0.9194')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2850', 'WORST valid acc 0.9034')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.2850', 'MIN valid acc 0.9034')\n",
      "('Epoch 00000080 ', 'test loss 0.7269', 'test acc 0.7733')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7269', 'WORST test acc 0.7414')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7269', 'MIN test acc 0.7414')\n",
      "('Epoch 00000090 ', 'avg train loss over', 1, ' batches ', '0.2529', 'avg train acc ', '0.9247')\n",
      "('Epoch 00000090 ', 'valid loss 0.2793', 'valid acc 0.9262')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2793', 'WORST valid acc 0.9037')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2793', 'MIN valid acc 0.9037')\n",
      "('Epoch 00000090 ', 'test loss 0.7350', 'test acc 0.7695')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7350', 'WORST test acc 0.7382')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7350', 'MIN test acc 0.7382')\n",
      "('======WORST TRAINING DOMAIN 00000006 ', 'MAX training loss 0.2501', 'WORST training acc 0.9202')\n",
      "('Epoch 00000100 ', 'avg train loss over', 1, ' batches ', '0.2501', 'avg train acc ', '0.9213')\n",
      "('Epoch 00000100 ', 'valid loss 0.2796', 'valid acc 0.9227')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2796', 'WORST valid acc 0.9053')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.2796', 'MIN valid acc 0.9053')\n",
      "('Epoch 00000100 ', 'test loss 0.7431', 'test acc 0.7723')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7431', 'WORST test acc 0.7378')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7431', 'MIN test acc 0.7378')\n",
      "===FINAL RESULTS WITH BATCH SIZE 4000===\n",
      "('VALID: acc 0.9227', 'accs sd 0.0000', 'loss 0.2796', 'loss sd 0.0000')\n",
      "('TEST: acc 0.7723', 'accs sd 0.0000', 'loss 0.7431', 'loss sd 0.0000')\n",
      "('WORST VALID: acc 0.9053', 'accs sd 0.0000', 'loss 0.2796', 'loss sd 0.0000')\n",
      "WORST VALID DOMAINS: [8]\n",
      "('WORST TEST: acc 0.7378', 'accs sd 0.0000', 'loss 0.7431', 'loss sd 0.0000')\n",
      "WORST TEST DOMAINS: [2]\n",
      "('MIN VALID: acc 0.9053', 'accs sd 0.0000', 'loss 0.2796', 'loss sd 0.0000')\n",
      "MIN VALID DOMAINS: [8]\n",
      "('MIN TEST: acc 0.7378', 'accs sd 0.0000', 'loss 0.7431', 'loss sd 0.0000')\n",
      "MIN TEST DOMAINS: [2]\n"
     ]
    }
   ],
   "source": [
    "num_trials = 1\n",
    "\n",
    "for loss in [True, False]:\n",
    "    if loss:\n",
    "        print(\"===AVERAGE LOSS FUNCTION===\")\n",
    "    else:\n",
    "        print(\"===MAXIMUM LOSS FUNCTION===\")\n",
    "\n",
    "    for b in [5, 32, 64, 128, 1000, 4000]:\n",
    "        v_accs = []\n",
    "        v_ls = []\n",
    "        t_accs = []\n",
    "        t_ls = []\n",
    "        worst_v_accs = []\n",
    "        worst_v_ls = []\n",
    "        worst_v_domains = []\n",
    "        worst_t_accs = []\n",
    "        worst_t_ls = []\n",
    "        worst_t_domains = []\n",
    "        \n",
    "        min_v_accs = []\n",
    "        worst_v_accs_ls = []\n",
    "        worst_v_acc_domains = []\n",
    "        min_t_accs = []\n",
    "        worst_t_accs_ls = []\n",
    "        worst_t_acc_domains = []\n",
    "\n",
    "        for i in range(1, num_trials+1):\n",
    "            print(\"===ITERATION %d===\" % i)\n",
    "            results = run_experiment(1, 1, avg_loss=loss, training_epochs=100, b=b)\n",
    "\n",
    "            v_accs.append(results[0])\n",
    "            v_ls.append(results[1])\n",
    "            t_accs.append(results[2])\n",
    "            t_ls.append(results[3])\n",
    "            \n",
    "            worst_v_accs.append(results[4])\n",
    "            worst_v_ls.append(results[5])\n",
    "            worst_v_domains.append(results[6])\n",
    "            worst_t_accs.append(results[7])\n",
    "            worst_t_ls.append(results[8])\n",
    "            worst_t_domains.append(results[9])\n",
    "            \n",
    "            min_v_accs.append(results[10])\n",
    "            worst_v_accs_ls.append(results[11])\n",
    "            worst_v_acc_domains.append(results[12])\n",
    "            min_t_accs.append(results[13])\n",
    "            worst_t_accs_ls.append(results[14])\n",
    "            worst_t_acc_domains.append(results[15])\n",
    "\n",
    "        print(\"===FINAL RESULTS WITH BATCH SIZE %d===\" % b)\n",
    "        print (\"VALID: acc %.4f\" % np.average(v_accs), \"accs sd %.4f\" % np.std(v_accs), \"loss %.4f\" % np.average(v_ls), \"loss sd %.4f\" % np.std(v_ls))\n",
    "        print (\"TEST: acc %.4f\" % np.average(t_accs), \"accs sd %.4f\" % np.std(t_accs), \"loss %.4f\" % np.average(t_ls), \"loss sd %.4f\" % np.std(t_ls))\n",
    "        \n",
    "        print (\"WORST VALID: acc %.4f\" % np.average(worst_v_accs), \"accs sd %.4f\" % np.std(worst_v_accs), \"loss %.4f\" % np.average(worst_v_ls), \"loss sd %.4f\" % np.std(worst_v_ls))\n",
    "        print (\"WORST VALID DOMAINS: \" + str(worst_v_domains))\n",
    "        print (\"WORST TEST: acc %.4f\" % np.average(worst_t_accs), \"accs sd %.4f\" % np.std(worst_t_accs), \"loss %.4f\" % np.average(worst_t_ls), \"loss sd %.4f\" % np.std(worst_t_ls))\n",
    "        print (\"WORST TEST DOMAINS: \" + str(worst_t_domains))\n",
    "        \n",
    "        print (\"MIN VALID: acc %.4f\" % np.average(min_v_accs), \"accs sd %.4f\" % np.std(min_v_accs), \"loss %.4f\" % np.average(worst_v_accs_ls), \"loss sd %.4f\" % np.std(worst_v_accs_ls))\n",
    "        print (\"MIN VALID DOMAINS: \" + str(worst_v_acc_domains))\n",
    "        print (\"MIN TEST: acc %.4f\" % np.average(min_t_accs), \"accs sd %.4f\" % np.std(min_t_accs), \"loss %.4f\" % np.average(worst_t_accs_ls), \"loss sd %.4f\" % np.std(worst_t_accs_ls))\n",
    "        print (\"MIN TEST DOMAINS: \" + str(worst_t_acc_domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===AVERAGE LOSS FUNCTION===\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2850', 'avg train acc ', '0.9142')\n",
      "('Epoch 00000010 ', 'valid loss 0.2792', 'valid acc 0.9172')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2943', 'WORST valid acc 0.9133')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2927', 'MIN valid acc 0.9077')\n",
      "('Epoch 00000010 ', 'test loss 0.6679', 'test acc 0.7666')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8265', 'WORST test acc 0.7262')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8265', 'MIN test acc 0.7262')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2880', 'avg train acc ', '0.9117')\n",
      "('Epoch 00000020 ', 'valid loss 0.2867', 'valid acc 0.9071')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3171', 'WORST valid acc 0.8977')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3171', 'MIN valid acc 0.8977')\n",
      "('Epoch 00000020 ', 'test loss 0.6787', 'test acc 0.7679')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8769', 'WORST test acc 0.7296')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8769', 'MIN test acc 0.7296')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2915', 'avg train acc ', '0.9092')\n",
      "('Epoch 00000030 ', 'valid loss 0.2843', 'valid acc 0.9114')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.3036', 'WORST valid acc 0.8987')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.3036', 'MIN valid acc 0.8987')\n",
      "('Epoch 00000030 ', 'test loss 0.6345', 'test acc 0.7850')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8197', 'WORST test acc 0.7386')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8197', 'MIN test acc 0.7386')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2858', 'avg train acc ', '0.9148')\n",
      "('Epoch 00000040 ', 'valid loss 0.2803', 'valid acc 0.9152')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3220', 'WORST valid acc 0.9027')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3220', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000040 ', 'test loss 0.6626', 'test acc 0.7717')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8475', 'WORST test acc 0.7308')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8475', 'MIN test acc 0.7308')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2853', 'avg train acc ', '0.9130')\n",
      "('Epoch 00000050 ', 'valid loss 0.2773', 'valid acc 0.9153')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3349', 'WORST valid acc 0.8806')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3349', 'MIN valid acc 0.8806')\n",
      "('Epoch 00000050 ', 'test loss 0.6395', 'test acc 0.7815')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7786', 'WORST test acc 0.7522')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7786', 'MIN test acc 0.7522')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2849', 'avg train acc ', '0.9136')\n",
      "('Epoch 00000010 ', 'valid loss 0.2779', 'valid acc 0.9204')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2991', 'WORST valid acc 0.9127')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2972', 'MIN valid acc 0.9107')\n",
      "('Epoch 00000010 ', 'test loss 0.6828', 'test acc 0.7540')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7823', 'WORST test acc 0.7260')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7823', 'MIN test acc 0.7260')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2917', 'avg train acc ', '0.9099')\n",
      "('Epoch 00000020 ', 'valid loss 0.2851', 'valid acc 0.9169')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3152', 'WORST valid acc 0.9047')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3152', 'MIN valid acc 0.9047')\n",
      "('Epoch 00000020 ', 'test loss 0.6193', 'test acc 0.7878')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7628', 'WORST test acc 0.7552')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7628', 'MIN test acc 0.7552')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2970', 'avg train acc ', '0.9121')\n",
      "('Epoch 00000030 ', 'valid loss 0.2846', 'valid acc 0.9173')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3126', 'WORST valid acc 0.9058')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3126', 'MIN valid acc 0.9058')\n",
      "('Epoch 00000030 ', 'test loss 0.6542', 'test acc 0.7686')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.7401', 'WORST test acc 0.7338')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7401', 'MIN test acc 0.7338')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2876', 'avg train acc ', '0.9135')\n",
      "('Epoch 00000040 ', 'valid loss 0.2715', 'valid acc 0.9222')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3315', 'WORST valid acc 0.8937')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3315', 'MIN valid acc 0.8937')\n",
      "('Epoch 00000040 ', 'test loss 0.6941', 'test acc 0.7529')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8143', 'WORST test acc 0.7204')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8143', 'MIN test acc 0.7204')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2871', 'avg train acc ', '0.9095')\n",
      "('Epoch 00000050 ', 'valid loss 0.2816', 'valid acc 0.9118')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3012', 'WORST valid acc 0.9047')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2986', 'MIN valid acc 0.8987')\n",
      "('Epoch 00000050 ', 'test loss 0.6409', 'test acc 0.7850')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8033', 'WORST test acc 0.7512')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8033', 'MIN test acc 0.7512')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2889', 'avg train acc ', '0.9123')\n",
      "('Epoch 00000010 ', 'valid loss 0.2749', 'valid acc 0.9222')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2938', 'WORST valid acc 0.9137')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2938', 'MIN valid acc 0.9137')\n",
      "('Epoch 00000010 ', 'test loss 0.6280', 'test acc 0.7849')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7130', 'WORST test acc 0.7674')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6383', 'MIN test acc 0.7624')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2824', 'avg train acc ', '0.9155')\n",
      "('Epoch 00000020 ', 'valid loss 0.2812', 'valid acc 0.9182')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3291', 'WORST valid acc 0.8987')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3291', 'MIN valid acc 0.8987')\n",
      "('Epoch 00000020 ', 'test loss 0.6731', 'test acc 0.7656')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7656', 'WORST test acc 0.7414')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7656', 'MIN test acc 0.7414')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2879', 'avg train acc ', '0.9139')\n",
      "('Epoch 00000030 ', 'valid loss 0.2806', 'valid acc 0.9161')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.3163', 'WORST valid acc 0.8957')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.3163', 'MIN valid acc 0.8957')\n",
      "('Epoch 00000030 ', 'test loss 0.6672', 'test acc 0.7729')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8692', 'WORST test acc 0.7218')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8692', 'MIN test acc 0.7218')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2897', 'avg train acc ', '0.9144')\n",
      "('Epoch 00000040 ', 'valid loss 0.2769', 'valid acc 0.9199')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3049', 'WORST valid acc 0.9117')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3035', 'MIN valid acc 0.9111')\n",
      "('Epoch 00000040 ', 'test loss 0.6392', 'test acc 0.7801')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7798', 'WORST test acc 0.7454')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7798', 'MIN test acc 0.7454')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2826', 'avg train acc ', '0.9171')\n",
      "('Epoch 00000050 ', 'valid loss 0.2736', 'valid acc 0.9228')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3206', 'WORST valid acc 0.9037')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3206', 'MIN valid acc 0.9037')\n",
      "('Epoch 00000050 ', 'test loss 0.6606', 'test acc 0.7692')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7825', 'WORST test acc 0.7370')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7825', 'MIN test acc 0.7370')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2889', 'avg train acc ', '0.9144')\n",
      "('Epoch 00000010 ', 'valid loss 0.2780', 'valid acc 0.9182')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3148', 'WORST valid acc 0.8997')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3148', 'MIN valid acc 0.8997')\n",
      "('Epoch 00000010 ', 'test loss 0.6658', 'test acc 0.7730')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7998', 'WORST test acc 0.7494')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7007', 'MIN test acc 0.7436')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2860', 'avg train acc ', '0.9144')\n",
      "('Epoch 00000020 ', 'valid loss 0.2788', 'valid acc 0.9169')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3180', 'WORST valid acc 0.9028')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3180', 'MIN valid acc 0.9028')\n",
      "('Epoch 00000020 ', 'test loss 0.7100', 'test acc 0.7595')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9533', 'WORST test acc 0.7176')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9533', 'MIN test acc 0.7176')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2860', 'avg train acc ', '0.9117')\n",
      "('Epoch 00000030 ', 'valid loss 0.2749', 'valid acc 0.9211')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3059', 'WORST valid acc 0.9087')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3059', 'MIN valid acc 0.9087')\n",
      "('Epoch 00000030 ', 'test loss 0.6337', 'test acc 0.7832')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8096', 'WORST test acc 0.7404')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8096', 'MIN test acc 0.7404')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2827', 'avg train acc ', '0.9172')\n",
      "('Epoch 00000040 ', 'valid loss 0.2682', 'valid acc 0.9238')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3069', 'WORST valid acc 0.9101')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3069', 'MIN valid acc 0.9101')\n",
      "('Epoch 00000040 ', 'test loss 0.6502', 'test acc 0.7696')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7998', 'WORST test acc 0.7236')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7998', 'MIN test acc 0.7236')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2829', 'avg train acc ', '0.9145')\n",
      "('Epoch 00000050 ', 'valid loss 0.2756', 'valid acc 0.9189')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3193', 'WORST valid acc 0.8997')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3193', 'MIN valid acc 0.8997')\n",
      "('Epoch 00000050 ', 'test loss 0.6783', 'test acc 0.7704')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8394', 'WORST test acc 0.7330')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8394', 'MIN test acc 0.7330')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2894', 'avg train acc ', '0.9123')\n",
      "('Epoch 00000010 ', 'valid loss 0.2898', 'valid acc 0.9148')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3259', 'WORST valid acc 0.8930')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3259', 'MIN valid acc 0.8930')\n",
      "('Epoch 00000010 ', 'test loss 0.6822', 'test acc 0.7658')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8561', 'WORST test acc 0.7300')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8561', 'MIN test acc 0.7300')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2873', 'avg train acc ', '0.9133')\n",
      "('Epoch 00000020 ', 'valid loss 0.2879', 'valid acc 0.9111')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3531', 'WORST valid acc 0.8837')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3531', 'MIN valid acc 0.8837')\n",
      "('Epoch 00000020 ', 'test loss 0.6174', 'test acc 0.7876')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7906', 'WORST test acc 0.7492')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7906', 'MIN test acc 0.7492')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2887', 'avg train acc ', '0.9125')\n",
      "('Epoch 00000030 ', 'valid loss 0.2822', 'valid acc 0.9161')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2902', 'WORST valid acc 0.9087')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2877', 'MIN valid acc 0.9077')\n",
      "('Epoch 00000030 ', 'test loss 0.6871', 'test acc 0.7664')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8940', 'WORST test acc 0.7234')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8940', 'MIN test acc 0.7234')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2817', 'avg train acc ', '0.9174')\n",
      "('Epoch 00000040 ', 'valid loss 0.2752', 'valid acc 0.9206')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3024', 'WORST valid acc 0.9057')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3024', 'MIN valid acc 0.9057')\n",
      "('Epoch 00000040 ', 'test loss 0.6799', 'test acc 0.7620')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8403', 'WORST test acc 0.7202')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8403', 'MIN test acc 0.7202')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2811', 'avg train acc ', '0.9183')\n",
      "('Epoch 00000050 ', 'valid loss 0.2710', 'valid acc 0.9219')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3253', 'WORST valid acc 0.8957')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3253', 'MIN valid acc 0.8957')\n",
      "('Epoch 00000050 ', 'test loss 0.6427', 'test acc 0.7784')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7945', 'WORST test acc 0.7418')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7945', 'MIN test acc 0.7418')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2928', 'avg train acc ', '0.9072')\n",
      "('Epoch 00000010 ', 'valid loss 0.2928', 'valid acc 0.9099')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3415', 'WORST valid acc 0.8847')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3415', 'MIN valid acc 0.8847')\n",
      "('Epoch 00000010 ', 'test loss 0.7204', 'test acc 0.7525')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.8513', 'WORST test acc 0.7580')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7351', 'MIN test acc 0.7316')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2872', 'avg train acc ', '0.9149')\n",
      "('Epoch 00000020 ', 'valid loss 0.2747', 'valid acc 0.9223')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2901', 'WORST valid acc 0.9176')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2901', 'MIN valid acc 0.9176')\n",
      "('Epoch 00000020 ', 'test loss 0.6628', 'test acc 0.7667')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8011', 'WORST test acc 0.7350')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7054', 'MIN test acc 0.7348')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2995', 'avg train acc ', '0.9047')\n",
      "('Epoch 00000030 ', 'valid loss 0.2872', 'valid acc 0.9130')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3434', 'WORST valid acc 0.8867')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3434', 'MIN valid acc 0.8867')\n",
      "('Epoch 00000030 ', 'test loss 0.6469', 'test acc 0.7675')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8067', 'WORST test acc 0.7464')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7161', 'MIN test acc 0.7184')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2901', 'avg train acc ', '0.9120')\n",
      "('Epoch 00000040 ', 'valid loss 0.2725', 'valid acc 0.9208')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2966', 'WORST valid acc 0.9107')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2966', 'MIN valid acc 0.9107')\n",
      "('Epoch 00000040 ', 'test loss 0.6516', 'test acc 0.7750')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8757', 'WORST test acc 0.7242')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8757', 'MIN test acc 0.7242')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2840', 'avg train acc ', '0.9139')\n",
      "('Epoch 00000050 ', 'valid loss 0.2816', 'valid acc 0.9164')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3189', 'WORST valid acc 0.8927')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3189', 'MIN valid acc 0.8927')\n",
      "('Epoch 00000050 ', 'test loss 0.6484', 'test acc 0.7740')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8019', 'WORST test acc 0.7378')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8019', 'MIN test acc 0.7378')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2831', 'avg train acc ', '0.9147')\n",
      "('Epoch 00000010 ', 'valid loss 0.2773', 'valid acc 0.9197')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3174', 'WORST valid acc 0.9027')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3174', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000010 ', 'test loss 0.6789', 'test acc 0.7620')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8337', 'WORST test acc 0.7296')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8337', 'MIN test acc 0.7296')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2967', 'avg train acc ', '0.9064')\n",
      "('Epoch 00000020 ', 'valid loss 0.3008', 'valid acc 0.9042')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3481', 'WORST valid acc 0.8766')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3481', 'MIN valid acc 0.8766')\n",
      "('Epoch 00000020 ', 'test loss 0.7719', 'test acc 0.7310')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9824', 'WORST test acc 0.6892')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9824', 'MIN test acc 0.6892')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2843', 'avg train acc ', '0.9156')\n",
      "('Epoch 00000030 ', 'valid loss 0.2711', 'valid acc 0.9210')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2888', 'WORST valid acc 0.9157')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2888', 'MIN valid acc 0.9157')\n",
      "('Epoch 00000030 ', 'test loss 0.6657', 'test acc 0.7734')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8325', 'WORST test acc 0.7334')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8325', 'MIN test acc 0.7334')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2914', 'avg train acc ', '0.9125')\n",
      "('Epoch 00000040 ', 'valid loss 0.2615', 'valid acc 0.9260')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.2979', 'WORST valid acc 0.9087')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2979', 'MIN valid acc 0.9087')\n",
      "('Epoch 00000040 ', 'test loss 0.6316', 'test acc 0.7880')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7924', 'WORST test acc 0.7504')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7924', 'MIN test acc 0.7504')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2943', 'avg train acc ', '0.9065')\n",
      "('Epoch 00000050 ', 'valid loss 0.2809', 'valid acc 0.9187')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3102', 'WORST valid acc 0.9027')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3102', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000050 ', 'test loss 0.6104', 'test acc 0.7903')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6905', 'WORST test acc 0.7752')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6573', 'MIN test acc 0.7568')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2993', 'avg train acc ', '0.9076')\n",
      "('Epoch 00000010 ', 'valid loss 0.2895', 'valid acc 0.9118')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3617', 'WORST valid acc 0.8746')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3617', 'MIN valid acc 0.8746')\n",
      "('Epoch 00000010 ', 'test loss 0.6638', 'test acc 0.7738')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.7498', 'WORST test acc 0.7864')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6886', 'MIN test acc 0.7448')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2913', 'avg train acc ', '0.9138')\n",
      "('Epoch 00000020 ', 'valid loss 0.2947', 'valid acc 0.9105')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3421', 'WORST valid acc 0.8862')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3421', 'MIN valid acc 0.8862')\n",
      "('Epoch 00000020 ', 'test loss 0.6981', 'test acc 0.7670')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9187', 'WORST test acc 0.7218')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9187', 'MIN test acc 0.7218')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2965', 'avg train acc ', '0.9094')\n",
      "('Epoch 00000030 ', 'valid loss 0.2961', 'valid acc 0.9056')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3248', 'WORST valid acc 0.8766')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3248', 'MIN valid acc 0.8766')\n",
      "('Epoch 00000030 ', 'test loss 0.7107', 'test acc 0.7594')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9148', 'WORST test acc 0.7124')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9148', 'MIN test acc 0.7124')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2853', 'avg train acc ', '0.9154')\n",
      "('Epoch 00000040 ', 'valid loss 0.2800', 'valid acc 0.9187')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3415', 'WORST valid acc 0.8887')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3415', 'MIN valid acc 0.8887')\n",
      "('Epoch 00000040 ', 'test loss 0.6000', 'test acc 0.7885')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.6424', 'WORST test acc 0.7620')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6424', 'MIN test acc 0.7620')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2834', 'avg train acc ', '0.9148')\n",
      "('Epoch 00000050 ', 'valid loss 0.2738', 'valid acc 0.9192')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3132', 'WORST valid acc 0.9017')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3132', 'MIN valid acc 0.9017')\n",
      "('Epoch 00000050 ', 'test loss 0.6538', 'test acc 0.7766')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8239', 'WORST test acc 0.7380')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8239', 'MIN test acc 0.7380')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2931', 'avg train acc ', '0.9129')\n",
      "('Epoch 00000010 ', 'valid loss 0.2933', 'valid acc 0.9153')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3268', 'WORST valid acc 0.9028')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3268', 'MIN valid acc 0.9028')\n",
      "('Epoch 00000010 ', 'test loss 0.6735', 'test acc 0.7622')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7986', 'WORST test acc 0.7248')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7986', 'MIN test acc 0.7248')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2933', 'avg train acc ', '0.9090')\n",
      "('Epoch 00000020 ', 'valid loss 0.2937', 'valid acc 0.9085')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3368', 'WORST valid acc 0.8776')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3368', 'MIN valid acc 0.8776')\n",
      "('Epoch 00000020 ', 'test loss 0.6739', 'test acc 0.7789')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8779', 'WORST test acc 0.7382')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8779', 'MIN test acc 0.7382')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2934', 'avg train acc ', '0.9116')\n",
      "('Epoch 00000030 ', 'valid loss 0.2894', 'valid acc 0.9165')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3196', 'WORST valid acc 0.9082')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3035', 'MIN valid acc 0.9057')\n",
      "('Epoch 00000030 ', 'test loss 0.6237', 'test acc 0.7851')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7446', 'WORST test acc 0.7592')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7446', 'MIN test acc 0.7592')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2914', 'avg train acc ', '0.9119')\n",
      "('Epoch 00000040 ', 'valid loss 0.2846', 'valid acc 0.9164')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3123', 'WORST valid acc 0.8947')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3123', 'MIN valid acc 0.8947')\n",
      "('Epoch 00000040 ', 'test loss 0.7167', 'test acc 0.7571')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8900', 'WORST test acc 0.7184')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8900', 'MIN test acc 0.7184')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2897', 'avg train acc ', '0.9130')\n",
      "('Epoch 00000050 ', 'valid loss 0.2851', 'valid acc 0.9148')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.3059', 'WORST valid acc 0.9100')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3030', 'MIN valid acc 0.9097')\n",
      "('Epoch 00000050 ', 'test loss 0.5825', 'test acc 0.8026')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7503', 'WORST test acc 0.7622')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7503', 'MIN test acc 0.7622')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2865', 'avg train acc ', '0.9148')\n",
      "('Epoch 00000010 ', 'valid loss 0.2689', 'valid acc 0.9239')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3136', 'WORST valid acc 0.9027')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3136', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000010 ', 'test loss 0.6330', 'test acc 0.7814')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7546', 'WORST test acc 0.7490')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7546', 'MIN test acc 0.7490')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2859', 'avg train acc ', '0.9168')\n",
      "('Epoch 00000020 ', 'valid loss 0.2818', 'valid acc 0.9187')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3250', 'WORST valid acc 0.9038')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3250', 'MIN valid acc 0.9038')\n",
      "('Epoch 00000020 ', 'test loss 0.7158', 'test acc 0.7578')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8551', 'WORST test acc 0.7240')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8551', 'MIN test acc 0.7240')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2829', 'avg train acc ', '0.9155')\n",
      "('Epoch 00000030 ', 'valid loss 0.2715', 'valid acc 0.9207')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2940', 'WORST valid acc 0.9147')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2927', 'MIN valid acc 0.9103')\n",
      "('Epoch 00000030 ', 'test loss 0.6750', 'test acc 0.7773')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8348', 'WORST test acc 0.7452')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8348', 'MIN test acc 0.7452')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2890', 'avg train acc ', '0.9136')\n",
      "('Epoch 00000040 ', 'valid loss 0.2918', 'valid acc 0.9117')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3385', 'WORST valid acc 0.8877')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3385', 'MIN valid acc 0.8877')\n",
      "('Epoch 00000040 ', 'test loss 0.5943', 'test acc 0.7973')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7351', 'WORST test acc 0.7692')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6417', 'MIN test acc 0.7628')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2811', 'avg train acc ', '0.9140')\n",
      "('Epoch 00000050 ', 'valid loss 0.2706', 'valid acc 0.9204')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3167', 'WORST valid acc 0.9007')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3167', 'MIN valid acc 0.9007')\n",
      "('Epoch 00000050 ', 'test loss 0.6778', 'test acc 0.7772')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8403', 'WORST test acc 0.7412')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8403', 'MIN test acc 0.7412')\n",
      "===FINAL RESULTS WITH NODE 1===\n",
      "('VALID: acc 0.9180', 'accs sd 0.0032', 'loss 0.2771', 'loss sd 0.0047')\n",
      "('TEST: acc 0.7805', 'accs sd 0.0095', 'loss 0.6435', 'loss sd 0.0277')\n",
      "('WORST VALID: acc 0.8992', 'accs sd 0.0077', 'loss 0.3166', 'loss sd 0.0092')\n",
      "WORST VALID DOMAINS: [9, 3, 9, 9, 9, 9, 9, 9, 8, 9]\n",
      "('WORST TEST: acc 0.7470', 'accs sd 0.0126', 'loss 0.7905', 'loss sd 0.0426')\n",
      "WORST TEST DOMAINS: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "('MIN VALID: acc 0.8986', 'accs sd 0.0074', 'loss 0.3161', 'loss sd 0.0100')\n",
      "MIN VALID DOMAINS: [9, 0, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "('MIN TEST: acc 0.7451', 'accs sd 0.0093', 'loss 0.7872', 'loss sd 0.0507')\n",
      "MIN TEST DOMAINS: [2, 2, 2, 2, 2, 2, 1, 2, 2, 2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1950', 'avg train acc ', '0.9490')\n",
      "('Epoch 00000010 ', 'valid loss 0.1890', 'valid acc 0.9512')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2344', 'WORST valid acc 0.9370')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2344', 'MIN valid acc 0.9370')\n",
      "('Epoch 00000010 ', 'test loss 0.9120', 'test acc 0.7453')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0827', 'WORST test acc 0.7206')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0827', 'MIN test acc 0.7206')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1814', 'avg train acc ', '0.9543')\n",
      "('Epoch 00000020 ', 'valid loss 0.1937', 'valid acc 0.9504')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2408', 'WORST valid acc 0.9352')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2408', 'MIN valid acc 0.9352')\n",
      "('Epoch 00000020 ', 'test loss 0.8799', 'test acc 0.7481')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0775', 'WORST test acc 0.7038')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0775', 'MIN test acc 0.7038')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1862', 'avg train acc ', '0.9523')\n",
      "('Epoch 00000030 ', 'valid loss 0.1861', 'valid acc 0.9501')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2751', 'WORST valid acc 0.9218')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2751', 'MIN valid acc 0.9218')\n",
      "('Epoch 00000030 ', 'test loss 0.8796', 'test acc 0.7678')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1302', 'WORST test acc 0.7220')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1302', 'MIN test acc 0.7220')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1923', 'avg train acc ', '0.9500')\n",
      "('Epoch 00000040 ', 'valid loss 0.1903', 'valid acc 0.9491')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2693', 'WORST valid acc 0.9225')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2693', 'MIN valid acc 0.9225')\n",
      "('Epoch 00000040 ', 'test loss 0.8290', 'test acc 0.7722')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0290', 'WORST test acc 0.7370')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0290', 'MIN test acc 0.7370')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1905', 'avg train acc ', '0.9511')\n",
      "('Epoch 00000050 ', 'valid loss 0.1873', 'valid acc 0.9527')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2521', 'WORST valid acc 0.9317')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2521', 'MIN valid acc 0.9317')\n",
      "('Epoch 00000050 ', 'test loss 0.8666', 'test acc 0.7622')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0579', 'WORST test acc 0.7288')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0579', 'MIN test acc 0.7288')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1916', 'avg train acc ', '0.9498')\n",
      "('Epoch 00000010 ', 'valid loss 0.1956', 'valid acc 0.9491')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2582', 'WORST valid acc 0.9293')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2582', 'MIN valid acc 0.9293')\n",
      "('Epoch 00000010 ', 'test loss 0.8167', 'test acc 0.7680')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1112', 'WORST test acc 0.7112')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1112', 'MIN test acc 0.7112')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1896', 'avg train acc ', '0.9504')\n",
      "('Epoch 00000020 ', 'valid loss 0.1955', 'valid acc 0.9485')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2598', 'WORST valid acc 0.9267')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2598', 'MIN valid acc 0.9267')\n",
      "('Epoch 00000020 ', 'test loss 0.7809', 'test acc 0.7818')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0901', 'WORST test acc 0.7144')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0901', 'MIN test acc 0.7144')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1972', 'avg train acc ', '0.9450')\n",
      "('Epoch 00000030 ', 'valid loss 0.1947', 'valid acc 0.9447')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2809', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2809', 'MIN valid acc 0.9136')\n",
      "('Epoch 00000030 ', 'test loss 0.7562', 'test acc 0.7839')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9924', 'WORST test acc 0.7408')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.7095', 'MIN test acc 0.7394')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1869', 'avg train acc ', '0.9509')\n",
      "('Epoch 00000040 ', 'valid loss 0.2029', 'valid acc 0.9383')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3044', 'WORST valid acc 0.8989')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3044', 'MIN valid acc 0.8989')\n",
      "('Epoch 00000040 ', 'test loss 0.7796', 'test acc 0.7678')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0092', 'WORST test acc 0.7268')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.7235', 'MIN test acc 0.7064')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1937', 'avg train acc ', '0.9484')\n",
      "('Epoch 00000050 ', 'valid loss 0.1907', 'valid acc 0.9510')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2425', 'WORST valid acc 0.9350')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2384', 'MIN valid acc 0.9346')\n",
      "('Epoch 00000050 ', 'test loss 0.8419', 'test acc 0.7678')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1068', 'WORST test acc 0.7138')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1068', 'MIN test acc 0.7138')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1939', 'avg train acc ', '0.9495')\n",
      "('Epoch 00000010 ', 'valid loss 0.2056', 'valid acc 0.9457')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2626', 'WORST valid acc 0.9264')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2626', 'MIN valid acc 0.9264')\n",
      "('Epoch 00000010 ', 'test loss 0.8779', 'test acc 0.7448')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1224', 'WORST test acc 0.6910')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1224', 'MIN test acc 0.6910')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1955', 'avg train acc ', '0.9488')\n",
      "('Epoch 00000020 ', 'valid loss 0.1850', 'valid acc 0.9528')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2267', 'WORST valid acc 0.9396')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2267', 'MIN valid acc 0.9396')\n",
      "('Epoch 00000020 ', 'test loss 0.7963', 'test acc 0.7793')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0136', 'WORST test acc 0.7360')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0136', 'MIN test acc 0.7360')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1939', 'avg train acc ', '0.9487')\n",
      "('Epoch 00000030 ', 'valid loss 0.1969', 'valid acc 0.9475')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2746', 'WORST valid acc 0.9230')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2738', 'MIN valid acc 0.9215')\n",
      "('Epoch 00000030 ', 'test loss 0.8210', 'test acc 0.7582')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0613', 'WORST test acc 0.6948')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0613', 'MIN test acc 0.6948')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1884', 'avg train acc ', '0.9511')\n",
      "('Epoch 00000040 ', 'valid loss 0.1933', 'valid acc 0.9493')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2520', 'WORST valid acc 0.9304')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2520', 'MIN valid acc 0.9304')\n",
      "('Epoch 00000040 ', 'test loss 0.7737', 'test acc 0.7864')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0723', 'WORST test acc 0.7234')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0723', 'MIN test acc 0.7234')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1816', 'avg train acc ', '0.9539')\n",
      "('Epoch 00000050 ', 'valid loss 0.1775', 'valid acc 0.9545')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2414', 'WORST valid acc 0.9342')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2414', 'MIN valid acc 0.9342')\n",
      "('Epoch 00000050 ', 'test loss 0.9044', 'test acc 0.7478')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1365', 'WORST test acc 0.7052')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1365', 'MIN test acc 0.7052')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1812', 'avg train acc ', '0.9535')\n",
      "('Epoch 00000010 ', 'valid loss 0.2167', 'valid acc 0.9414')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2725', 'WORST valid acc 0.9248')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2725', 'MIN valid acc 0.9248')\n",
      "('Epoch 00000010 ', 'test loss 0.9111', 'test acc 0.7381')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0371', 'WORST test acc 0.7082')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0371', 'MIN test acc 0.7082')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1855', 'avg train acc ', '0.9517')\n",
      "('Epoch 00000020 ', 'valid loss 0.1828', 'valid acc 0.9525')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2310', 'WORST valid acc 0.9367')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2288', 'MIN valid acc 0.9362')\n",
      "('Epoch 00000020 ', 'test loss 0.8659', 'test acc 0.7491')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 1.0164', 'WORST test acc 0.7100')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 1.0164', 'MIN test acc 0.7100')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1825', 'avg train acc ', '0.9524')\n",
      "('Epoch 00000030 ', 'valid loss 0.1722', 'valid acc 0.9564')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2424', 'WORST valid acc 0.9342')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2381', 'MIN valid acc 0.9337')\n",
      "('Epoch 00000030 ', 'test loss 0.8179', 'test acc 0.7652')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9962', 'WORST test acc 0.7202')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9962', 'MIN test acc 0.7202')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1747', 'avg train acc ', '0.9552')\n",
      "('Epoch 00000040 ', 'valid loss 0.1756', 'valid acc 0.9560')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2414', 'WORST valid acc 0.9346')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2414', 'MIN valid acc 0.9346')\n",
      "('Epoch 00000040 ', 'test loss 0.8700', 'test acc 0.7508')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9902', 'WORST test acc 0.7292')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9902', 'MIN test acc 0.7292')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1751', 'avg train acc ', '0.9560')\n",
      "('Epoch 00000050 ', 'valid loss 0.1796', 'valid acc 0.9526')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2519', 'WORST valid acc 0.9267')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2519', 'MIN valid acc 0.9267')\n",
      "('Epoch 00000050 ', 'test loss 0.8611', 'test acc 0.7521')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9934', 'WORST test acc 0.7282')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.8849', 'MIN test acc 0.7272')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1928', 'avg train acc ', '0.9497')\n",
      "('Epoch 00000010 ', 'valid loss 0.1959', 'valid acc 0.9490')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2596', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2596', 'MIN valid acc 0.9272')\n",
      "('Epoch 00000010 ', 'test loss 0.9242', 'test acc 0.7521')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1582', 'WORST test acc 0.7134')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1582', 'MIN test acc 0.7134')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1875', 'avg train acc ', '0.9515')\n",
      "('Epoch 00000020 ', 'valid loss 0.1744', 'valid acc 0.9564')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.2469', 'WORST valid acc 0.9318')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2469', 'MIN valid acc 0.9318')\n",
      "('Epoch 00000020 ', 'test loss 0.8886', 'test acc 0.7734')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2013', 'WORST test acc 0.7206')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2013', 'MIN test acc 0.7206')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1949', 'avg train acc ', '0.9477')\n",
      "('Epoch 00000030 ', 'valid loss 0.2174', 'valid acc 0.9385')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2916', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2916', 'MIN valid acc 0.9136')\n",
      "('Epoch 00000030 ', 'test loss 0.9370', 'test acc 0.7491')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1325', 'WORST test acc 0.7214')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1325', 'MIN test acc 0.7214')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1858', 'avg train acc ', '0.9526')\n",
      "('Epoch 00000040 ', 'valid loss 0.1780', 'valid acc 0.9551')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2445', 'WORST valid acc 0.9347')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2445', 'MIN valid acc 0.9347')\n",
      "('Epoch 00000040 ', 'test loss 0.8818', 'test acc 0.7717')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1904', 'WORST test acc 0.7134')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1904', 'MIN test acc 0.7134')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1881', 'avg train acc ', '0.9516')\n",
      "('Epoch 00000050 ', 'valid loss 0.1908', 'valid acc 0.9486')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2671', 'WORST valid acc 0.9218')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2671', 'MIN valid acc 0.9218')\n",
      "('Epoch 00000050 ', 'test loss 0.7741', 'test acc 0.7708')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9872', 'WORST test acc 0.7248')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9872', 'MIN test acc 0.7248')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2086', 'avg train acc ', '0.9427')\n",
      "('Epoch 00000010 ', 'valid loss 0.1869', 'valid acc 0.9469')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2472', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2472', 'MIN valid acc 0.9272')\n",
      "('Epoch 00000010 ', 'test loss 0.9602', 'test acc 0.7116')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.2063', 'WORST test acc 0.5980')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.2063', 'MIN test acc 0.5980')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1953', 'avg train acc ', '0.9461')\n",
      "('Epoch 00000020 ', 'valid loss 0.2014', 'valid acc 0.9483')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2625', 'WORST valid acc 0.9274')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2625', 'MIN valid acc 0.9274')\n",
      "('Epoch 00000020 ', 'test loss 1.1419', 'test acc 0.6964')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.8150', 'WORST test acc 0.5426')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.8150', 'MIN test acc 0.5426')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1943', 'avg train acc ', '0.9439')\n",
      "('Epoch 00000030 ', 'valid loss 0.2092', 'valid acc 0.9383')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2872', 'WORST valid acc 0.9072')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2872', 'MIN valid acc 0.9072')\n",
      "('Epoch 00000030 ', 'test loss 0.9133', 'test acc 0.7249')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.1829', 'WORST test acc 0.6130')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.1829', 'MIN test acc 0.6130')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1862', 'avg train acc ', '0.9507')\n",
      "('Epoch 00000040 ', 'valid loss 0.1840', 'valid acc 0.9551')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2725', 'WORST valid acc 0.9304')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2725', 'MIN valid acc 0.9304')\n",
      "('Epoch 00000040 ', 'test loss 1.0801', 'test acc 0.7026')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.6298', 'WORST test acc 0.5396')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.6298', 'MIN test acc 0.5396')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1843', 'avg train acc ', '0.9524')\n",
      "('Epoch 00000050 ', 'valid loss 0.2044', 'valid acc 0.9440')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2841', 'WORST valid acc 0.9167')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2841', 'MIN valid acc 0.9167')\n",
      "('Epoch 00000050 ', 'test loss 1.1288', 'test acc 0.7010')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.8767', 'WORST test acc 0.5096')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.8767', 'MIN test acc 0.5096')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2053', 'avg train acc ', '0.9419')\n",
      "('Epoch 00000010 ', 'valid loss 0.2096', 'valid acc 0.9443')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2727', 'WORST valid acc 0.9274')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2727', 'MIN valid acc 0.9274')\n",
      "('Epoch 00000010 ', 'test loss 0.9425', 'test acc 0.7112')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.2589', 'WORST test acc 0.5816')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.2589', 'MIN test acc 0.5816')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2012', 'avg train acc ', '0.9430')\n",
      "('Epoch 00000020 ', 'valid loss 0.2112', 'valid acc 0.9371')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2951', 'WORST valid acc 0.9058')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2951', 'MIN valid acc 0.9058')\n",
      "('Epoch 00000020 ', 'test loss 0.9341', 'test acc 0.7229')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.1876', 'WORST test acc 0.5998')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.1876', 'MIN test acc 0.5998')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1940', 'avg train acc ', '0.9459')\n",
      "('Epoch 00000030 ', 'valid loss 0.1803', 'valid acc 0.9524')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2438', 'WORST valid acc 0.9314')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2375', 'MIN valid acc 0.9308')\n",
      "('Epoch 00000030 ', 'test loss 1.0408', 'test acc 0.7028')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.7494', 'WORST test acc 0.4984')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.7494', 'MIN test acc 0.4984')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1982', 'avg train acc ', '0.9426')\n",
      "('Epoch 00000040 ', 'valid loss 0.1892', 'valid acc 0.9469')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2503', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2379', 'MIN valid acc 0.9268')\n",
      "('Epoch 00000040 ', 'test loss 0.9816', 'test acc 0.7090')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.2000', 'WORST test acc 0.6022')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.2000', 'MIN test acc 0.6022')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.2029', 'avg train acc ', '0.9457')\n",
      "('Epoch 00000050 ', 'valid loss 0.1954', 'valid acc 0.9501')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2690', 'WORST valid acc 0.9293')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2690', 'MIN valid acc 0.9293')\n",
      "('Epoch 00000050 ', 'test loss 0.9302', 'test acc 0.7085')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.2593', 'WORST test acc 0.5644')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.2593', 'MIN test acc 0.5644')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1837', 'avg train acc ', '0.9511')\n",
      "('Epoch 00000010 ', 'valid loss 0.1928', 'valid acc 0.9485')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2677', 'WORST valid acc 0.9210')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2677', 'MIN valid acc 0.9210')\n",
      "('Epoch 00000010 ', 'test loss 0.8468', 'test acc 0.7657')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1143', 'WORST test acc 0.7102')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1143', 'MIN test acc 0.7102')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1863', 'avg train acc ', '0.9507')\n",
      "('Epoch 00000020 ', 'valid loss 0.1883', 'valid acc 0.9483')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2705', 'WORST valid acc 0.9228')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2705', 'MIN valid acc 0.9228')\n",
      "('Epoch 00000020 ', 'test loss 0.8341', 'test acc 0.7665')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0711', 'WORST test acc 0.7246')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0711', 'MIN test acc 0.7246')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1875', 'avg train acc ', '0.9505')\n",
      "('Epoch 00000030 ', 'valid loss 0.1744', 'valid acc 0.9542')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2481', 'WORST valid acc 0.9304')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2481', 'MIN valid acc 0.9304')\n",
      "('Epoch 00000030 ', 'test loss 0.8245', 'test acc 0.7627')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0075', 'WORST test acc 0.7228')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0075', 'MIN test acc 0.7228')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1763', 'avg train acc ', '0.9555')\n",
      "('Epoch 00000040 ', 'valid loss 0.1911', 'valid acc 0.9510')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2578', 'WORST valid acc 0.9307')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2578', 'MIN valid acc 0.9307')\n",
      "('Epoch 00000040 ', 'test loss 0.8454', 'test acc 0.7709')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0409', 'WORST test acc 0.7352')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0409', 'MIN test acc 0.7352')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1774', 'avg train acc ', '0.9548')\n",
      "('Epoch 00000050 ', 'valid loss 0.1731', 'valid acc 0.9561')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2350', 'WORST valid acc 0.9372')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2350', 'MIN valid acc 0.9372')\n",
      "('Epoch 00000050 ', 'test loss 0.7878', 'test acc 0.7724')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9979', 'WORST test acc 0.7284')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9979', 'MIN test acc 0.7284')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1929', 'avg train acc ', '0.9489')\n",
      "('Epoch 00000010 ', 'valid loss 0.1841', 'valid acc 0.9534')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2573', 'WORST valid acc 0.9325')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2573', 'MIN valid acc 0.9325')\n",
      "('Epoch 00000010 ', 'test loss 0.9562', 'test acc 0.7528')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1807', 'WORST test acc 0.7264')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1807', 'MIN test acc 0.7264')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1892', 'avg train acc ', '0.9511')\n",
      "('Epoch 00000020 ', 'valid loss 0.1936', 'valid acc 0.9504')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2537', 'WORST valid acc 0.9310')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2534', 'MIN valid acc 0.9298')\n",
      "('Epoch 00000020 ', 'test loss 0.8210', 'test acc 0.7644')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0808', 'WORST test acc 0.7178')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0808', 'MIN test acc 0.7178')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1884', 'avg train acc ', '0.9510')\n",
      "('Epoch 00000030 ', 'valid loss 0.1862', 'valid acc 0.9519')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2500', 'WORST valid acc 0.9307')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2500', 'MIN valid acc 0.9307')\n",
      "('Epoch 00000030 ', 'test loss 0.7305', 'test acc 0.7907')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9668', 'WORST test acc 0.7422')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9668', 'MIN test acc 0.7422')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1812', 'avg train acc ', '0.9538')\n",
      "('Epoch 00000040 ', 'valid loss 0.1971', 'valid acc 0.9481')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2705', 'WORST valid acc 0.9251')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2697', 'MIN valid acc 0.9230')\n",
      "('Epoch 00000040 ', 'test loss 0.8392', 'test acc 0.7592')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0087', 'WORST test acc 0.7270')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0087', 'MIN test acc 0.7270')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1837', 'avg train acc ', '0.9524')\n",
      "('Epoch 00000050 ', 'valid loss 0.1869', 'valid acc 0.9495')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2608', 'WORST valid acc 0.9254')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2608', 'MIN valid acc 0.9254')\n",
      "('Epoch 00000050 ', 'test loss 0.8703', 'test acc 0.7627')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1116', 'WORST test acc 0.7206')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1116', 'MIN test acc 0.7206')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.2081', 'avg train acc ', '0.9433')\n",
      "('Epoch 00000010 ', 'valid loss 0.2205', 'valid acc 0.9415')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3201', 'WORST valid acc 0.9097')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3201', 'MIN valid acc 0.9097')\n",
      "('Epoch 00000010 ', 'test loss 0.8736', 'test acc 0.7208')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.2289', 'WORST test acc 0.5864')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.2289', 'MIN test acc 0.5864')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.2069', 'avg train acc ', '0.9406')\n",
      "('Epoch 00000020 ', 'valid loss 0.2042', 'valid acc 0.9428')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2752', 'WORST valid acc 0.9215')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2752', 'MIN valid acc 0.9215')\n",
      "('Epoch 00000020 ', 'test loss 1.0239', 'test acc 0.7120')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.5215', 'WORST test acc 0.5730')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.5215', 'MIN test acc 0.5730')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.2035', 'avg train acc ', '0.9461')\n",
      "('Epoch 00000030 ', 'valid loss 0.2069', 'valid acc 0.9439')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2921', 'WORST valid acc 0.9176')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2921', 'MIN valid acc 0.9176')\n",
      "('Epoch 00000030 ', 'test loss 0.9418', 'test acc 0.7215')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.3202', 'WORST test acc 0.5780')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.3202', 'MIN test acc 0.5780')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.2032', 'avg train acc ', '0.9428')\n",
      "('Epoch 00000040 ', 'valid loss 0.2028', 'valid acc 0.9397')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2778', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2778', 'MIN valid acc 0.9136')\n",
      "('Epoch 00000040 ', 'test loss 0.9534', 'test acc 0.7182')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.1499', 'WORST test acc 0.6114')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.1499', 'MIN test acc 0.6114')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1988', 'avg train acc ', '0.9483')\n",
      "('Epoch 00000050 ', 'valid loss 0.2001', 'valid acc 0.9501')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2930', 'WORST valid acc 0.9235')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2930', 'MIN valid acc 0.9235')\n",
      "('Epoch 00000050 ', 'test loss 1.0245', 'test acc 0.7039')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.4964', 'WORST test acc 0.5666')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.4964', 'MIN test acc 0.5666')\n",
      "===FINAL RESULTS WITH NODE 2===\n",
      "('VALID: acc 0.9509', 'accs sd 0.0032', 'loss 0.1886', 'loss sd 0.0094')\n",
      "('TEST: acc 0.7449', 'accs sd 0.0275', 'loss 0.8990', 'loss sd 0.1020')\n",
      "('WORST VALID: acc 0.9282', 'accs sd 0.0062', 'loss 0.2597', 'loss sd 0.0179')\n",
      "WORST VALID DOMAINS: [2, 5, 1, 2, 2, 0, 1, 1, 1, 1]\n",
      "('WORST TEST: acc 0.6690', 'accs sd 0.0816', 'loss 1.2024', 'loss sd 0.2681')\n",
      "WORST TEST DOMAINS: [2, 2, 2, 2, 2, 1, 1, 2, 2, 1]\n",
      "('MIN VALID: acc 0.9281', 'accs sd 0.0062', 'loss 0.2593', 'loss sd 0.0183')\n",
      "MIN VALID DOMAINS: [2, 0, 1, 2, 2, 0, 1, 1, 1, 1]\n",
      "('MIN TEST: acc 0.6689', 'accs sd 0.0815', 'loss 1.1915', 'loss sd 0.2783')\n",
      "MIN TEST DOMAINS: [2, 2, 2, 0, 2, 1, 1, 2, 2, 1]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1310', 'avg train acc ', '0.9517')\n",
      "('Epoch 00000010 ', 'valid loss 0.1181', 'valid acc 0.9641')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1529', 'WORST valid acc 0.9536')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1529', 'MIN valid acc 0.9536')\n",
      "('Epoch 00000010 ', 'test loss 0.6482', 'test acc 0.7663')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7807', 'WORST test acc 0.7194')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6130', 'MIN test acc 0.7038')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1326', 'avg train acc ', '0.9583')\n",
      "('Epoch 00000020 ', 'valid loss 0.1384', 'valid acc 0.9543')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.1722', 'WORST valid acc 0.9350')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1722', 'MIN valid acc 0.9350')\n",
      "('Epoch 00000020 ', 'test loss 0.8319', 'test acc 0.7562')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0115', 'WORST test acc 0.7096')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0115', 'MIN test acc 0.7096')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1251', 'avg train acc ', '0.9602')\n",
      "('Epoch 00000030 ', 'valid loss 0.1245', 'valid acc 0.9605')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1592', 'WORST valid acc 0.9475')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1592', 'MIN valid acc 0.9475')\n",
      "('Epoch 00000030 ', 'test loss 0.6402', 'test acc 0.7744')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7820', 'WORST test acc 0.7120')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7820', 'MIN test acc 0.7120')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1151', 'avg train acc ', '0.9647')\n",
      "('Epoch 00000040 ', 'valid loss 0.1215', 'valid acc 0.9640')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1816', 'WORST valid acc 0.9454')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1816', 'MIN valid acc 0.9454')\n",
      "('Epoch 00000040 ', 'test loss 0.7133', 'test acc 0.7682')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8608', 'WORST test acc 0.7486')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.7915', 'MIN test acc 0.7040')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1217', 'avg train acc ', '0.9625')\n",
      "('Epoch 00000050 ', 'valid loss 0.1332', 'valid acc 0.9572')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1830', 'WORST valid acc 0.9388')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1830', 'MIN valid acc 0.9388')\n",
      "('Epoch 00000050 ', 'test loss 0.7813', 'test acc 0.7754')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9905', 'WORST test acc 0.7176')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9905', 'MIN test acc 0.7176')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1359', 'avg train acc ', '0.9525')\n",
      "('Epoch 00000010 ', 'valid loss 0.1333', 'valid acc 0.9585')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.1642', 'WORST valid acc 0.9460')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1642', 'MIN valid acc 0.9460')\n",
      "('Epoch 00000010 ', 'test loss 0.7074', 'test acc 0.7796')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8276', 'WORST test acc 0.7772')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.8128', 'MIN test acc 0.7096')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1216', 'avg train acc ', '0.9632')\n",
      "('Epoch 00000020 ', 'valid loss 0.1272', 'valid acc 0.9637')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1641', 'WORST valid acc 0.9554')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1579', 'MIN valid acc 0.9507')\n",
      "('Epoch 00000020 ', 'test loss 0.7639', 'test acc 0.7755')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9065', 'WORST test acc 0.7216')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9065', 'MIN test acc 0.7216')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1235', 'avg train acc ', '0.9614')\n",
      "('Epoch 00000030 ', 'valid loss 0.1306', 'valid acc 0.9571')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1542', 'WORST valid acc 0.9468')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1542', 'MIN valid acc 0.9468')\n",
      "('Epoch 00000030 ', 'test loss 0.8794', 'test acc 0.7198')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.9443', 'WORST test acc 0.7288')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.7826', 'MIN test acc 0.6920')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1318', 'avg train acc ', '0.9557')\n",
      "('Epoch 00000040 ', 'valid loss 0.1335', 'valid acc 0.9557')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1830', 'WORST valid acc 0.9475')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1351', 'MIN valid acc 0.9401')\n",
      "('Epoch 00000040 ', 'test loss 1.0293', 'test acc 0.6881')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 1.4708', 'WORST test acc 0.5846')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 1.4708', 'MIN test acc 0.5846')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1100', 'avg train acc ', '0.9694')\n",
      "('Epoch 00000050 ', 'valid loss 0.1117', 'valid acc 0.9685')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1535', 'WORST valid acc 0.9561')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1535', 'MIN valid acc 0.9561')\n",
      "('Epoch 00000050 ', 'test loss 0.8683', 'test acc 0.7643')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.9866', 'WORST test acc 0.7208')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.9866', 'MIN test acc 0.7208')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1366', 'avg train acc ', '0.9483')\n",
      "('Epoch 00000010 ', 'valid loss 0.1310', 'valid acc 0.9528')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1714', 'WORST valid acc 0.9315')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1714', 'MIN valid acc 0.9315')\n",
      "('Epoch 00000010 ', 'test loss 0.6963', 'test acc 0.7528')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8743', 'WORST test acc 0.7462')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6092', 'MIN test acc 0.7078')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1295', 'avg train acc ', '0.9583')\n",
      "('Epoch 00000020 ', 'valid loss 0.1282', 'valid acc 0.9600')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1610', 'WORST valid acc 0.9433')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1610', 'MIN valid acc 0.9433')\n",
      "('Epoch 00000020 ', 'test loss 0.8979', 'test acc 0.7605')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1625', 'WORST test acc 0.7162')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 1.0904', 'MIN test acc 0.6958')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1314', 'avg train acc ', '0.9596')\n",
      "('Epoch 00000030 ', 'valid loss 0.1412', 'valid acc 0.9535')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1936', 'WORST valid acc 0.9420')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1936', 'MIN valid acc 0.9420')\n",
      "('Epoch 00000030 ', 'test loss 0.6914', 'test acc 0.8003')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0344', 'WORST test acc 0.7508')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0344', 'MIN test acc 0.7508')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1292', 'avg train acc ', '0.9556')\n",
      "('Epoch 00000040 ', 'valid loss 0.1322', 'valid acc 0.9572')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1797', 'WORST valid acc 0.9443')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1650', 'MIN valid acc 0.9430')\n",
      "('Epoch 00000040 ', 'test loss 0.9086', 'test acc 0.7849')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3109', 'WORST test acc 0.7584')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.9467', 'MIN test acc 0.7340')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1174', 'avg train acc ', '0.9642')\n",
      "('Epoch 00000050 ', 'valid loss 0.1205', 'valid acc 0.9635')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1401', 'WORST valid acc 0.9615')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.1309', 'MIN valid acc 0.9579')\n",
      "('Epoch 00000050 ', 'test loss 0.6477', 'test acc 0.7886')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6746', 'WORST test acc 0.8174')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6672', 'MIN test acc 0.7194')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1245', 'avg train acc ', '0.9583')\n",
      "('Epoch 00000010 ', 'valid loss 0.1237', 'valid acc 0.9565')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1684', 'WORST valid acc 0.9451')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1524', 'MIN valid acc 0.9408')\n",
      "('Epoch 00000010 ', 'test loss 0.6082', 'test acc 0.8010')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7277', 'WORST test acc 0.8002')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7251', 'MIN test acc 0.7474')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1385', 'avg train acc ', '0.9489')\n",
      "('Epoch 00000020 ', 'valid loss 0.1335', 'valid acc 0.9481')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1677', 'WORST valid acc 0.9251')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1677', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000020 ', 'test loss 0.6695', 'test acc 0.7627')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8681', 'WORST test acc 0.7274')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6452', 'MIN test acc 0.7100')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1382', 'avg train acc ', '0.9557')\n",
      "('Epoch 00000030 ', 'valid loss 0.1421', 'valid acc 0.9507')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1945', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1945', 'MIN valid acc 0.9272')\n",
      "('Epoch 00000030 ', 'test loss 0.7574', 'test acc 0.7858')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9265', 'WORST test acc 0.7374')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9265', 'MIN test acc 0.7374')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1229', 'avg train acc ', '0.9607')\n",
      "('Epoch 00000040 ', 'valid loss 0.1155', 'valid acc 0.9652')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1502', 'WORST valid acc 0.9557')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1502', 'MIN valid acc 0.9557')\n",
      "('Epoch 00000040 ', 'test loss 0.7474', 'test acc 0.7780')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9584', 'WORST test acc 0.7350')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.8318', 'MIN test acc 0.7350')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1107', 'avg train acc ', '0.9631')\n",
      "('Epoch 00000050 ', 'valid loss 0.1130', 'valid acc 0.9634')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1535', 'WORST valid acc 0.9451')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1535', 'MIN valid acc 0.9451')\n",
      "('Epoch 00000050 ', 'test loss 0.6924', 'test acc 0.7931')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7827', 'WORST test acc 0.7916')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.7288', 'MIN test acc 0.7628')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1269', 'avg train acc ', '0.9596')\n",
      "('Epoch 00000010 ', 'valid loss 0.1363', 'valid acc 0.9560')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1782', 'WORST valid acc 0.9390')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1685', 'MIN valid acc 0.9378')\n",
      "('Epoch 00000010 ', 'test loss 0.9922', 'test acc 0.7411')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3556', 'WORST test acc 0.6940')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3556', 'MIN test acc 0.6940')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1156', 'avg train acc ', '0.9645')\n",
      "('Epoch 00000020 ', 'valid loss 0.1225', 'valid acc 0.9591')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1577', 'WORST valid acc 0.9411')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1577', 'MIN valid acc 0.9411')\n",
      "('Epoch 00000020 ', 'test loss 0.9626', 'test acc 0.7268')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3123', 'WORST test acc 0.6988')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3123', 'MIN test acc 0.6988')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1176', 'avg train acc ', '0.9626')\n",
      "('Epoch 00000030 ', 'valid loss 0.1113', 'valid acc 0.9593')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.1488', 'WORST valid acc 0.9410')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1488', 'MIN valid acc 0.9410')\n",
      "('Epoch 00000030 ', 'test loss 0.9389', 'test acc 0.7383')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2488', 'WORST test acc 0.7028')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2488', 'MIN test acc 0.7028')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1206', 'avg train acc ', '0.9604')\n",
      "('Epoch 00000040 ', 'valid loss 0.1373', 'valid acc 0.9466')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1910', 'WORST valid acc 0.9186')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1910', 'MIN valid acc 0.9186')\n",
      "('Epoch 00000040 ', 'test loss 1.0074', 'test acc 0.7376')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.4475', 'WORST test acc 0.7006')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.8555', 'MIN test acc 0.6962')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1166', 'avg train acc ', '0.9712')\n",
      "('Epoch 00000050 ', 'valid loss 0.1489', 'valid acc 0.9640')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1774', 'WORST valid acc 0.9568')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1774', 'MIN valid acc 0.9568')\n",
      "('Epoch 00000050 ', 'test loss 0.9566', 'test acc 0.7374')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.1294', 'WORST test acc 0.6802')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.1294', 'MIN test acc 0.6802')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1337', 'avg train acc ', '0.9584')\n",
      "('Epoch 00000010 ', 'valid loss 0.1419', 'valid acc 0.9574')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1699', 'WORST valid acc 0.9495')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1699', 'MIN valid acc 0.9495')\n",
      "('Epoch 00000010 ', 'test loss 0.8692', 'test acc 0.7459')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2331', 'WORST test acc 0.7040')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2331', 'MIN test acc 0.7040')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1325', 'avg train acc ', '0.9573')\n",
      "('Epoch 00000020 ', 'valid loss 0.1390', 'valid acc 0.9506')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1786', 'WORST valid acc 0.9433')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1677', 'MIN valid acc 0.9347')\n",
      "('Epoch 00000020 ', 'test loss 0.6955', 'test acc 0.7846')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9345', 'WORST test acc 0.7390')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9345', 'MIN test acc 0.7390')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1238', 'avg train acc ', '0.9615')\n",
      "('Epoch 00000030 ', 'valid loss 0.1100', 'valid acc 0.9674')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1504', 'WORST valid acc 0.9529')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1504', 'MIN valid acc 0.9529')\n",
      "('Epoch 00000030 ', 'test loss 0.7854', 'test acc 0.7687')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1245', 'WORST test acc 0.7196')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1245', 'MIN test acc 0.7196')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1213', 'avg train acc ', '0.9616')\n",
      "('Epoch 00000040 ', 'valid loss 0.1289', 'valid acc 0.9592')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1711', 'WORST valid acc 0.9431')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1573', 'MIN valid acc 0.9430')\n",
      "('Epoch 00000040 ', 'test loss 0.8456', 'test acc 0.7532')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0513', 'WORST test acc 0.7232')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.9111', 'MIN test acc 0.7116')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1383', 'avg train acc ', '0.9526')\n",
      "('Epoch 00000050 ', 'valid loss 0.1353', 'valid acc 0.9587')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1675', 'WORST valid acc 0.9509')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1581', 'MIN valid acc 0.9433')\n",
      "('Epoch 00000050 ', 'test loss 0.7395', 'test acc 0.7752')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9594', 'WORST test acc 0.7510')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7388', 'MIN test acc 0.7476')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1396', 'avg train acc ', '0.9525')\n",
      "('Epoch 00000010 ', 'valid loss 0.1293', 'valid acc 0.9535')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1852', 'WORST valid acc 0.9362')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1852', 'MIN valid acc 0.9362')\n",
      "('Epoch 00000010 ', 'test loss 0.7326', 'test acc 0.7525')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8823', 'WORST test acc 0.7232')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.7940', 'MIN test acc 0.6994')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1263', 'avg train acc ', '0.9609')\n",
      "('Epoch 00000020 ', 'valid loss 0.1384', 'valid acc 0.9604')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1996', 'WORST valid acc 0.9443')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1996', 'MIN valid acc 0.9443')\n",
      "('Epoch 00000020 ', 'test loss 0.7205', 'test acc 0.7505')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 1.0067', 'WORST test acc 0.5898')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.0067', 'MIN test acc 0.5898')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1281', 'avg train acc ', '0.9531')\n",
      "('Epoch 00000030 ', 'valid loss 0.1262', 'valid acc 0.9549')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1611', 'WORST valid acc 0.9420')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1598', 'MIN valid acc 0.9390')\n",
      "('Epoch 00000030 ', 'test loss 0.6738', 'test acc 0.7644')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8784', 'WORST test acc 0.7714')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7624', 'MIN test acc 0.7148')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1504', 'avg train acc ', '0.9452')\n",
      "('Epoch 00000040 ', 'valid loss 0.1402', 'valid acc 0.9508')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2195', 'WORST valid acc 0.9251')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2195', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000040 ', 'test loss 0.5913', 'test acc 0.8013')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7500', 'WORST test acc 0.8022')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6309', 'MIN test acc 0.7224')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1246', 'avg train acc ', '0.9577')\n",
      "('Epoch 00000050 ', 'valid loss 0.1483', 'valid acc 0.9468')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1870', 'WORST valid acc 0.9304')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1808', 'MIN valid acc 0.9272')\n",
      "('Epoch 00000050 ', 'test loss 0.7177', 'test acc 0.7914')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.8337', 'WORST test acc 0.7530')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8141', 'MIN test acc 0.7446')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1252', 'avg train acc ', '0.9564')\n",
      "('Epoch 00000010 ', 'valid loss 0.1214', 'valid acc 0.9587')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1555', 'WORST valid acc 0.9430')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1555', 'MIN valid acc 0.9430')\n",
      "('Epoch 00000010 ', 'test loss 0.7770', 'test acc 0.7479')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9580', 'WORST test acc 0.7340')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8424', 'MIN test acc 0.7208')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1296', 'avg train acc ', '0.9593')\n",
      "('Epoch 00000020 ', 'valid loss 0.1423', 'valid acc 0.9554')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1909', 'WORST valid acc 0.9325')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1909', 'MIN valid acc 0.9325')\n",
      "('Epoch 00000020 ', 'test loss 0.7785', 'test acc 0.7263')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9715', 'WORST test acc 0.7302')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.7952', 'MIN test acc 0.6666')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1258', 'avg train acc ', '0.9587')\n",
      "('Epoch 00000030 ', 'valid loss 0.1307', 'valid acc 0.9581')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1709', 'WORST valid acc 0.9411')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1709', 'MIN valid acc 0.9411')\n",
      "('Epoch 00000030 ', 'test loss 0.9976', 'test acc 0.7479')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 1.2812', 'WORST test acc 0.6690')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 1.2812', 'MIN test acc 0.6690')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1280', 'avg train acc ', '0.9596')\n",
      "('Epoch 00000040 ', 'valid loss 0.1294', 'valid acc 0.9575')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1612', 'WORST valid acc 0.9549')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1498', 'MIN valid acc 0.9507')\n",
      "('Epoch 00000040 ', 'test loss 0.6995', 'test acc 0.7554')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8343', 'WORST test acc 0.7622')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6611', 'MIN test acc 0.7014')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1168', 'avg train acc ', '0.9596')\n",
      "('Epoch 00000050 ', 'valid loss 0.1214', 'valid acc 0.9578')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1630', 'WORST valid acc 0.9347')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1630', 'MIN valid acc 0.9347')\n",
      "('Epoch 00000050 ', 'test loss 0.8751', 'test acc 0.7503')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0089', 'WORST test acc 0.7426')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.8598', 'MIN test acc 0.7080')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1389', 'avg train acc ', '0.9481')\n",
      "('Epoch 00000010 ', 'valid loss 0.1568', 'valid acc 0.9382')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2190', 'WORST valid acc 0.9176')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2000', 'MIN valid acc 0.9120')\n",
      "('Epoch 00000010 ', 'test loss 0.7410', 'test acc 0.7844')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9918', 'WORST test acc 0.7432')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6485', 'MIN test acc 0.7430')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1246', 'avg train acc ', '0.9550')\n",
      "('Epoch 00000020 ', 'valid loss 0.1234', 'valid acc 0.9560')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1558', 'WORST valid acc 0.9401')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1501', 'MIN valid acc 0.9366')\n",
      "('Epoch 00000020 ', 'test loss 0.7789', 'test acc 0.7647')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9070', 'WORST test acc 0.7286')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.8414', 'MIN test acc 0.7128')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1306', 'avg train acc ', '0.9532')\n",
      "('Epoch 00000030 ', 'valid loss 0.1331', 'valid acc 0.9536')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1645', 'WORST valid acc 0.9436')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1442', 'MIN valid acc 0.9410')\n",
      "('Epoch 00000030 ', 'test loss 0.6743', 'test acc 0.7754')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8450', 'WORST test acc 0.7342')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6987', 'MIN test acc 0.7044')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1195', 'avg train acc ', '0.9617')\n",
      "('Epoch 00000040 ', 'valid loss 0.1254', 'valid acc 0.9575')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1534', 'WORST valid acc 0.9504')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1534', 'MIN valid acc 0.9504')\n",
      "('Epoch 00000040 ', 'test loss 0.7222', 'test acc 0.7674')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8071', 'WORST test acc 0.7416')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.7156', 'MIN test acc 0.7322')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1103', 'avg train acc ', '0.9631')\n",
      "('Epoch 00000050 ', 'valid loss 0.1136', 'valid acc 0.9636')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1341', 'WORST valid acc 0.9598')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1301', 'MIN valid acc 0.9578')\n",
      "('Epoch 00000050 ', 'test loss 0.7566', 'test acc 0.7726')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.9366', 'WORST test acc 0.7030')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.9366', 'MIN test acc 0.7030')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1437', 'avg train acc ', '0.9472')\n",
      "('Epoch 00000010 ', 'valid loss 0.1309', 'valid acc 0.9541')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1940', 'WORST valid acc 0.9230')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1940', 'MIN valid acc 0.9230')\n",
      "('Epoch 00000010 ', 'test loss 0.8261', 'test acc 0.7480')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2623', 'WORST test acc 0.6764')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2623', 'MIN test acc 0.6764')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.1348', 'avg train acc ', '0.9614')\n",
      "('Epoch 00000020 ', 'valid loss 0.1430', 'valid acc 0.9571')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1874', 'WORST valid acc 0.9422')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1764', 'MIN valid acc 0.9388')\n",
      "('Epoch 00000020 ', 'test loss 0.8498', 'test acc 0.7575')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1800', 'WORST test acc 0.7254')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.0168', 'MIN test acc 0.7196')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1283', 'avg train acc ', '0.9589')\n",
      "('Epoch 00000030 ', 'valid loss 0.1261', 'valid acc 0.9627')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1742', 'WORST valid acc 0.9483')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1742', 'MIN valid acc 0.9483')\n",
      "('Epoch 00000030 ', 'test loss 0.7675', 'test acc 0.7866')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9849', 'WORST test acc 0.7896')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.9691', 'MIN test acc 0.7438')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1357', 'avg train acc ', '0.9504')\n",
      "('Epoch 00000040 ', 'valid loss 0.1496', 'valid acc 0.9457')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2174', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2174', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000040 ', 'test loss 0.7829', 'test acc 0.7574')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0104', 'WORST test acc 0.7338')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.8391', 'MIN test acc 0.7136')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1378', 'avg train acc ', '0.9531')\n",
      "('Epoch 00000050 ', 'valid loss 0.1401', 'valid acc 0.9474')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2044', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2044', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000050 ', 'test loss 0.8122', 'test acc 0.7472')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1814', 'WORST test acc 0.6960')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1814', 'MIN test acc 0.6960')\n",
      "===FINAL RESULTS WITH NODE 5===\n",
      "('VALID: acc 0.9591', 'accs sd 0.0068', 'loss 0.1286', 'loss sd 0.0137')\n",
      "('TEST: acc 0.7695', 'accs sd 0.0184', 'loss 0.7847', 'loss sd 0.0895')\n",
      "('WORST VALID: acc 0.9450', 'accs sd 0.0142', 'loss 0.1663', 'loss sd 0.0208')\n",
      "WORST VALID DOMAINS: [0, 3, 3, 0, 0, 4, 0, 3, 1, 1]\n",
      "('WORST TEST: acc 0.7373', 'accs sd 0.0408', 'loss 0.9484', 'loss sd 0.1448')\n",
      "WORST TEST DOMAINS: [2, 4, 2, 2, 1, 2, 1, 2, 4, 2]\n",
      "('MIN VALID: acc 0.9433', 'accs sd 0.0138', 'loss 0.1635', 'loss sd 0.0222')\n",
      "MIN VALID DOMAINS: [0, 3, 9, 0, 0, 3, 3, 3, 0, 1]\n",
      "('MIN TEST: acc 0.7200', 'accs sd 0.0241', 'loss 0.9033', 'loss sd 0.1635')\n",
      "MIN TEST DOMAINS: [2, 4, 4, 4, 1, 1, 2, 4, 4, 2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1057', 'avg train acc ', '0.9623')\n",
      "('Epoch 00000010 ', 'valid loss 0.1247', 'valid acc 0.9539')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1625', 'WORST valid acc 0.9420')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1625', 'MIN valid acc 0.9420')\n",
      "('Epoch 00000010 ', 'test loss 0.7900', 'test acc 0.7726')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0160', 'WORST test acc 0.7340')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0160', 'MIN test acc 0.7340')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0973', 'avg train acc ', '0.9635')\n",
      "('Epoch 00000020 ', 'valid loss 0.1065', 'valid acc 0.9611')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1511', 'WORST valid acc 0.9420')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1395', 'MIN valid acc 0.9368')\n",
      "('Epoch 00000020 ', 'test loss 0.9926', 'test acc 0.7546')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.6857', 'WORST test acc 0.6828')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.6857', 'MIN test acc 0.6828')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0910', 'avg train acc ', '0.9657')\n",
      "('Epoch 00000030 ', 'valid loss 0.0918', 'valid acc 0.9596')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1317', 'WORST valid acc 0.9388')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1317', 'MIN valid acc 0.9388')\n",
      "('Epoch 00000030 ', 'test loss 0.8995', 'test acc 0.7608')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2290', 'WORST test acc 0.7080')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2290', 'MIN test acc 0.7080')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0863', 'avg train acc ', '0.9696')\n",
      "('Epoch 00000040 ', 'valid loss 0.0859', 'valid acc 0.9721')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1186', 'WORST valid acc 0.9647')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1122', 'MIN valid acc 0.9578')\n",
      "('Epoch 00000040 ', 'test loss 0.8566', 'test acc 0.7624')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0619', 'WORST test acc 0.7246')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0619', 'MIN test acc 0.7246')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0898', 'avg train acc ', '0.9698')\n",
      "('Epoch 00000050 ', 'valid loss 0.0849', 'valid acc 0.9742')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1240', 'WORST valid acc 0.9615')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1240', 'MIN valid acc 0.9615')\n",
      "('Epoch 00000050 ', 'test loss 1.0199', 'test acc 0.7590')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.4660', 'WORST test acc 0.7162')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.4660', 'MIN test acc 0.7162')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1042', 'avg train acc ', '0.9626')\n",
      "('Epoch 00000010 ', 'valid loss 0.1158', 'valid acc 0.9590')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1542', 'WORST valid acc 0.9483')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1542', 'MIN valid acc 0.9483')\n",
      "('Epoch 00000010 ', 'test loss 0.6909', 'test acc 0.8166')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0392', 'WORST test acc 0.7484')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0392', 'MIN test acc 0.7484')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0905', 'avg train acc ', '0.9684')\n",
      "('Epoch 00000020 ', 'valid loss 0.0847', 'valid acc 0.9675')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1235', 'WORST valid acc 0.9495')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1235', 'MIN valid acc 0.9495')\n",
      "('Epoch 00000020 ', 'test loss 0.8757', 'test acc 0.7979')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1993', 'WORST test acc 0.7532')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1993', 'MIN test acc 0.7532')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1005', 'avg train acc ', '0.9685')\n",
      "('Epoch 00000030 ', 'valid loss 0.1084', 'valid acc 0.9665')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1290', 'WORST valid acc 0.9579')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1277', 'MIN valid acc 0.9578')\n",
      "('Epoch 00000030 ', 'test loss 0.8245', 'test acc 0.7961')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0888', 'WORST test acc 0.7610')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0888', 'MIN test acc 0.7610')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0977', 'avg train acc ', '0.9656')\n",
      "('Epoch 00000040 ', 'valid loss 0.1016', 'valid acc 0.9647')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1418', 'WORST valid acc 0.9500')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1206', 'MIN valid acc 0.9470')\n",
      "('Epoch 00000040 ', 'test loss 0.8727', 'test acc 0.7760')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0576', 'WORST test acc 0.7504')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9617', 'MIN test acc 0.7426')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.1072', 'avg train acc ', '0.9602')\n",
      "('Epoch 00000050 ', 'valid loss 0.1014', 'valid acc 0.9602')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1333', 'WORST valid acc 0.9483')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1274', 'MIN valid acc 0.9460')\n",
      "('Epoch 00000050 ', 'test loss 0.8671', 'test acc 0.7679')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0776', 'WORST test acc 0.7328')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0776', 'MIN test acc 0.7328')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1039', 'avg train acc ', '0.9619')\n",
      "('Epoch 00000010 ', 'valid loss 0.1109', 'valid acc 0.9640')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1282', 'WORST valid acc 0.9593')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1136', 'MIN valid acc 0.9540')\n",
      "('Epoch 00000010 ', 'test loss 0.9427', 'test acc 0.7315')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2646', 'WORST test acc 0.6978')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.9963', 'MIN test acc 0.6572')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0900', 'avg train acc ', '0.9684')\n",
      "('Epoch 00000020 ', 'valid loss 0.0986', 'valid acc 0.9626')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1305', 'WORST valid acc 0.9515')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1258', 'MIN valid acc 0.9486')\n",
      "('Epoch 00000020 ', 'test loss 0.8180', 'test acc 0.7474')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0016', 'WORST test acc 0.7198')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0016', 'MIN test acc 0.7198')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0830', 'avg train acc ', '0.9705')\n",
      "('Epoch 00000030 ', 'valid loss 0.0754', 'valid acc 0.9742')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.0975', 'WORST valid acc 0.9662')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.0975', 'MIN valid acc 0.9662')\n",
      "('Epoch 00000030 ', 'test loss 0.8920', 'test acc 0.7470')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0589', 'WORST test acc 0.7152')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0589', 'MIN test acc 0.7152')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0772', 'avg train acc ', '0.9736')\n",
      "('Epoch 00000040 ', 'valid loss 0.0852', 'valid acc 0.9732')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1261', 'WORST valid acc 0.9631')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1261', 'MIN valid acc 0.9631')\n",
      "('Epoch 00000040 ', 'test loss 0.8241', 'test acc 0.7640')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9758', 'WORST test acc 0.7660')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9351', 'MIN test acc 0.7150')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0789', 'avg train acc ', '0.9707')\n",
      "('Epoch 00000050 ', 'valid loss 0.0902', 'valid acc 0.9678')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1096', 'WORST valid acc 0.9610')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1096', 'MIN valid acc 0.9610')\n",
      "('Epoch 00000050 ', 'test loss 0.8868', 'test acc 0.7582')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0575', 'WORST test acc 0.7420')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.9817', 'MIN test acc 0.7406')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1070', 'avg train acc ', '0.9612')\n",
      "('Epoch 00000010 ', 'valid loss 0.0994', 'valid acc 0.9640')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1330', 'WORST valid acc 0.9599')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1166', 'MIN valid acc 0.9572')\n",
      "('Epoch 00000010 ', 'test loss 0.6922', 'test acc 0.8014')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.8188', 'WORST test acc 0.7310')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.8188', 'MIN test acc 0.7310')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0957', 'avg train acc ', '0.9644')\n",
      "('Epoch 00000020 ', 'valid loss 0.1037', 'valid acc 0.9619')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1540', 'WORST valid acc 0.9451')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1540', 'MIN valid acc 0.9451')\n",
      "('Epoch 00000020 ', 'test loss 0.7128', 'test acc 0.7978')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8881', 'WORST test acc 0.7546')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8881', 'MIN test acc 0.7546')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0869', 'avg train acc ', '0.9686')\n",
      "('Epoch 00000030 ', 'valid loss 0.1014', 'valid acc 0.9650')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.1210', 'WORST valid acc 0.9659')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1197', 'MIN valid acc 0.9568')\n",
      "('Epoch 00000030 ', 'test loss 0.7109', 'test acc 0.7843')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.7916', 'WORST test acc 0.7462')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7632', 'MIN test acc 0.7238')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0824', 'avg train acc ', '0.9721')\n",
      "('Epoch 00000040 ', 'valid loss 0.0781', 'valid acc 0.9732')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1131', 'WORST valid acc 0.9662')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1009', 'MIN valid acc 0.9627')\n",
      "('Epoch 00000040 ', 'test loss 0.8137', 'test acc 0.8040')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9516', 'WORST test acc 0.7670')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9516', 'MIN test acc 0.7670')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0815', 'avg train acc ', '0.9704')\n",
      "('Epoch 00000050 ', 'valid loss 0.1005', 'valid acc 0.9666')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1147', 'WORST valid acc 0.9536')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1147', 'MIN valid acc 0.9536')\n",
      "('Epoch 00000050 ', 'test loss 0.6594', 'test acc 0.8050')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8169', 'WORST test acc 0.7878')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6971', 'MIN test acc 0.7576')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0981', 'avg train acc ', '0.9629')\n",
      "('Epoch 00000010 ', 'valid loss 0.1039', 'valid acc 0.9605')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1296', 'WORST valid acc 0.9557')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1296', 'MIN valid acc 0.9557')\n",
      "('Epoch 00000010 ', 'test loss 0.7459', 'test acc 0.7802')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1504', 'WORST test acc 0.7298')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1504', 'MIN test acc 0.7298')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0961', 'avg train acc ', '0.9662')\n",
      "('Epoch 00000020 ', 'valid loss 0.0953', 'valid acc 0.9677')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1340', 'WORST valid acc 0.9495')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1340', 'MIN valid acc 0.9495')\n",
      "('Epoch 00000020 ', 'test loss 0.8115', 'test acc 0.7730')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1045', 'WORST test acc 0.7204')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1045', 'MIN test acc 0.7204')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0959', 'avg train acc ', '0.9682')\n",
      "('Epoch 00000030 ', 'valid loss 0.0972', 'valid acc 0.9637')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1370', 'WORST valid acc 0.9486')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1370', 'MIN valid acc 0.9486')\n",
      "('Epoch 00000030 ', 'test loss 0.7355', 'test acc 0.7848')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9592', 'WORST test acc 0.7506')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9592', 'MIN test acc 0.7506')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0896', 'avg train acc ', '0.9708')\n",
      "('Epoch 00000040 ', 'valid loss 0.0920', 'valid acc 0.9718')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1297', 'WORST valid acc 0.9649')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1181', 'MIN valid acc 0.9584')\n",
      "('Epoch 00000040 ', 'test loss 0.6527', 'test acc 0.7902')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7981', 'WORST test acc 0.7324')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7981', 'MIN test acc 0.7324')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0909', 'avg train acc ', '0.9682')\n",
      "('Epoch 00000050 ', 'valid loss 0.0839', 'valid acc 0.9714')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1286', 'WORST valid acc 0.9529')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1286', 'MIN valid acc 0.9529')\n",
      "('Epoch 00000050 ', 'test loss 0.7061', 'test acc 0.8160')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9769', 'WORST test acc 0.7778')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9193', 'MIN test acc 0.7500')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1118', 'avg train acc ', '0.9579')\n",
      "('Epoch 00000010 ', 'valid loss 0.1303', 'valid acc 0.9558')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1702', 'WORST valid acc 0.9450')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1702', 'MIN valid acc 0.9450')\n",
      "('Epoch 00000010 ', 'test loss 0.7768', 'test acc 0.7838')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1870', 'WORST test acc 0.7260')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1870', 'MIN test acc 0.7260')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0962', 'avg train acc ', '0.9652')\n",
      "('Epoch 00000020 ', 'valid loss 0.1007', 'valid acc 0.9648')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1337', 'WORST valid acc 0.9525')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1337', 'MIN valid acc 0.9525')\n",
      "('Epoch 00000020 ', 'test loss 0.7271', 'test acc 0.8022')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0808', 'WORST test acc 0.7510')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0808', 'MIN test acc 0.7510')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0848', 'avg train acc ', '0.9700')\n",
      "('Epoch 00000030 ', 'valid loss 0.0969', 'valid acc 0.9670')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1233', 'WORST valid acc 0.9582')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1233', 'MIN valid acc 0.9582')\n",
      "('Epoch 00000030 ', 'test loss 0.7440', 'test acc 0.8015')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2120', 'WORST test acc 0.7302')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2120', 'MIN test acc 0.7302')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0914', 'avg train acc ', '0.9706')\n",
      "('Epoch 00000040 ', 'valid loss 0.0839', 'valid acc 0.9707')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1098', 'WORST valid acc 0.9615')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1098', 'MIN valid acc 0.9615')\n",
      "('Epoch 00000040 ', 'test loss 0.6937', 'test acc 0.8070')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9963', 'WORST test acc 0.7514')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9963', 'MIN test acc 0.7514')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0896', 'avg train acc ', '0.9694')\n",
      "('Epoch 00000050 ', 'valid loss 0.0973', 'valid acc 0.9640')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1312', 'WORST valid acc 0.9451')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1312', 'MIN valid acc 0.9451')\n",
      "('Epoch 00000050 ', 'test loss 0.7453', 'test acc 0.7950')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0737', 'WORST test acc 0.7494')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0737', 'MIN test acc 0.7494')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0927', 'avg train acc ', '0.9680')\n",
      "('Epoch 00000010 ', 'valid loss 0.0883', 'valid acc 0.9729')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1076', 'WORST valid acc 0.9637')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1076', 'MIN valid acc 0.9637')\n",
      "('Epoch 00000010 ', 'test loss 0.8321', 'test acc 0.7622')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2193', 'WORST test acc 0.7180')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2193', 'MIN test acc 0.7180')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0959', 'avg train acc ', '0.9657')\n",
      "('Epoch 00000020 ', 'valid loss 0.1271', 'valid acc 0.9556')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1582', 'WORST valid acc 0.9443')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1463', 'MIN valid acc 0.9436')\n",
      "('Epoch 00000020 ', 'test loss 0.8769', 'test acc 0.7758')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3849', 'WORST test acc 0.7210')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3849', 'MIN test acc 0.7210')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.1015', 'avg train acc ', '0.9669')\n",
      "('Epoch 00000030 ', 'valid loss 0.0982', 'valid acc 0.9690')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1323', 'WORST valid acc 0.9550')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1323', 'MIN valid acc 0.9550')\n",
      "('Epoch 00000030 ', 'test loss 0.9421', 'test acc 0.7467')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3321', 'WORST test acc 0.6986')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3321', 'MIN test acc 0.6986')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0846', 'avg train acc ', '0.9721')\n",
      "('Epoch 00000040 ', 'valid loss 0.0863', 'valid acc 0.9659')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1296', 'WORST valid acc 0.9483')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1296', 'MIN valid acc 0.9483')\n",
      "('Epoch 00000040 ', 'test loss 1.0026', 'test acc 0.7708')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.5287', 'WORST test acc 0.7110')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.5287', 'MIN test acc 0.7110')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0847', 'avg train acc ', '0.9682')\n",
      "('Epoch 00000050 ', 'valid loss 0.0854', 'valid acc 0.9670')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1196', 'WORST valid acc 0.9515')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1078', 'MIN valid acc 0.9470')\n",
      "('Epoch 00000050 ', 'test loss 0.8873', 'test acc 0.7628')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1627', 'WORST test acc 0.7180')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1627', 'MIN test acc 0.7180')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1117', 'avg train acc ', '0.9607')\n",
      "('Epoch 00000010 ', 'valid loss 0.1118', 'valid acc 0.9591')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1482', 'WORST valid acc 0.9441')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1482', 'MIN valid acc 0.9441')\n",
      "('Epoch 00000010 ', 'test loss 0.7663', 'test acc 0.7725')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0018', 'WORST test acc 0.7380')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0018', 'MIN test acc 0.7380')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0992', 'avg train acc ', '0.9667')\n",
      "('Epoch 00000020 ', 'valid loss 0.1175', 'valid acc 0.9603')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1446', 'WORST valid acc 0.9536')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1416', 'MIN valid acc 0.9519')\n",
      "('Epoch 00000020 ', 'test loss 0.7213', 'test acc 0.7906')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0473', 'WORST test acc 0.7472')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0473', 'MIN test acc 0.7472')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0882', 'avg train acc ', '0.9675')\n",
      "('Epoch 00000030 ', 'valid loss 0.0885', 'valid acc 0.9679')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1149', 'WORST valid acc 0.9578')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1107', 'MIN valid acc 0.9518')\n",
      "('Epoch 00000030 ', 'test loss 0.6646', 'test acc 0.8004')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9562', 'WORST test acc 0.7318')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9562', 'MIN test acc 0.7318')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0961', 'avg train acc ', '0.9667')\n",
      "('Epoch 00000040 ', 'valid loss 0.1016', 'valid acc 0.9667')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1276', 'WORST valid acc 0.9559')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1276', 'MIN valid acc 0.9559')\n",
      "('Epoch 00000040 ', 'test loss 0.7107', 'test acc 0.8013')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0460', 'WORST test acc 0.7488')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0460', 'MIN test acc 0.7488')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0816', 'avg train acc ', '0.9710')\n",
      "('Epoch 00000050 ', 'valid loss 0.0773', 'valid acc 0.9719')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.0966', 'WORST valid acc 0.9631')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.0966', 'MIN valid acc 0.9631')\n",
      "('Epoch 00000050 ', 'test loss 0.7524', 'test acc 0.8053')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1562', 'WORST test acc 0.7380')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1562', 'MIN test acc 0.7380')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1014', 'avg train acc ', '0.9648')\n",
      "('Epoch 00000010 ', 'valid loss 0.1006', 'valid acc 0.9654')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1310', 'WORST valid acc 0.9515')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1310', 'MIN valid acc 0.9515')\n",
      "('Epoch 00000010 ', 'test loss 0.7103', 'test acc 0.7888')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0426', 'WORST test acc 0.7216')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0426', 'MIN test acc 0.7216')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0884', 'avg train acc ', '0.9677')\n",
      "('Epoch 00000020 ', 'valid loss 0.1020', 'valid acc 0.9665')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.1411', 'WORST valid acc 0.9530')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1405', 'MIN valid acc 0.9529')\n",
      "('Epoch 00000020 ', 'test loss 0.6997', 'test acc 0.7894')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8498', 'WORST test acc 0.7556')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8058', 'MIN test acc 0.7520')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0878', 'avg train acc ', '0.9700')\n",
      "('Epoch 00000030 ', 'valid loss 0.0925', 'valid acc 0.9635')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1092', 'WORST valid acc 0.9465')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1092', 'MIN valid acc 0.9465')\n",
      "('Epoch 00000030 ', 'test loss 0.7344', 'test acc 0.7650')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9187', 'WORST test acc 0.7232')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9187', 'MIN test acc 0.7232')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.1061', 'avg train acc ', '0.9624')\n",
      "('Epoch 00000040 ', 'valid loss 0.1023', 'valid acc 0.9654')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.1292', 'WORST valid acc 0.9550')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1285', 'MIN valid acc 0.9549')\n",
      "('Epoch 00000040 ', 'test loss 0.7204', 'test acc 0.7661')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8715', 'WORST test acc 0.7774')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6144', 'MIN test acc 0.7094')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0870', 'avg train acc ', '0.9686')\n",
      "('Epoch 00000050 ', 'valid loss 0.0969', 'valid acc 0.9664')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1339', 'WORST valid acc 0.9488')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1339', 'MIN valid acc 0.9488')\n",
      "('Epoch 00000050 ', 'test loss 0.7469', 'test acc 0.7716')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9659', 'WORST test acc 0.7794')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6169', 'MIN test acc 0.7270')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0962', 'avg train acc ', '0.9667')\n",
      "('Epoch 00000010 ', 'valid loss 0.1056', 'valid acc 0.9653')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1299', 'WORST valid acc 0.9572')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1299', 'MIN valid acc 0.9572')\n",
      "('Epoch 00000010 ', 'test loss 0.8329', 'test acc 0.7784')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1280', 'WORST test acc 0.7404')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1280', 'MIN test acc 0.7404')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0950', 'avg train acc ', '0.9674')\n",
      "('Epoch 00000020 ', 'valid loss 0.0951', 'valid acc 0.9697')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1264', 'WORST valid acc 0.9631')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1164', 'MIN valid acc 0.9599')\n",
      "('Epoch 00000020 ', 'test loss 0.7462', 'test acc 0.7763')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9595', 'WORST test acc 0.7168')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9595', 'MIN test acc 0.7168')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0935', 'avg train acc ', '0.9676')\n",
      "('Epoch 00000030 ', 'valid loss 0.0885', 'valid acc 0.9692')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1168', 'WORST valid acc 0.9578')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1168', 'MIN valid acc 0.9578')\n",
      "('Epoch 00000030 ', 'test loss 0.8450', 'test acc 0.7673')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0524', 'WORST test acc 0.7420')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.0524', 'MIN test acc 0.7420')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0791', 'avg train acc ', '0.9752')\n",
      "('Epoch 00000040 ', 'valid loss 0.0804', 'valid acc 0.9738')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1144', 'WORST valid acc 0.9615')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1144', 'MIN valid acc 0.9615')\n",
      "('Epoch 00000040 ', 'test loss 0.9326', 'test acc 0.7537')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3288', 'WORST test acc 0.7004')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3288', 'MIN test acc 0.7004')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0887', 'avg train acc ', '0.9735')\n",
      "('Epoch 00000050 ', 'valid loss 0.0892', 'valid acc 0.9725')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1212', 'WORST valid acc 0.9615')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1212', 'MIN valid acc 0.9615')\n",
      "('Epoch 00000050 ', 'test loss 0.8540', 'test acc 0.7633')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2407', 'WORST test acc 0.7200')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2407', 'MIN test acc 0.7200')\n",
      "===FINAL RESULTS WITH NODE 10===\n",
      "('VALID: acc 0.9682', 'accs sd 0.0041', 'loss 0.0907', 'loss sd 0.0076')\n",
      "('TEST: acc 0.7804', 'accs sd 0.0212', 'loss 0.8125', 'loss sd 0.1030')\n",
      "('WORST VALID: acc 0.9547', 'accs sd 0.0062', 'loss 0.1213', 'loss sd 0.0112')\n",
      "WORST VALID DOMAINS: [3, 0, 0, 0, 4, 0, 0, 0, 4, 3]\n",
      "('WORST TEST: acc 0.7461', 'accs sd 0.0255', 'loss 1.0994', 'loss sd 0.1665')\n",
      "WORST TEST DOMAINS: [2, 2, 2, 0, 0, 2, 2, 2, 0, 2]\n",
      "('MIN VALID: acc 0.9540', 'accs sd 0.0068', 'loss 0.1195', 'loss sd 0.0114')\n",
      "MIN VALID DOMAINS: [3, 1, 0, 0, 4, 0, 1, 0, 4, 3]\n",
      "('MIN TEST: acc 0.7350', 'accs sd 0.0139', 'loss 1.0392', 'loss sd 0.2382')\n",
      "MIN TEST DOMAINS: [2, 2, 0, 2, 2, 2, 2, 2, 4, 2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0824', 'avg train acc ', '0.9713')\n",
      "('Epoch 00000010 ', 'valid loss 0.0849', 'valid acc 0.9717')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1160', 'WORST valid acc 0.9637')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1077', 'MIN valid acc 0.9620')\n",
      "('Epoch 00000010 ', 'test loss 0.8421', 'test acc 0.7572')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1022', 'WORST test acc 0.7220')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1022', 'MIN test acc 0.7220')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0942', 'avg train acc ', '0.9651')\n",
      "('Epoch 00000020 ', 'valid loss 0.0963', 'valid acc 0.9634')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1379', 'WORST valid acc 0.9500')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1379', 'MIN valid acc 0.9500')\n",
      "('Epoch 00000020 ', 'test loss 1.0115', 'test acc 0.7556')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.3198', 'WORST test acc 0.7240')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2382', 'MIN test acc 0.7070')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0773', 'avg train acc ', '0.9720')\n",
      "('Epoch 00000030 ', 'valid loss 0.0845', 'valid acc 0.9711')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1214', 'WORST valid acc 0.9546')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1214', 'MIN valid acc 0.9546')\n",
      "('Epoch 00000030 ', 'test loss 0.8348', 'test acc 0.7870')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2440', 'WORST test acc 0.7284')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2440', 'MIN test acc 0.7284')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0682', 'avg train acc ', '0.9758')\n",
      "('Epoch 00000040 ', 'valid loss 0.0757', 'valid acc 0.9720')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1025', 'WORST valid acc 0.9629')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.0957', 'MIN valid acc 0.9604')\n",
      "('Epoch 00000040 ', 'test loss 1.0065', 'test acc 0.7859')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.3302', 'WORST test acc 0.7516')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.1621', 'MIN test acc 0.7468')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0733', 'avg train acc ', '0.9733')\n",
      "('Epoch 00000050 ', 'valid loss 0.0732', 'valid acc 0.9751')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.0949', 'WORST valid acc 0.9669')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.0949', 'MIN valid acc 0.9669')\n",
      "('Epoch 00000050 ', 'test loss 0.9439', 'test acc 0.7889')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2531', 'WORST test acc 0.7390')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2531', 'MIN test acc 0.7390')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0920', 'avg train acc ', '0.9668')\n",
      "('Epoch 00000010 ', 'valid loss 0.0918', 'valid acc 0.9665')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1162', 'WORST valid acc 0.9598')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1138', 'MIN valid acc 0.9593')\n",
      "('Epoch 00000010 ', 'test loss 0.8754', 'test acc 0.7671')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3258', 'WORST test acc 0.7106')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3258', 'MIN test acc 0.7106')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0809', 'avg train acc ', '0.9718')\n",
      "('Epoch 00000020 ', 'valid loss 0.0882', 'valid acc 0.9713')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1169', 'WORST valid acc 0.9557')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1169', 'MIN valid acc 0.9557')\n",
      "('Epoch 00000020 ', 'test loss 1.0019', 'test acc 0.7596')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.3043', 'WORST test acc 0.7502')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 1.2998', 'MIN test acc 0.7112')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0788', 'avg train acc ', '0.9716')\n",
      "('Epoch 00000030 ', 'valid loss 0.0915', 'valid acc 0.9675')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1223', 'WORST valid acc 0.9589')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1220', 'MIN valid acc 0.9525')\n",
      "('Epoch 00000030 ', 'test loss 1.2079', 'test acc 0.7401')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.7633', 'WORST test acc 0.7046')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 1.0814', 'MIN test acc 0.6908')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0706', 'avg train acc ', '0.9766')\n",
      "('Epoch 00000040 ', 'valid loss 0.0740', 'valid acc 0.9761')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1090', 'WORST valid acc 0.9715')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1013', 'MIN valid acc 0.9647')\n",
      "('Epoch 00000040 ', 'test loss 1.1096', 'test acc 0.7446')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.6372', 'WORST test acc 0.6990')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.6372', 'MIN test acc 0.6990')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0780', 'avg train acc ', '0.9724')\n",
      "('Epoch 00000050 ', 'valid loss 0.0751', 'valid acc 0.9751')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.0948', 'WORST valid acc 0.9684')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.0905', 'MIN valid acc 0.9670')\n",
      "('Epoch 00000050 ', 'test loss 1.1192', 'test acc 0.7706')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.5396', 'WORST test acc 0.7152')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.5396', 'MIN test acc 0.7152')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.1059', 'avg train acc ', '0.9631')\n",
      "('Epoch 00000010 ', 'valid loss 0.1158', 'valid acc 0.9628')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.1352', 'WORST valid acc 0.9609')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1217', 'MIN valid acc 0.9579')\n",
      "('Epoch 00000010 ', 'test loss 0.9376', 'test acc 0.7741')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2202', 'WORST test acc 0.7150')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2202', 'MIN test acc 0.7150')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0856', 'avg train acc ', '0.9688')\n",
      "('Epoch 00000020 ', 'valid loss 0.1028', 'valid acc 0.9665')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1631', 'WORST valid acc 0.9465')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1631', 'MIN valid acc 0.9465')\n",
      "('Epoch 00000020 ', 'test loss 0.9690', 'test acc 0.7911')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3741', 'WORST test acc 0.7488')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3741', 'MIN test acc 0.7488')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0858', 'avg train acc ', '0.9684')\n",
      "('Epoch 00000030 ', 'valid loss 0.0916', 'valid acc 0.9669')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1246', 'WORST valid acc 0.9546')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1246', 'MIN valid acc 0.9546')\n",
      "('Epoch 00000030 ', 'test loss 1.0437', 'test acc 0.7815')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.6109', 'WORST test acc 0.7288')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.6109', 'MIN test acc 0.7288')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0869', 'avg train acc ', '0.9690')\n",
      "('Epoch 00000040 ', 'valid loss 0.0915', 'valid acc 0.9677')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1178', 'WORST valid acc 0.9578')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1178', 'MIN valid acc 0.9578')\n",
      "('Epoch 00000040 ', 'test loss 0.9837', 'test acc 0.7750')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3027', 'WORST test acc 0.7346')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3027', 'MIN test acc 0.7346')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0810', 'avg train acc ', '0.9720')\n",
      "('Epoch 00000050 ', 'valid loss 0.0847', 'valid acc 0.9687')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1210', 'WORST valid acc 0.9631')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.0986', 'MIN valid acc 0.9568')\n",
      "('Epoch 00000050 ', 'test loss 1.0041', 'test acc 0.7802')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2629', 'WORST test acc 0.7376')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2629', 'MIN test acc 0.7376')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0919', 'avg train acc ', '0.9679')\n",
      "('Epoch 00000010 ', 'valid loss 0.1018', 'valid acc 0.9634')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1287', 'WORST valid acc 0.9619')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.1006', 'MIN valid acc 0.9574')\n",
      "('Epoch 00000010 ', 'test loss 0.8164', 'test acc 0.7797')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1791', 'WORST test acc 0.7170')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1791', 'MIN test acc 0.7170')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0870', 'avg train acc ', '0.9672')\n",
      "('Epoch 00000020 ', 'valid loss 0.1241', 'valid acc 0.9523')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1804', 'WORST valid acc 0.9287')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1741', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000020 ', 'test loss 0.8014', 'test acc 0.7810')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0637', 'WORST test acc 0.7378')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.0637', 'MIN test acc 0.7378')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0648', 'avg train acc ', '0.9767')\n",
      "('Epoch 00000030 ', 'valid loss 0.0693', 'valid acc 0.9758')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.0912', 'WORST valid acc 0.9683')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.0886', 'MIN valid acc 0.9641')\n",
      "('Epoch 00000030 ', 'test loss 0.7987', 'test acc 0.7927')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9866', 'WORST test acc 0.7632')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.9866', 'MIN test acc 0.7632')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0787', 'avg train acc ', '0.9716')\n",
      "('Epoch 00000040 ', 'valid loss 0.0910', 'valid acc 0.9665')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1195', 'WORST valid acc 0.9557')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1146', 'MIN valid acc 0.9529')\n",
      "('Epoch 00000040 ', 'test loss 0.9681', 'test acc 0.7642')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2395', 'WORST test acc 0.7400')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2395', 'MIN test acc 0.7400')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0702', 'avg train acc ', '0.9748')\n",
      "('Epoch 00000050 ', 'valid loss 0.0735', 'valid acc 0.9722')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.0931', 'WORST valid acc 0.9673')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.0865', 'MIN valid acc 0.9657')\n",
      "('Epoch 00000050 ', 'test loss 0.8921', 'test acc 0.7810')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1860', 'WORST test acc 0.7528')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1860', 'MIN test acc 0.7528')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0912', 'avg train acc ', '0.9672')\n",
      "('Epoch 00000010 ', 'valid loss 0.1118', 'valid acc 0.9582')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1519', 'WORST valid acc 0.9475')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1519', 'MIN valid acc 0.9475')\n",
      "('Epoch 00000010 ', 'test loss 0.9254', 'test acc 0.7629')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2836', 'WORST test acc 0.7158')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2836', 'MIN test acc 0.7158')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0801', 'avg train acc ', '0.9706')\n",
      "('Epoch 00000020 ', 'valid loss 0.0777', 'valid acc 0.9742')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1139', 'WORST valid acc 0.9668')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1139', 'MIN valid acc 0.9668')\n",
      "('Epoch 00000020 ', 'test loss 0.9571', 'test acc 0.7667')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3776', 'WORST test acc 0.7184')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3776', 'MIN test acc 0.7184')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0769', 'avg train acc ', '0.9709')\n",
      "('Epoch 00000030 ', 'valid loss 0.0833', 'valid acc 0.9671')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1167', 'WORST valid acc 0.9500')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1167', 'MIN valid acc 0.9500')\n",
      "('Epoch 00000030 ', 'test loss 1.0691', 'test acc 0.7458')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.4375', 'WORST test acc 0.7186')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.4375', 'MIN test acc 0.7186')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0795', 'avg train acc ', '0.9693')\n",
      "('Epoch 00000040 ', 'valid loss 0.0816', 'valid acc 0.9681')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1052', 'WORST valid acc 0.9625')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1032', 'MIN valid acc 0.9568')\n",
      "('Epoch 00000040 ', 'test loss 0.9931', 'test acc 0.7546')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.2793', 'WORST test acc 0.7262')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2170', 'MIN test acc 0.6976')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0755', 'avg train acc ', '0.9721')\n",
      "('Epoch 00000050 ', 'valid loss 0.0896', 'valid acc 0.9690')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1159', 'WORST valid acc 0.9610')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1159', 'MIN valid acc 0.9610')\n",
      "('Epoch 00000050 ', 'test loss 0.8495', 'test acc 0.7716')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9699', 'WORST test acc 0.7510')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9659', 'MIN test acc 0.7382')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0955', 'avg train acc ', '0.9657')\n",
      "('Epoch 00000010 ', 'valid loss 0.0981', 'valid acc 0.9630')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1199', 'WORST valid acc 0.9557')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1100', 'MIN valid acc 0.9525')\n",
      "('Epoch 00000010 ', 'test loss 0.7175', 'test acc 0.7776')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.9899', 'WORST test acc 0.7436')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7366', 'MIN test acc 0.7372')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0811', 'avg train acc ', '0.9719')\n",
      "('Epoch 00000020 ', 'valid loss 0.0839', 'valid acc 0.9694')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1142', 'WORST valid acc 0.9568')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1142', 'MIN valid acc 0.9568')\n",
      "('Epoch 00000020 ', 'test loss 0.7911', 'test acc 0.7775')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1956', 'WORST test acc 0.7274')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1956', 'MIN test acc 0.7274')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0831', 'avg train acc ', '0.9707')\n",
      "('Epoch 00000030 ', 'valid loss 0.0865', 'valid acc 0.9702')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1186', 'WORST valid acc 0.9589')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1186', 'MIN valid acc 0.9589')\n",
      "('Epoch 00000030 ', 'test loss 0.9032', 'test acc 0.7727')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3927', 'WORST test acc 0.7270')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3927', 'MIN test acc 0.7270')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0787', 'avg train acc ', '0.9730')\n",
      "('Epoch 00000040 ', 'valid loss 0.0810', 'valid acc 0.9714')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1066', 'WORST valid acc 0.9589')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1066', 'MIN valid acc 0.9589')\n",
      "('Epoch 00000040 ', 'test loss 0.9058', 'test acc 0.7796')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3589', 'WORST test acc 0.7072')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3589', 'MIN test acc 0.7072')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0879', 'avg train acc ', '0.9673')\n",
      "('Epoch 00000050 ', 'valid loss 0.0886', 'valid acc 0.9668')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1232', 'WORST valid acc 0.9504')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1232', 'MIN valid acc 0.9504')\n",
      "('Epoch 00000050 ', 'test loss 0.8082', 'test acc 0.7850')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0591', 'WORST test acc 0.7382')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0591', 'MIN test acc 0.7382')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0907', 'avg train acc ', '0.9670')\n",
      "('Epoch 00000010 ', 'valid loss 0.1017', 'valid acc 0.9687')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1251', 'WORST valid acc 0.9536')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1251', 'MIN valid acc 0.9536')\n",
      "('Epoch 00000010 ', 'test loss 0.7939', 'test acc 0.7925')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0585', 'WORST test acc 0.7572')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.0585', 'MIN test acc 0.7572')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0884', 'avg train acc ', '0.9673')\n",
      "('Epoch 00000020 ', 'valid loss 0.0941', 'valid acc 0.9642')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1137', 'WORST valid acc 0.9578')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1045', 'MIN valid acc 0.9568')\n",
      "('Epoch 00000020 ', 'test loss 0.8188', 'test acc 0.7906')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1880', 'WORST test acc 0.7512')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1880', 'MIN test acc 0.7512')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0697', 'avg train acc ', '0.9738')\n",
      "('Epoch 00000030 ', 'valid loss 0.0796', 'valid acc 0.9695')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1227', 'WORST valid acc 0.9470')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1227', 'MIN valid acc 0.9470')\n",
      "('Epoch 00000030 ', 'test loss 0.8900', 'test acc 0.7760')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.1430', 'WORST test acc 0.7370')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.1430', 'MIN test acc 0.7370')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0694', 'avg train acc ', '0.9769')\n",
      "('Epoch 00000040 ', 'valid loss 0.0764', 'valid acc 0.9722')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1007', 'WORST valid acc 0.9657')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1003', 'MIN valid acc 0.9599')\n",
      "('Epoch 00000040 ', 'test loss 0.9961', 'test acc 0.7860')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3909', 'WORST test acc 0.7482')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3909', 'MIN test acc 0.7482')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0638', 'avg train acc ', '0.9765')\n",
      "('Epoch 00000050 ', 'valid loss 0.0642', 'valid acc 0.9765')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.0904', 'WORST valid acc 0.9615')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.0904', 'MIN valid acc 0.9615')\n",
      "('Epoch 00000050 ', 'test loss 1.0082', 'test acc 0.7820')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.2228', 'WORST test acc 0.7594')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 1.0010', 'MIN test acc 0.7566')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0976', 'avg train acc ', '0.9638')\n",
      "('Epoch 00000010 ', 'valid loss 0.0973', 'valid acc 0.9650')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1393', 'WORST valid acc 0.9507')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1393', 'MIN valid acc 0.9507')\n",
      "('Epoch 00000010 ', 'test loss 0.7948', 'test acc 0.7772')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.3081', 'WORST test acc 0.7196')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.3081', 'MIN test acc 0.7196')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0883', 'avg train acc ', '0.9676')\n",
      "('Epoch 00000020 ', 'valid loss 0.0976', 'valid acc 0.9623')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1348', 'WORST valid acc 0.9515')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1099', 'MIN valid acc 0.9500')\n",
      "('Epoch 00000020 ', 'test loss 0.7952', 'test acc 0.7916')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0307', 'WORST test acc 0.7654')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.7888', 'MIN test acc 0.7640')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0723', 'avg train acc ', '0.9736')\n",
      "('Epoch 00000030 ', 'valid loss 0.0764', 'valid acc 0.9697')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1033', 'WORST valid acc 0.9525')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1033', 'MIN valid acc 0.9525')\n",
      "('Epoch 00000030 ', 'test loss 0.6238', 'test acc 0.8148')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7938', 'WORST test acc 0.7904')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7768', 'MIN test acc 0.7862')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0733', 'avg train acc ', '0.9740')\n",
      "('Epoch 00000040 ', 'valid loss 0.0862', 'valid acc 0.9683')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1241', 'WORST valid acc 0.9536')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1241', 'MIN valid acc 0.9536')\n",
      "('Epoch 00000040 ', 'test loss 0.8274', 'test acc 0.7928')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1368', 'WORST test acc 0.7508')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1368', 'MIN test acc 0.7508')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0743', 'avg train acc ', '0.9728')\n",
      "('Epoch 00000050 ', 'valid loss 0.0742', 'valid acc 0.9760')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1101', 'WORST valid acc 0.9610')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1101', 'MIN valid acc 0.9610')\n",
      "('Epoch 00000050 ', 'test loss 0.7715', 'test acc 0.8058')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.1089', 'WORST test acc 0.7468')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.1089', 'MIN test acc 0.7468')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0935', 'avg train acc ', '0.9663')\n",
      "('Epoch 00000010 ', 'valid loss 0.0940', 'valid acc 0.9676')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1137', 'WORST valid acc 0.9557')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1137', 'MIN valid acc 0.9557')\n",
      "('Epoch 00000010 ', 'test loss 0.7129', 'test acc 0.7950')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0299', 'WORST test acc 0.7554')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.0299', 'MIN test acc 0.7554')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0811', 'avg train acc ', '0.9710')\n",
      "('Epoch 00000020 ', 'valid loss 0.0916', 'valid acc 0.9654')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1218', 'WORST valid acc 0.9518')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1218', 'MIN valid acc 0.9518')\n",
      "('Epoch 00000020 ', 'test loss 0.9117', 'test acc 0.7832')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2278', 'WORST test acc 0.7278')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2278', 'MIN test acc 0.7278')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0838', 'avg train acc ', '0.9712')\n",
      "('Epoch 00000030 ', 'valid loss 0.0908', 'valid acc 0.9693')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1360', 'WORST valid acc 0.9549')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1360', 'MIN valid acc 0.9549')\n",
      "('Epoch 00000030 ', 'test loss 0.7437', 'test acc 0.7997')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9721', 'WORST test acc 0.7430')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9721', 'MIN test acc 0.7430')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0822', 'avg train acc ', '0.9682')\n",
      "('Epoch 00000040 ', 'valid loss 0.1018', 'valid acc 0.9641')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1440', 'WORST valid acc 0.9460')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1440', 'MIN valid acc 0.9460')\n",
      "('Epoch 00000040 ', 'test loss 0.7562', 'test acc 0.8030')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0682', 'WORST test acc 0.7570')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7843', 'MIN test acc 0.7556')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0772', 'avg train acc ', '0.9720')\n",
      "('Epoch 00000050 ', 'valid loss 0.0863', 'valid acc 0.9693')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1189', 'WORST valid acc 0.9662')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.0891', 'MIN valid acc 0.9619')\n",
      "('Epoch 00000050 ', 'test loss 0.8009', 'test acc 0.7909')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 1.0657', 'WORST test acc 0.7442')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 1.0657', 'MIN test acc 0.7442')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.0972', 'avg train acc ', '0.9651')\n",
      "('Epoch 00000010 ', 'valid loss 0.1244', 'valid acc 0.9586')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1806', 'WORST valid acc 0.9399')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1806', 'MIN valid acc 0.9399')\n",
      "('Epoch 00000010 ', 'test loss 0.7149', 'test acc 0.8089')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.8596', 'WORST test acc 0.7896')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8447', 'MIN test acc 0.7664')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.0770', 'avg train acc ', '0.9725')\n",
      "('Epoch 00000020 ', 'valid loss 0.0954', 'valid acc 0.9653')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1250', 'WORST valid acc 0.9569')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1196', 'MIN valid acc 0.9558')\n",
      "('Epoch 00000020 ', 'test loss 0.8343', 'test acc 0.7982')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0350', 'WORST test acc 0.7504')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0350', 'MIN test acc 0.7504')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.0833', 'avg train acc ', '0.9700')\n",
      "('Epoch 00000030 ', 'valid loss 0.0830', 'valid acc 0.9718')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1193', 'WORST valid acc 0.9579')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1193', 'MIN valid acc 0.9579')\n",
      "('Epoch 00000030 ', 'test loss 0.7254', 'test acc 0.7912')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9115', 'WORST test acc 0.7514')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9115', 'MIN test acc 0.7514')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.0813', 'avg train acc ', '0.9705')\n",
      "('Epoch 00000040 ', 'valid loss 0.0899', 'valid acc 0.9707')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1370', 'WORST valid acc 0.9599')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1370', 'MIN valid acc 0.9599')\n",
      "('Epoch 00000040 ', 'test loss 0.7816', 'test acc 0.8026')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.0881', 'WORST test acc 0.7622')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.0881', 'MIN test acc 0.7622')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.0771', 'avg train acc ', '0.9707')\n",
      "('Epoch 00000050 ', 'valid loss 0.0742', 'valid acc 0.9738')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.0990', 'WORST valid acc 0.9652')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.0990', 'MIN valid acc 0.9652')\n",
      "('Epoch 00000050 ', 'test loss 0.7737', 'test acc 0.7896')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 1.2114', 'WORST test acc 0.7362')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 1.2114', 'MIN test acc 0.7362')\n",
      "===FINAL RESULTS WITH NODE 15===\n",
      "('VALID: acc 0.9722', 'accs sd 0.0034', 'loss 0.0784', 'loss sd 0.0079')\n",
      "('TEST: acc 0.7846', 'accs sd 0.0097', 'loss 0.8971', 'loss sd 0.1121')\n",
      "('WORST VALID: acc 0.9631', 'accs sd 0.0050', 'loss 0.1062', 'loss sd 0.0123')\n",
      "WORST VALID DOMAINS: [4, 0, 0, 0, 0, 0, 3, 0, 0, 0]\n",
      "('WORST TEST: acc 0.7420', 'accs sd 0.0115', 'loss 1.1879', 'loss sd 0.1485')\n",
      "WORST TEST DOMAINS: [2, 2, 2, 2, 0, 2, 0, 2, 0, 2]\n",
      "('MIN VALID: acc 0.9617', 'accs sd 0.0049', 'loss 0.0998', 'loss sd 0.0119')\n",
      "MIN VALID DOMAINS: [4, 5, 1, 3, 0, 0, 3, 0, 9, 0]\n",
      "('MIN TEST: acc 0.7405', 'accs sd 0.0107', 'loss 1.1653', 'loss sd 0.1584')\n",
      "MIN TEST DOMAINS: [2, 2, 2, 2, 2, 2, 3, 2, 0, 2]\n",
      "===MAXIMUM LOSS FUNCTION===\n",
      "===ITERATION 1===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6643', 'avg train acc ', '0.8901')\n",
      "('Epoch 00000010 ', 'valid loss 0.4570', 'valid acc 0.8357')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4570', 'WORST valid acc 0.8319')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4561', 'MIN valid acc 0.8184')\n",
      "('Epoch 00000010 ', 'test loss 0.7086', 'test acc 0.7408')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.7086', 'WORST test acc 0.7528')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6469', 'MIN test acc 0.7078')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6725', 'avg train acc ', '0.8496')\n",
      "('Epoch 00000020 ', 'valid loss 0.4703', 'valid acc 0.8681')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.4703', 'WORST valid acc 0.8500')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.4703', 'MIN valid acc 0.8500')\n",
      "('Epoch 00000020 ', 'test loss 0.6447', 'test acc 0.7709')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6447', 'WORST test acc 0.7966')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6242', 'MIN test acc 0.7154')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6648', 'avg train acc ', '0.8706')\n",
      "('Epoch 00000030 ', 'valid loss 0.4596', 'valid acc 0.8796')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.4596', 'WORST valid acc 0.8745')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4558', 'MIN valid acc 0.8636')\n",
      "('Epoch 00000030 ', 'test loss 0.5751', 'test acc 0.8081')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.5751', 'WORST test acc 0.8106')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5615', 'MIN test acc 0.7770')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6601', 'avg train acc ', '0.9000')\n",
      "('Epoch 00000040 ', 'valid loss 0.4828', 'valid acc 0.9035')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4828', 'WORST valid acc 0.8783')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4828', 'MIN valid acc 0.8783')\n",
      "('Epoch 00000040 ', 'test loss 0.6300', 'test acc 0.7576')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6300', 'WORST test acc 0.7666')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5951', 'MIN test acc 0.7256')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6711', 'avg train acc ', '0.8444')\n",
      "('Epoch 00000050 ', 'valid loss 0.4505', 'valid acc 0.8647')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.4505', 'WORST valid acc 0.8370')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.4505', 'MIN valid acc 0.8370')\n",
      "('Epoch 00000050 ', 'test loss 0.6862', 'test acc 0.7734')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6862', 'WORST test acc 0.7064')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6862', 'MIN test acc 0.7064')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6626', 'avg train acc ', '0.8925')\n",
      "('Epoch 00000010 ', 'valid loss 0.4981', 'valid acc 0.9062')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4981', 'WORST valid acc 0.8961')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.4893', 'MIN valid acc 0.8917')\n",
      "('Epoch 00000010 ', 'test loss 0.6199', 'test acc 0.8078')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6199', 'WORST test acc 0.8206')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5809', 'MIN test acc 0.7738')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6728', 'avg train acc ', '0.8944')\n",
      "('Epoch 00000020 ', 'valid loss 0.5213', 'valid acc 0.9006')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.5213', 'WORST valid acc 0.8871')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.5213', 'MIN valid acc 0.8871')\n",
      "('Epoch 00000020 ', 'test loss 0.6251', 'test acc 0.7383')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6251', 'WORST test acc 0.6926')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6251', 'MIN test acc 0.6926')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6588', 'avg train acc ', '0.9078')\n",
      "('Epoch 00000030 ', 'valid loss 0.5104', 'valid acc 0.9144')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.5104', 'WORST valid acc 0.9030')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.5104', 'MIN valid acc 0.9030')\n",
      "('Epoch 00000030 ', 'test loss 0.6241', 'test acc 0.7724')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6241', 'WORST test acc 0.7760')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5912', 'MIN test acc 0.7484')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6680', 'avg train acc ', '0.8955')\n",
      "('Epoch 00000040 ', 'valid loss 0.4799', 'valid acc 0.9126')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4799', 'WORST valid acc 0.9019')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4799', 'MIN valid acc 0.9019')\n",
      "('Epoch 00000040 ', 'test loss 0.6006', 'test acc 0.7652')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6006', 'WORST test acc 0.7120')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6006', 'MIN test acc 0.7120')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6556', 'avg train acc ', '0.9072')\n",
      "('Epoch 00000050 ', 'valid loss 0.4565', 'valid acc 0.9124')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4565', 'WORST valid acc 0.9090')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.4481', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000050 ', 'test loss 0.6115', 'test acc 0.7678')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6115', 'WORST test acc 0.7250')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5467', 'MIN test acc 0.7236')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6608', 'avg train acc ', '0.8886')\n",
      "('Epoch 00000010 ', 'valid loss 0.4677', 'valid acc 0.8983')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4677', 'WORST valid acc 0.9079')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4646', 'MIN valid acc 0.8726')\n",
      "('Epoch 00000010 ', 'test loss 0.6042', 'test acc 0.7726')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6042', 'WORST test acc 0.7774')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5784', 'MIN test acc 0.7306')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6558', 'avg train acc ', '0.9049')\n",
      "('Epoch 00000020 ', 'valid loss 0.4406', 'valid acc 0.9169')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4406', 'WORST valid acc 0.9028')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4406', 'MIN valid acc 0.9028')\n",
      "('Epoch 00000020 ', 'test loss 0.5754', 'test acc 0.7743')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5754', 'WORST test acc 0.7402')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5754', 'MIN test acc 0.7402')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6543', 'avg train acc ', '0.9012')\n",
      "('Epoch 00000030 ', 'valid loss 0.4572', 'valid acc 0.9148')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4572', 'WORST valid acc 0.9111')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.4525', 'MIN valid acc 0.9044')\n",
      "('Epoch 00000030 ', 'test loss 0.5832', 'test acc 0.7652')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5832', 'WORST test acc 0.8042')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5767', 'MIN test acc 0.7304')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6597', 'avg train acc ', '0.9081')\n",
      "('Epoch 00000040 ', 'valid loss 0.4339', 'valid acc 0.9041')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4339', 'WORST valid acc 0.8816')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4339', 'MIN valid acc 0.8816')\n",
      "('Epoch 00000040 ', 'test loss 0.5976', 'test acc 0.7568')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5976', 'WORST test acc 0.7954')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5747', 'MIN test acc 0.7218')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6586', 'avg train acc ', '0.9074')\n",
      "('Epoch 00000050 ', 'valid loss 0.4472', 'valid acc 0.9115')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4472', 'WORST valid acc 0.8967')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4472', 'MIN valid acc 0.8967')\n",
      "('Epoch 00000050 ', 'test loss 0.6044', 'test acc 0.7369')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6044', 'WORST test acc 0.7126')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5932', 'MIN test acc 0.6992')\n",
      "===ITERATION 4===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6536', 'avg train acc ', '0.9001')\n",
      "('Epoch 00000010 ', 'valid loss 0.4040', 'valid acc 0.9102')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4040', 'WORST valid acc 0.9101')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3980', 'MIN valid acc 0.8927')\n",
      "('Epoch 00000010 ', 'test loss 0.6289', 'test acc 0.7626')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6289', 'WORST test acc 0.7230')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6289', 'MIN test acc 0.7230')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6700', 'avg train acc ', '0.8980')\n",
      "('Epoch 00000020 ', 'valid loss 0.4649', 'valid acc 0.9055')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4649', 'WORST valid acc 0.8871')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4649', 'MIN valid acc 0.8871')\n",
      "('Epoch 00000020 ', 'test loss 0.6037', 'test acc 0.7449')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6037', 'WORST test acc 0.7060')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6037', 'MIN test acc 0.7060')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6575', 'avg train acc ', '0.8864')\n",
      "('Epoch 00000030 ', 'valid loss 0.4245', 'valid acc 0.8992')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4245', 'WORST valid acc 0.8919')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.4229', 'MIN valid acc 0.8819')\n",
      "('Epoch 00000030 ', 'test loss 0.6110', 'test acc 0.7802')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6110', 'WORST test acc 0.7420')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5625', 'MIN test acc 0.7396')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6530', 'avg train acc ', '0.8974')\n",
      "('Epoch 00000040 ', 'valid loss 0.4096', 'valid acc 0.9031')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.4096', 'WORST valid acc 0.8930')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.4096', 'MIN valid acc 0.8930')\n",
      "('Epoch 00000040 ', 'test loss 0.6168', 'test acc 0.7791')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6168', 'WORST test acc 0.7414')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5632', 'MIN test acc 0.7364')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6523', 'avg train acc ', '0.9108')\n",
      "('Epoch 00000050 ', 'valid loss 0.4434', 'valid acc 0.9134')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4434', 'WORST valid acc 0.8837')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4434', 'MIN valid acc 0.8837')\n",
      "('Epoch 00000050 ', 'test loss 0.5978', 'test acc 0.7603')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5978', 'WORST test acc 0.7242')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5978', 'MIN test acc 0.7242')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6640', 'avg train acc ', '0.9034')\n",
      "('Epoch 00000010 ', 'valid loss 0.4371', 'valid acc 0.9156')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.4371', 'WORST valid acc 0.9072')\n",
      "('WORST ACC DOMAIN 00000007 ', 'WORST ACC valid loss 0.4237', 'MIN valid acc 0.9041')\n",
      "('Epoch 00000010 ', 'test loss 0.5789', 'test acc 0.7880')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.5789', 'WORST test acc 0.7892')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5680', 'MIN test acc 0.7574')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6479', 'avg train acc ', '0.9074')\n",
      "('Epoch 00000020 ', 'valid loss 0.4517', 'valid acc 0.9137')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4517', 'WORST valid acc 0.9122')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4355', 'MIN valid acc 0.8987')\n",
      "('Epoch 00000020 ', 'test loss 0.6233', 'test acc 0.7613')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6233', 'WORST test acc 0.8174')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5819', 'MIN test acc 0.7158')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6694', 'avg train acc ', '0.8434')\n",
      "('Epoch 00000030 ', 'valid loss 0.4255', 'valid acc 0.8964')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4255', 'WORST valid acc 0.8696')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4255', 'MIN valid acc 0.8696')\n",
      "('Epoch 00000030 ', 'test loss 0.6242', 'test acc 0.7860')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6242', 'WORST test acc 0.7356')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6242', 'MIN test acc 0.7356')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6560', 'avg train acc ', '0.8924')\n",
      "('Epoch 00000040 ', 'valid loss 0.4393', 'valid acc 0.9126')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.4393', 'WORST valid acc 0.9082')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4368', 'MIN valid acc 0.8847')\n",
      "('Epoch 00000040 ', 'test loss 0.5812', 'test acc 0.7954')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5812', 'WORST test acc 0.8288')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5540', 'MIN test acc 0.7640')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6565', 'avg train acc ', '0.9103')\n",
      "('Epoch 00000050 ', 'valid loss 0.4621', 'valid acc 0.9177')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4621', 'WORST valid acc 0.9101')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4591', 'MIN valid acc 0.9067')\n",
      "('Epoch 00000050 ', 'test loss 0.5781', 'test acc 0.7794')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5781', 'WORST test acc 0.7374')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5781', 'MIN test acc 0.7374')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6600', 'avg train acc ', '0.8852')\n",
      "('Epoch 00000010 ', 'valid loss 0.4548', 'valid acc 0.8886')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4548', 'WORST valid acc 0.8656')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4548', 'MIN valid acc 0.8656')\n",
      "('Epoch 00000010 ', 'test loss 0.6393', 'test acc 0.7380')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6393', 'WORST test acc 0.6790')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6393', 'MIN test acc 0.6790')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6619', 'avg train acc ', '0.8964')\n",
      "('Epoch 00000020 ', 'valid loss 0.4673', 'valid acc 0.9019')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4673', 'WORST valid acc 0.8857')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4673', 'MIN valid acc 0.8857')\n",
      "('Epoch 00000020 ', 'test loss 0.5883', 'test acc 0.7810')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.5883', 'WORST test acc 0.7914')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5841', 'MIN test acc 0.7442')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6599', 'avg train acc ', '0.8752')\n",
      "('Epoch 00000030 ', 'valid loss 0.4253', 'valid acc 0.8967')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4253', 'WORST valid acc 0.8862')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4181', 'MIN valid acc 0.8756')\n",
      "('Epoch 00000030 ', 'test loss 0.6813', 'test acc 0.7594')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6813', 'WORST test acc 0.7620')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5734', 'MIN test acc 0.7202')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6747', 'avg train acc ', '0.8936')\n",
      "('Epoch 00000040 ', 'valid loss 0.4779', 'valid acc 0.9009')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4779', 'WORST valid acc 0.8786')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4779', 'MIN valid acc 0.8786')\n",
      "('Epoch 00000040 ', 'test loss 0.6192', 'test acc 0.7532')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6192', 'WORST test acc 0.7850')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6018', 'MIN test acc 0.6898')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6530', 'avg train acc ', '0.8961')\n",
      "('Epoch 00000050 ', 'valid loss 0.4367', 'valid acc 0.8805')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4367', 'WORST valid acc 0.8865')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4245', 'MIN valid acc 0.8676')\n",
      "('Epoch 00000050 ', 'test loss 0.5743', 'test acc 0.8052')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5743', 'WORST test acc 0.7700')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5743', 'MIN test acc 0.7700')\n",
      "===ITERATION 7===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6789', 'avg train acc ', '0.8665')\n",
      "('Epoch 00000010 ', 'valid loss 0.5144', 'valid acc 0.8908')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5144', 'WORST valid acc 0.8676')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5144', 'MIN valid acc 0.8676')\n",
      "('Epoch 00000010 ', 'test loss 0.6447', 'test acc 0.7471')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6447', 'WORST test acc 0.7134')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.6447', 'MIN test acc 0.7134')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6658', 'avg train acc ', '0.8973')\n",
      "('Epoch 00000020 ', 'valid loss 0.4486', 'valid acc 0.9054')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4486', 'WORST valid acc 0.9079')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4469', 'MIN valid acc 0.8806')\n",
      "('Epoch 00000020 ', 'test loss 0.6307', 'test acc 0.7351')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6307', 'WORST test acc 0.7734')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6018', 'MIN test acc 0.6844')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6618', 'avg train acc ', '0.8867')\n",
      "('Epoch 00000030 ', 'valid loss 0.4653', 'valid acc 0.8940')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4653', 'WORST valid acc 0.8506')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4653', 'MIN valid acc 0.8506')\n",
      "('Epoch 00000030 ', 'test loss 0.6092', 'test acc 0.7568')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6092', 'WORST test acc 0.7190')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5612', 'MIN test acc 0.7166')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6642', 'avg train acc ', '0.8866')\n",
      "('Epoch 00000040 ', 'valid loss 0.4774', 'valid acc 0.8970')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4774', 'WORST valid acc 0.8536')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4774', 'MIN valid acc 0.8536')\n",
      "('Epoch 00000040 ', 'test loss 0.6285', 'test acc 0.7991')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6285', 'WORST test acc 0.8058')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5793', 'MIN test acc 0.7516')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6686', 'avg train acc ', '0.8793')\n",
      "('Epoch 00000050 ', 'valid loss 0.4591', 'valid acc 0.8972')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4591', 'WORST valid acc 0.8435')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4591', 'MIN valid acc 0.8435')\n",
      "('Epoch 00000050 ', 'test loss 0.5918', 'test acc 0.7667')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.5918', 'WORST test acc 0.7820')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5844', 'MIN test acc 0.6962')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6683', 'avg train acc ', '0.8614')\n",
      "('Epoch 00000010 ', 'valid loss 0.5368', 'valid acc 0.8676')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.5368', 'WORST valid acc 0.8405')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.5306', 'MIN valid acc 0.8315')\n",
      "('Epoch 00000010 ', 'test loss 0.6415', 'test acc 0.7417')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6415', 'WORST test acc 0.7804')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6298', 'MIN test acc 0.6890')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6697', 'avg train acc ', '0.8978')\n",
      "('Epoch 00000020 ', 'valid loss 0.5045', 'valid acc 0.9137')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.5045', 'WORST valid acc 0.9026')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.5015', 'MIN valid acc 0.8979')\n",
      "('Epoch 00000020 ', 'test loss 0.6262', 'test acc 0.7538')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6262', 'WORST test acc 0.7760')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6250', 'MIN test acc 0.6962')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6686', 'avg train acc ', '0.8794')\n",
      "('Epoch 00000030 ', 'valid loss 0.4956', 'valid acc 0.8743')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4956', 'WORST valid acc 0.8375')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4956', 'MIN valid acc 0.8375')\n",
      "('Epoch 00000030 ', 'test loss 0.6358', 'test acc 0.7643')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6358', 'WORST test acc 0.7598')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5980', 'MIN test acc 0.7116')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6502', 'avg train acc ', '0.9075')\n",
      "('Epoch 00000040 ', 'valid loss 0.4889', 'valid acc 0.9175')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4889', 'WORST valid acc 0.9026')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.4889', 'MIN valid acc 0.9026')\n",
      "('Epoch 00000040 ', 'test loss 0.6051', 'test acc 0.7756')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6051', 'WORST test acc 0.8208')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5851', 'MIN test acc 0.7348')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6568', 'avg train acc ', '0.8669')\n",
      "('Epoch 00000050 ', 'valid loss 0.4759', 'valid acc 0.8662')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4759', 'WORST valid acc 0.8325')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4759', 'MIN valid acc 0.8325')\n",
      "('Epoch 00000050 ', 'test loss 0.6280', 'test acc 0.7506')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6280', 'WORST test acc 0.8118')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5989', 'MIN test acc 0.7060')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6689', 'avg train acc ', '0.8971')\n",
      "('Epoch 00000010 ', 'valid loss 0.5160', 'valid acc 0.8876')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.5160', 'WORST valid acc 0.8565')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.5160', 'MIN valid acc 0.8565')\n",
      "('Epoch 00000010 ', 'test loss 0.6198', 'test acc 0.7468')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6198', 'WORST test acc 0.6730')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6198', 'MIN test acc 0.6730')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6597', 'avg train acc ', '0.9016')\n",
      "('Epoch 00000020 ', 'valid loss 0.4719', 'valid acc 0.9108')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4719', 'WORST valid acc 0.9028')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.4693', 'MIN valid acc 0.9027')\n",
      "('Epoch 00000020 ', 'test loss 0.5943', 'test acc 0.7614')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5943', 'WORST test acc 0.7084')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5943', 'MIN test acc 0.7084')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6579', 'avg train acc ', '0.9008')\n",
      "('Epoch 00000030 ', 'valid loss 0.4319', 'valid acc 0.9086')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4319', 'WORST valid acc 0.9079')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.4279', 'MIN valid acc 0.8997')\n",
      "('Epoch 00000030 ', 'test loss 0.5913', 'test acc 0.7786')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5913', 'WORST test acc 0.7410')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5643', 'MIN test acc 0.7268')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6604', 'avg train acc ', '0.8869')\n",
      "('Epoch 00000040 ', 'valid loss 0.4656', 'valid acc 0.9026')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4656', 'WORST valid acc 0.8983')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4645', 'MIN valid acc 0.8911')\n",
      "('Epoch 00000040 ', 'test loss 0.6695', 'test acc 0.7717')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6695', 'WORST test acc 0.7832')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5822', 'MIN test acc 0.7416')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6711', 'avg train acc ', '0.8804')\n",
      "('Epoch 00000050 ', 'valid loss 0.5221', 'valid acc 0.8998')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.5221', 'WORST valid acc 0.8365')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.5221', 'MIN valid acc 0.8365')\n",
      "('Epoch 00000050 ', 'test loss 0.6158', 'test acc 0.7632')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6158', 'WORST test acc 0.8076')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6014', 'MIN test acc 0.7218')\n",
      "===ITERATION 10===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6711', 'avg train acc ', '0.8961')\n",
      "('Epoch 00000010 ', 'valid loss 0.4959', 'valid acc 0.9051')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4959', 'WORST valid acc 0.8746')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4959', 'MIN valid acc 0.8746')\n",
      "('Epoch 00000010 ', 'test loss 0.6096', 'test acc 0.7583')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6096', 'WORST test acc 0.8054')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5952', 'MIN test acc 0.7228')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6654', 'avg train acc ', '0.8736')\n",
      "('Epoch 00000020 ', 'valid loss 0.4609', 'valid acc 0.8839')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.4609', 'WORST valid acc 0.8703')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.4609', 'MIN valid acc 0.8703')\n",
      "('Epoch 00000020 ', 'test loss 0.6183', 'test acc 0.7720')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6183', 'WORST test acc 0.8124')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5898', 'MIN test acc 0.7386')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6661', 'avg train acc ', '0.9005')\n",
      "('Epoch 00000030 ', 'valid loss 0.4902', 'valid acc 0.9069')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4902', 'WORST valid acc 0.8696')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4902', 'MIN valid acc 0.8696')\n",
      "('Epoch 00000030 ', 'test loss 0.6005', 'test acc 0.7708')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6005', 'WORST test acc 0.7616')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5950', 'MIN test acc 0.7344')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6541', 'avg train acc ', '0.8990')\n",
      "('Epoch 00000040 ', 'valid loss 0.4172', 'valid acc 0.9141')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4172', 'WORST valid acc 0.9101')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4055', 'MIN valid acc 0.9037')\n",
      "('Epoch 00000040 ', 'test loss 0.6347', 'test acc 0.7449')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6347', 'WORST test acc 0.7016')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5925', 'MIN test acc 0.7004')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6710', 'avg train acc ', '0.8918')\n",
      "('Epoch 00000050 ', 'valid loss 0.4863', 'valid acc 0.9049')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4863', 'WORST valid acc 0.8546')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4863', 'MIN valid acc 0.8546')\n",
      "('Epoch 00000050 ', 'test loss 0.6373', 'test acc 0.7379')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6373', 'WORST test acc 0.7366')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5988', 'MIN test acc 0.7112')\n",
      "===FINAL RESULTS WITH NODE 1===\n",
      "('VALID: acc 0.8968', 'accs sd 0.0187', 'loss 0.4640', 'loss sd 0.0239')\n",
      "('TEST: acc 0.7641', 'accs sd 0.0191', 'loss 0.6125', 'loss sd 0.0311')\n",
      "('WORST VALID: acc 0.8690', 'accs sd 0.0297', 'loss 0.4640', 'loss sd 0.0239')\n",
      "WORST VALID DOMAINS: [5, 3, 9, 9, 3, 3, 9, 9, 9, 9]\n",
      "('WORST TEST: acc 0.7514', 'accs sd 0.0367', 'loss 0.6125', 'loss sd 0.0311')\n",
      "WORST TEST DOMAINS: [2, 2, 2, 2, 0, 2, 4, 3, 3, 3]\n",
      "('MIN VALID: acc 0.8661', 'accs sd 0.0278', 'loss 0.4616', 'loss sd 0.0259')\n",
      "MIN VALID DOMAINS: [5, 4, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "('MIN TEST: acc 0.7196', 'accs sd 0.0207', 'loss 0.5960', 'loss sd 0.0340')\n",
      "MIN TEST DOMAINS: [2, 1, 0, 2, 0, 2, 0, 0, 0, 0]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6199', 'avg train acc ', '0.9195')\n",
      "('Epoch 00000010 ', 'valid loss 0.3739', 'valid acc 0.9024')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3739', 'WORST valid acc 0.8754')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3739', 'MIN valid acc 0.8754')\n",
      "('Epoch 00000010 ', 'test loss 0.5797', 'test acc 0.7580')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5797', 'WORST test acc 0.7586')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5594', 'MIN test acc 0.6966')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6093', 'avg train acc ', '0.9246')\n",
      "('Epoch 00000020 ', 'valid loss 0.3299', 'valid acc 0.9289')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.3299', 'WORST valid acc 0.9248')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3033', 'MIN valid acc 0.9176')\n",
      "('Epoch 00000020 ', 'test loss 0.6600', 'test acc 0.7766')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6600', 'WORST test acc 0.7172')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6600', 'MIN test acc 0.7172')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6086', 'avg train acc ', '0.9140')\n",
      "('Epoch 00000030 ', 'valid loss 0.3523', 'valid acc 0.9149')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3523', 'WORST valid acc 0.9030')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3523', 'MIN valid acc 0.9030')\n",
      "('Epoch 00000030 ', 'test loss 0.5424', 'test acc 0.7850')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5424', 'WORST test acc 0.7398')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5424', 'MIN test acc 0.7398')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6160', 'avg train acc ', '0.9198')\n",
      "('Epoch 00000040 ', 'valid loss 0.3898', 'valid acc 0.9066')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.3898', 'WORST valid acc 0.9209')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3892', 'MIN valid acc 0.8850')\n",
      "('Epoch 00000040 ', 'test loss 0.6250', 'test acc 0.7654')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6250', 'WORST test acc 0.7082')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6250', 'MIN test acc 0.7082')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6088', 'avg train acc ', '0.9236')\n",
      "('Epoch 00000050 ', 'valid loss 0.3495', 'valid acc 0.9245')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3495', 'WORST valid acc 0.9254')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3220', 'MIN valid acc 0.9129')\n",
      "('Epoch 00000050 ', 'test loss 0.6343', 'test acc 0.7558')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6343', 'WORST test acc 0.6898')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6343', 'MIN test acc 0.6898')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6433', 'avg train acc ', '0.8906')\n",
      "('Epoch 00000010 ', 'valid loss 0.4141', 'valid acc 0.9121')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.4141', 'WORST valid acc 0.8980')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.4141', 'MIN valid acc 0.8980')\n",
      "('Epoch 00000010 ', 'test loss 0.5863', 'test acc 0.7187')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5863', 'WORST test acc 0.6840')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5863', 'MIN test acc 0.6840')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6391', 'avg train acc ', '0.8570')\n",
      "('Epoch 00000020 ', 'valid loss 0.3916', 'valid acc 0.8693')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3916', 'WORST valid acc 0.8608')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3739', 'MIN valid acc 0.8597')\n",
      "('Epoch 00000020 ', 'test loss 0.6147', 'test acc 0.7244')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6147', 'WORST test acc 0.7014')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5746', 'MIN test acc 0.6822')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6258', 'avg train acc ', '0.8921')\n",
      "('Epoch 00000030 ', 'valid loss 0.3667', 'valid acc 0.9084')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3667', 'WORST valid acc 0.9036')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3502', 'MIN valid acc 0.8977')\n",
      "('Epoch 00000030 ', 'test loss 0.5995', 'test acc 0.7563')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5995', 'WORST test acc 0.7150')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5995', 'MIN test acc 0.7150')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6219', 'avg train acc ', '0.8784')\n",
      "('Epoch 00000040 ', 'valid loss 0.3907', 'valid acc 0.8916')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3907', 'WORST valid acc 0.8783')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3907', 'MIN valid acc 0.8783')\n",
      "('Epoch 00000040 ', 'test loss 0.5768', 'test acc 0.7553')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5768', 'WORST test acc 0.7156')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5768', 'MIN test acc 0.7156')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5985', 'avg train acc ', '0.8939')\n",
      "('Epoch 00000050 ', 'valid loss 0.3580', 'valid acc 0.8819')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3580', 'WORST valid acc 0.8662')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3580', 'MIN valid acc 0.8662')\n",
      "('Epoch 00000050 ', 'test loss 0.6079', 'test acc 0.7371')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6079', 'WORST test acc 0.6956')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6079', 'MIN test acc 0.6956')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6161', 'avg train acc ', '0.9064')\n",
      "('Epoch 00000010 ', 'valid loss 0.3316', 'valid acc 0.9262')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3316', 'WORST valid acc 0.9209')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.3313', 'MIN valid acc 0.9140')\n",
      "('Epoch 00000010 ', 'test loss 0.6028', 'test acc 0.7568')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6028', 'WORST test acc 0.7098')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6028', 'MIN test acc 0.7098')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6139', 'avg train acc ', '0.9207')\n",
      "('Epoch 00000020 ', 'valid loss 0.3703', 'valid acc 0.9316')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3703', 'WORST valid acc 0.9103')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3703', 'MIN valid acc 0.9103')\n",
      "('Epoch 00000020 ', 'test loss 0.6255', 'test acc 0.7446')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6255', 'WORST test acc 0.6932')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.6255', 'MIN test acc 0.6932')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6142', 'avg train acc ', '0.9220')\n",
      "('Epoch 00000030 ', 'valid loss 0.4074', 'valid acc 0.9215')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.4074', 'WORST valid acc 0.9069')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.4074', 'MIN valid acc 0.9069')\n",
      "('Epoch 00000030 ', 'test loss 0.6170', 'test acc 0.7581')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6170', 'WORST test acc 0.6948')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6170', 'MIN test acc 0.6948')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6064', 'avg train acc ', '0.9211')\n",
      "('Epoch 00000040 ', 'valid loss 0.3342', 'valid acc 0.9239')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3342', 'WORST valid acc 0.9288')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3261', 'MIN valid acc 0.9048')\n",
      "('Epoch 00000040 ', 'test loss 0.5814', 'test acc 0.7524')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5814', 'WORST test acc 0.7082')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.5814', 'MIN test acc 0.7082')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5958', 'avg train acc ', '0.9301')\n",
      "('Epoch 00000050 ', 'valid loss 0.3288', 'valid acc 0.9332')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3288', 'WORST valid acc 0.9529')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3198', 'MIN valid acc 0.9069')\n",
      "('Epoch 00000050 ', 'test loss 0.6435', 'test acc 0.7459')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6435', 'WORST test acc 0.7124')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6435', 'MIN test acc 0.7124')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5938', 'avg train acc ', '0.9357')\n",
      "('Epoch 00000010 ', 'valid loss 0.3483', 'valid acc 0.9320')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.3483', 'WORST valid acc 0.9150')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.3483', 'MIN valid acc 0.9150')\n",
      "('Epoch 00000010 ', 'test loss 0.6471', 'test acc 0.7711')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6471', 'WORST test acc 0.7722')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6400', 'MIN test acc 0.7242')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5977', 'avg train acc ', '0.9253')\n",
      "('Epoch 00000020 ', 'valid loss 0.3552', 'valid acc 0.9225')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3552', 'WORST valid acc 0.8919')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.3476', 'MIN valid acc 0.8917')\n",
      "('Epoch 00000020 ', 'test loss 0.6510', 'test acc 0.7615')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6510', 'WORST test acc 0.7186')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6510', 'MIN test acc 0.7186')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5991', 'avg train acc ', '0.9329')\n",
      "('Epoch 00000030 ', 'valid loss 0.3786', 'valid acc 0.8800')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.3786', 'WORST valid acc 0.8208')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3783', 'MIN valid acc 0.8143')\n",
      "('Epoch 00000030 ', 'test loss 0.5695', 'test acc 0.7619')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5695', 'WORST test acc 0.7150')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5695', 'MIN test acc 0.7150')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5852', 'avg train acc ', '0.9402')\n",
      "('Epoch 00000040 ', 'valid loss 0.3073', 'valid acc 0.9464')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.3073', 'WORST valid acc 0.9267')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.3073', 'MIN valid acc 0.9267')\n",
      "('Epoch 00000040 ', 'test loss 0.6299', 'test acc 0.7735')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6299', 'WORST test acc 0.7578')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6218', 'MIN test acc 0.7332')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5821', 'avg train acc ', '0.9411')\n",
      "('Epoch 00000050 ', 'valid loss 0.3739', 'valid acc 0.9345')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3739', 'WORST valid acc 0.9072')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3739', 'MIN valid acc 0.9072')\n",
      "('Epoch 00000050 ', 'test loss 0.5772', 'test acc 0.7731')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5772', 'WORST test acc 0.7326')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5772', 'MIN test acc 0.7326')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6206', 'avg train acc ', '0.9114')\n",
      "('Epoch 00000010 ', 'valid loss 0.3641', 'valid acc 0.9177')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3641', 'WORST valid acc 0.9168')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.3442', 'MIN valid acc 0.9079')\n",
      "('Epoch 00000010 ', 'test loss 0.6150', 'test acc 0.7498')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6150', 'WORST test acc 0.7010')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6150', 'MIN test acc 0.7010')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6314', 'avg train acc ', '0.8829')\n",
      "('Epoch 00000020 ', 'valid loss 0.4074', 'valid acc 0.8777')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4074', 'WORST valid acc 0.8415')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.4074', 'MIN valid acc 0.8415')\n",
      "('Epoch 00000020 ', 'test loss 0.5530', 'test acc 0.7548')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5530', 'WORST test acc 0.7276')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5530', 'MIN test acc 0.7276')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6145', 'avg train acc ', '0.8884')\n",
      "('Epoch 00000030 ', 'valid loss 0.3490', 'valid acc 0.9021')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3490', 'WORST valid acc 0.9015')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3247', 'MIN valid acc 0.8873')\n",
      "('Epoch 00000030 ', 'test loss 0.5696', 'test acc 0.7620')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5696', 'WORST test acc 0.7028')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5696', 'MIN test acc 0.7028')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6021', 'avg train acc ', '0.9315')\n",
      "('Epoch 00000040 ', 'valid loss 0.3509', 'valid acc 0.9309')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3509', 'WORST valid acc 0.9229')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3508', 'MIN valid acc 0.9058')\n",
      "('Epoch 00000040 ', 'test loss 0.6925', 'test acc 0.7330')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6925', 'WORST test acc 0.6952')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6925', 'MIN test acc 0.6952')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6030', 'avg train acc ', '0.9346')\n",
      "('Epoch 00000050 ', 'valid loss 0.3421', 'valid acc 0.9392')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3421', 'WORST valid acc 0.9166')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3421', 'MIN valid acc 0.9166')\n",
      "('Epoch 00000050 ', 'test loss 0.6307', 'test acc 0.7561')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6307', 'WORST test acc 0.6872')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6307', 'MIN test acc 0.6872')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6312', 'avg train acc ', '0.8763')\n",
      "('Epoch 00000010 ', 'valid loss 0.3829', 'valid acc 0.8705')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3829', 'WORST valid acc 0.8744')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3603', 'MIN valid acc 0.8400')\n",
      "('Epoch 00000010 ', 'test loss 0.6126', 'test acc 0.7266')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6126', 'WORST test acc 0.6918')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6126', 'MIN test acc 0.6918')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6208', 'avg train acc ', '0.8924')\n",
      "('Epoch 00000020 ', 'valid loss 0.3887', 'valid acc 0.8891')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3887', 'WORST valid acc 0.8597')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3887', 'MIN valid acc 0.8597')\n",
      "('Epoch 00000020 ', 'test loss 0.5500', 'test acc 0.7504')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5500', 'WORST test acc 0.7240')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5309', 'MIN test acc 0.7072')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6323', 'avg train acc ', '0.8812')\n",
      "('Epoch 00000030 ', 'valid loss 0.3869', 'valid acc 0.8936')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3869', 'WORST valid acc 0.8747')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.3771', 'MIN valid acc 0.8733')\n",
      "('Epoch 00000030 ', 'test loss 0.6422', 'test acc 0.7510')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6422', 'WORST test acc 0.6952')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6422', 'MIN test acc 0.6952')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6267', 'avg train acc ', '0.8673')\n",
      "('Epoch 00000040 ', 'valid loss 0.3770', 'valid acc 0.8759')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3770', 'WORST valid acc 0.9288')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3622', 'MIN valid acc 0.8212')\n",
      "('Epoch 00000040 ', 'test loss 0.6060', 'test acc 0.7230')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6060', 'WORST test acc 0.6760')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6060', 'MIN test acc 0.6760')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6195', 'avg train acc ', '0.8884')\n",
      "('Epoch 00000050 ', 'valid loss 0.3925', 'valid acc 0.8903')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3925', 'WORST valid acc 0.8469')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3925', 'MIN valid acc 0.8469')\n",
      "('Epoch 00000050 ', 'test loss 0.6104', 'test acc 0.7594')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6104', 'WORST test acc 0.6884')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6104', 'MIN test acc 0.6884')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6398', 'avg train acc ', '0.8777')\n",
      "('Epoch 00000010 ', 'valid loss 0.3811', 'valid acc 0.8889')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3811', 'WORST valid acc 0.8797')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3630', 'MIN valid acc 0.8788')\n",
      "('Epoch 00000010 ', 'test loss 0.5553', 'test acc 0.7855')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5553', 'WORST test acc 0.7256')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5553', 'MIN test acc 0.7256')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6487', 'avg train acc ', '0.8762')\n",
      "('Epoch 00000020 ', 'valid loss 0.4349', 'valid acc 0.8941')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4349', 'WORST valid acc 0.8813')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4349', 'MIN valid acc 0.8813')\n",
      "('Epoch 00000020 ', 'test loss 0.6208', 'test acc 0.7314')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6208', 'WORST test acc 0.6980')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6208', 'MIN test acc 0.6980')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6339', 'avg train acc ', '0.9013')\n",
      "('Epoch 00000030 ', 'valid loss 0.4036', 'valid acc 0.9129')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.4036', 'WORST valid acc 0.9077')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3885', 'MIN valid acc 0.9051')\n",
      "('Epoch 00000030 ', 'test loss 0.5845', 'test acc 0.7317')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.5845', 'WORST test acc 0.7298')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.5813', 'MIN test acc 0.7008')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6287', 'avg train acc ', '0.8939')\n",
      "('Epoch 00000040 ', 'valid loss 0.3762', 'valid acc 0.9089')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.3762', 'WORST valid acc 0.8971')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3489', 'MIN valid acc 0.8940')\n",
      "('Epoch 00000040 ', 'test loss 0.6064', 'test acc 0.7396')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6064', 'WORST test acc 0.6936')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6064', 'MIN test acc 0.6936')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6314', 'avg train acc ', '0.8763')\n",
      "('Epoch 00000050 ', 'valid loss 0.3787', 'valid acc 0.8896')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3787', 'WORST valid acc 0.8596')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3760', 'MIN valid acc 0.8504')\n",
      "('Epoch 00000050 ', 'test loss 0.5577', 'test acc 0.7575')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5577', 'WORST test acc 0.7364')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5316', 'MIN test acc 0.7094')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6001', 'avg train acc ', '0.9362')\n",
      "('Epoch 00000010 ', 'valid loss 0.3638', 'valid acc 0.9363')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3638', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3638', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000010 ', 'test loss 0.5661', 'test acc 0.7605')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5661', 'WORST test acc 0.7142')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5661', 'MIN test acc 0.7142')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5991', 'avg train acc ', '0.9384')\n",
      "('Epoch 00000020 ', 'valid loss 0.3683', 'valid acc 0.9369')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3683', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3665', 'MIN valid acc 0.9241')\n",
      "('Epoch 00000020 ', 'test loss 0.6390', 'test acc 0.7666')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6390', 'WORST test acc 0.6958')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6390', 'MIN test acc 0.6958')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5930', 'avg train acc ', '0.9347')\n",
      "('Epoch 00000030 ', 'valid loss 0.3722', 'valid acc 0.9342')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3722', 'WORST valid acc 0.9215')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3707', 'MIN valid acc 0.9209')\n",
      "('Epoch 00000030 ', 'test loss 0.5532', 'test acc 0.7621')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5532', 'WORST test acc 0.7308')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5532', 'MIN test acc 0.7308')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5890', 'avg train acc ', '0.9354')\n",
      "('Epoch 00000040 ', 'valid loss 0.3558', 'valid acc 0.9323')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3558', 'WORST valid acc 0.9378')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3437', 'MIN valid acc 0.9195')\n",
      "('Epoch 00000040 ', 'test loss 0.5462', 'test acc 0.7739')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5462', 'WORST test acc 0.7482')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5462', 'MIN test acc 0.7482')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5810', 'avg train acc ', '0.9428')\n",
      "('Epoch 00000050 ', 'valid loss 0.3650', 'valid acc 0.9381')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3650', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.3632', 'MIN valid acc 0.9133')\n",
      "('Epoch 00000050 ', 'test loss 0.5959', 'test acc 0.7691')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5959', 'WORST test acc 0.7156')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.5959', 'MIN test acc 0.7156')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6314', 'avg train acc ', '0.8739')\n",
      "('Epoch 00000010 ', 'valid loss 0.3970', 'valid acc 0.8809')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3970', 'WORST valid acc 0.8656')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3970', 'MIN valid acc 0.8656')\n",
      "('Epoch 00000010 ', 'test loss 0.5857', 'test acc 0.7341')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5857', 'WORST test acc 0.7268')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5774', 'MIN test acc 0.7084')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6228', 'avg train acc ', '0.8674')\n",
      "('Epoch 00000020 ', 'valid loss 0.3855', 'valid acc 0.8786')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3855', 'WORST valid acc 0.8790')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.3473', 'MIN valid acc 0.8589')\n",
      "('Epoch 00000020 ', 'test loss 0.6074', 'test acc 0.7357')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6074', 'WORST test acc 0.7000')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6074', 'MIN test acc 0.7000')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6202', 'avg train acc ', '0.8659')\n",
      "('Epoch 00000030 ', 'valid loss 0.3755', 'valid acc 0.8680')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3755', 'WORST valid acc 0.8205')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3755', 'MIN valid acc 0.8205')\n",
      "('Epoch 00000030 ', 'test loss 0.6088', 'test acc 0.7272')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6088', 'WORST test acc 0.6936')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6088', 'MIN test acc 0.6936')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.6029', 'avg train acc ', '0.8754')\n",
      "('Epoch 00000040 ', 'valid loss 0.3718', 'valid acc 0.8862')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.3718', 'WORST valid acc 0.8576')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3718', 'MIN valid acc 0.8576')\n",
      "('Epoch 00000040 ', 'test loss 0.5743', 'test acc 0.7508')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.5743', 'WORST test acc 0.7904')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5502', 'MIN test acc 0.7222')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.6069', 'avg train acc ', '0.8949')\n",
      "('Epoch 00000050 ', 'valid loss 0.3573', 'valid acc 0.9129')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3573', 'WORST valid acc 0.9165')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.3555', 'MIN valid acc 0.8997')\n",
      "('Epoch 00000050 ', 'test loss 0.5540', 'test acc 0.7599')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5540', 'WORST test acc 0.7442')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5325', 'MIN test acc 0.6870')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.6121', 'avg train acc ', '0.9266')\n",
      "('Epoch 00000010 ', 'valid loss 0.3841', 'valid acc 0.9371')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.3841', 'WORST valid acc 0.9209')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.3841', 'MIN valid acc 0.9209')\n",
      "('Epoch 00000010 ', 'test loss 0.5667', 'test acc 0.7842')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5667', 'WORST test acc 0.7346')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5667', 'MIN test acc 0.7346')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.6120', 'avg train acc ', '0.9124')\n",
      "('Epoch 00000020 ', 'valid loss 0.4060', 'valid acc 0.9199')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4060', 'WORST valid acc 0.9078')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.4060', 'MIN valid acc 0.9078')\n",
      "('Epoch 00000020 ', 'test loss 0.5365', 'test acc 0.7843')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5365', 'WORST test acc 0.7386')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5365', 'MIN test acc 0.7386')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.6096', 'avg train acc ', '0.9213')\n",
      "('Epoch 00000030 ', 'valid loss 0.4526', 'valid acc 0.9147')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.4526', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000007 ', 'WORST ACC valid loss 0.3933', 'MIN valid acc 0.8952')\n",
      "('Epoch 00000030 ', 'test loss 0.6712', 'test acc 0.7603')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6712', 'WORST test acc 0.7614')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6415', 'MIN test acc 0.7208')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5925', 'avg train acc ', '0.9407')\n",
      "('Epoch 00000040 ', 'valid loss 0.3674', 'valid acc 0.9382')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3674', 'WORST valid acc 0.9215')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3674', 'MIN valid acc 0.9215')\n",
      "('Epoch 00000040 ', 'test loss 0.6129', 'test acc 0.7656')\n",
      "('WORST DOMAIN 00000003 ', 'MAX test loss 0.6129', 'WORST test acc 0.7238')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5958', 'MIN test acc 0.7088')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5919', 'avg train acc ', '0.9407')\n",
      "('Epoch 00000050 ', 'valid loss 0.3412', 'valid acc 0.9454')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.3412', 'WORST valid acc 0.9411')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.3364', 'MIN valid acc 0.9400')\n",
      "('Epoch 00000050 ', 'test loss 0.6343', 'test acc 0.7685')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6343', 'WORST test acc 0.7072')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6343', 'MIN test acc 0.7072')\n",
      "===FINAL RESULTS WITH NODE 2===\n",
      "('VALID: acc 0.9190', 'accs sd 0.0225', 'loss 0.3587', 'loss sd 0.0184')\n",
      "('TEST: acc 0.7582', 'accs sd 0.0103', 'loss 0.6046', 'loss sd 0.0310')\n",
      "('WORST VALID: acc 0.9048', 'accs sd 0.0337', 'loss 0.3587', 'loss sd 0.0184')\n",
      "WORST VALID DOMAINS: [1, 3, 9, 0, 1, 3, 9, 0, 3, 3]\n",
      "('WORST TEST: acc 0.7109', 'accs sd 0.0200', 'loss 0.6046', 'loss sd 0.0310')\n",
      "WORST TEST DOMAINS: [2, 2, 2, 2, 2, 2, 0, 3, 2, 2]\n",
      "('MIN VALID: acc 0.8960', 'accs sd 0.0293', 'loss 0.3539', 'loss sd 0.0226')\n",
      "MIN VALID DOMAINS: [8, 3, 3, 0, 1, 3, 8, 3, 4, 5]\n",
      "('MIN TEST: acc 0.7025', 'accs sd 0.0146', 'loss 0.5998', 'loss sd 0.0389')\n",
      "MIN TEST DOMAINS: [2, 2, 2, 2, 2, 2, 2, 3, 1, 2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5398', 'avg train acc ', '0.9374')\n",
      "('Epoch 00000010 ', 'valid loss 0.2611', 'valid acc 0.9390')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2611', 'WORST valid acc 0.9559')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2452', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000010 ', 'test loss 0.6780', 'test acc 0.7549')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6780', 'WORST test acc 0.7182')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6780', 'MIN test acc 0.7182')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5303', 'avg train acc ', '0.9302')\n",
      "('Epoch 00000020 ', 'valid loss 0.2543', 'valid acc 0.9340')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2543', 'WORST valid acc 0.9103')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2543', 'MIN valid acc 0.9103')\n",
      "('Epoch 00000020 ', 'test loss 0.7083', 'test acc 0.7044')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7083', 'WORST test acc 0.6600')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5296', 'MIN test acc 0.6288')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5214', 'avg train acc ', '0.9120')\n",
      "('Epoch 00000030 ', 'valid loss 0.2322', 'valid acc 0.9270')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2322', 'WORST valid acc 0.9135')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2299', 'MIN valid acc 0.9028')\n",
      "('Epoch 00000030 ', 'test loss 0.6570', 'test acc 0.7346')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6570', 'WORST test acc 0.6828')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6570', 'MIN test acc 0.6828')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5004', 'avg train acc ', '0.9422')\n",
      "('Epoch 00000040 ', 'valid loss 0.2401', 'valid acc 0.9303')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2401', 'WORST valid acc 0.8882')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2401', 'MIN valid acc 0.8882')\n",
      "('Epoch 00000040 ', 'test loss 0.6461', 'test acc 0.7226')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.6461', 'WORST test acc 0.5812')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6461', 'MIN test acc 0.5812')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5121', 'avg train acc ', '0.9393')\n",
      "('Epoch 00000050 ', 'valid loss 0.2520', 'valid acc 0.9286')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2520', 'WORST valid acc 0.9103')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2491', 'MIN valid acc 0.9097')\n",
      "('Epoch 00000050 ', 'test loss 0.6512', 'test acc 0.7296')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6512', 'WORST test acc 0.6908')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5674', 'MIN test acc 0.6454')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5499', 'avg train acc ', '0.9180')\n",
      "('Epoch 00000010 ', 'valid loss 0.2638', 'valid acc 0.9293')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2638', 'WORST valid acc 0.9218')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2638', 'MIN valid acc 0.9218')\n",
      "('Epoch 00000010 ', 'test loss 0.6668', 'test acc 0.7694')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6668', 'WORST test acc 0.7274')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6668', 'MIN test acc 0.7274')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5197', 'avg train acc ', '0.9275')\n",
      "('Epoch 00000020 ', 'valid loss 0.2342', 'valid acc 0.9301')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2342', 'WORST valid acc 0.9225')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2342', 'MIN valid acc 0.9225')\n",
      "('Epoch 00000020 ', 'test loss 0.7110', 'test acc 0.7815')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7110', 'WORST test acc 0.7168')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7110', 'MIN test acc 0.7168')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5316', 'avg train acc ', '0.9268')\n",
      "('Epoch 00000030 ', 'valid loss 0.2676', 'valid acc 0.9289')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2676', 'WORST valid acc 0.9030')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2676', 'MIN valid acc 0.9030')\n",
      "('Epoch 00000030 ', 'test loss 0.6855', 'test acc 0.7687')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6855', 'WORST test acc 0.7068')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6855', 'MIN test acc 0.7068')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5186', 'avg train acc ', '0.9294')\n",
      "('Epoch 00000040 ', 'valid loss 0.2583', 'valid acc 0.9362')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2583', 'WORST valid acc 0.9244')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2507', 'MIN valid acc 0.9137')\n",
      "('Epoch 00000040 ', 'test loss 0.6387', 'test acc 0.7918')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6387', 'WORST test acc 0.7250')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6387', 'MIN test acc 0.7250')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5050', 'avg train acc ', '0.9307')\n",
      "('Epoch 00000050 ', 'valid loss 0.2589', 'valid acc 0.9283')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2589', 'WORST valid acc 0.9103')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2589', 'MIN valid acc 0.9103')\n",
      "('Epoch 00000050 ', 'test loss 0.6347', 'test acc 0.7663')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6347', 'WORST test acc 0.7066')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6347', 'MIN test acc 0.7066')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5615', 'avg train acc ', '0.9114')\n",
      "('Epoch 00000010 ', 'valid loss 0.2884', 'valid acc 0.9177')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2884', 'WORST valid acc 0.8999')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2866', 'MIN valid acc 0.8927')\n",
      "('Epoch 00000010 ', 'test loss 0.6188', 'test acc 0.7828')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6188', 'WORST test acc 0.7464')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6188', 'MIN test acc 0.7464')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5076', 'avg train acc ', '0.9337')\n",
      "('Epoch 00000020 ', 'valid loss 0.2493', 'valid acc 0.9382')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2493', 'WORST valid acc 0.9097')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2493', 'MIN valid acc 0.9097')\n",
      "('Epoch 00000020 ', 'test loss 0.6109', 'test acc 0.7757')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6109', 'WORST test acc 0.7060')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6109', 'MIN test acc 0.7060')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5111', 'avg train acc ', '0.9372')\n",
      "('Epoch 00000030 ', 'valid loss 0.2564', 'valid acc 0.9380')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2564', 'WORST valid acc 0.9146')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2563', 'MIN valid acc 0.9122')\n",
      "('Epoch 00000030 ', 'test loss 0.5719', 'test acc 0.7748')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5719', 'WORST test acc 0.7070')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5719', 'MIN test acc 0.7070')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4903', 'avg train acc ', '0.9363')\n",
      "('Epoch 00000040 ', 'valid loss 0.2514', 'valid acc 0.9270')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2514', 'WORST valid acc 0.8940')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2514', 'MIN valid acc 0.8940')\n",
      "('Epoch 00000040 ', 'test loss 0.5356', 'test acc 0.7782')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5356', 'WORST test acc 0.7350')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5356', 'MIN test acc 0.7350')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4917', 'avg train acc ', '0.9282')\n",
      "('Epoch 00000050 ', 'valid loss 0.2461', 'valid acc 0.9159')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2461', 'WORST valid acc 0.8726')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2461', 'MIN valid acc 0.8726')\n",
      "('Epoch 00000050 ', 'test loss 0.6483', 'test acc 0.7417')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.6483', 'WORST test acc 0.5904')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6483', 'MIN test acc 0.5904')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5541', 'avg train acc ', '0.9209')\n",
      "('Epoch 00000010 ', 'valid loss 0.2853', 'valid acc 0.9335')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2853', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2824', 'MIN valid acc 0.9127')\n",
      "('Epoch 00000010 ', 'test loss 0.6778', 'test acc 0.7176')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6778', 'WORST test acc 0.6774')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6778', 'MIN test acc 0.6774')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5551', 'avg train acc ', '0.9252')\n",
      "('Epoch 00000020 ', 'valid loss 0.3429', 'valid acc 0.9031')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3429', 'WORST valid acc 0.8842')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.3429', 'MIN valid acc 0.8842')\n",
      "('Epoch 00000020 ', 'test loss 0.6654', 'test acc 0.7486')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6654', 'WORST test acc 0.7104')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6654', 'MIN test acc 0.7104')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5183', 'avg train acc ', '0.9305')\n",
      "('Epoch 00000030 ', 'valid loss 0.2838', 'valid acc 0.9290')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2838', 'WORST valid acc 0.8987')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2838', 'MIN valid acc 0.8987')\n",
      "('Epoch 00000030 ', 'test loss 0.6257', 'test acc 0.7412')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6257', 'WORST test acc 0.6898')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6257', 'MIN test acc 0.6898')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5083', 'avg train acc ', '0.9299')\n",
      "('Epoch 00000040 ', 'valid loss 0.2312', 'valid acc 0.9328')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2312', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2312', 'MIN valid acc 0.9136')\n",
      "('Epoch 00000040 ', 'test loss 0.7054', 'test acc 0.7632')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7054', 'WORST test acc 0.6944')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7054', 'MIN test acc 0.6944')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5077', 'avg train acc ', '0.9311')\n",
      "('Epoch 00000050 ', 'valid loss 0.2348', 'valid acc 0.9347')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2348', 'WORST valid acc 0.9451')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2309', 'MIN valid acc 0.9254')\n",
      "('Epoch 00000050 ', 'test loss 0.6981', 'test acc 0.7519')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6981', 'WORST test acc 0.7180')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.5449', 'MIN test acc 0.6844')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5515', 'avg train acc ', '0.9141')\n",
      "('Epoch 00000010 ', 'valid loss 0.2758', 'valid acc 0.9322')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2758', 'WORST valid acc 0.9209')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2739', 'MIN valid acc 0.9185')\n",
      "('Epoch 00000010 ', 'test loss 0.6404', 'test acc 0.7455')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6404', 'WORST test acc 0.7090')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6404', 'MIN test acc 0.7090')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5035', 'avg train acc ', '0.9303')\n",
      "('Epoch 00000020 ', 'valid loss 0.2335', 'valid acc 0.9300')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2335', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2335', 'MIN valid acc 0.9136')\n",
      "('Epoch 00000020 ', 'test loss 0.6119', 'test acc 0.7636')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6119', 'WORST test acc 0.7062')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6119', 'MIN test acc 0.7062')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4893', 'avg train acc ', '0.9310')\n",
      "('Epoch 00000030 ', 'valid loss 0.2143', 'valid acc 0.9359')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.2143', 'WORST valid acc 0.9278')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2140', 'MIN valid acc 0.9264')\n",
      "('Epoch 00000030 ', 'test loss 0.6527', 'test acc 0.6884')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6527', 'WORST test acc 0.6710')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.5022', 'MIN test acc 0.6022')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4841', 'avg train acc ', '0.9325')\n",
      "('Epoch 00000040 ', 'valid loss 0.2364', 'valid acc 0.9436')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2364', 'WORST valid acc 0.9325')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2320', 'MIN valid acc 0.9218')\n",
      "('Epoch 00000040 ', 'test loss 0.5361', 'test acc 0.7355')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.5361', 'WORST test acc 0.7566')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.4845', 'MIN test acc 0.7066')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4690', 'avg train acc ', '0.9411')\n",
      "('Epoch 00000050 ', 'valid loss 0.2171', 'valid acc 0.9467')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2171', 'WORST valid acc 0.9399')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2070', 'MIN valid acc 0.9350')\n",
      "('Epoch 00000050 ', 'test loss 0.5801', 'test acc 0.7433')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5801', 'WORST test acc 0.7300')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5075', 'MIN test acc 0.7180')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5173', 'avg train acc ', '0.9339')\n",
      "('Epoch 00000010 ', 'valid loss 0.2579', 'valid acc 0.9389')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2579', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2579', 'MIN valid acc 0.9272')\n",
      "('Epoch 00000010 ', 'test loss 0.5485', 'test acc 0.7666')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5485', 'WORST test acc 0.7120')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5485', 'MIN test acc 0.7120')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5157', 'avg train acc ', '0.9317')\n",
      "('Epoch 00000020 ', 'valid loss 0.2243', 'valid acc 0.9464')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2243', 'WORST valid acc 0.9280')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2234', 'MIN valid acc 0.9258')\n",
      "('Epoch 00000020 ', 'test loss 0.5362', 'test acc 0.7441')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5362', 'WORST test acc 0.7214')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5362', 'MIN test acc 0.7214')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5186', 'avg train acc ', '0.9304')\n",
      "('Epoch 00000030 ', 'valid loss 0.2640', 'valid acc 0.9302')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2640', 'WORST valid acc 0.9235')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2534', 'MIN valid acc 0.9200')\n",
      "('Epoch 00000030 ', 'test loss 0.5772', 'test acc 0.7724')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5772', 'WORST test acc 0.7286')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5772', 'MIN test acc 0.7286')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5403', 'avg train acc ', '0.9102')\n",
      "('Epoch 00000040 ', 'valid loss 0.2539', 'valid acc 0.9282')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2539', 'WORST valid acc 0.9438')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2273', 'MIN valid acc 0.9154')\n",
      "('Epoch 00000040 ', 'test loss 0.5859', 'test acc 0.7473')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5859', 'WORST test acc 0.6956')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5859', 'MIN test acc 0.6956')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5000', 'avg train acc ', '0.9446')\n",
      "('Epoch 00000050 ', 'valid loss 0.2235', 'valid acc 0.9449')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2235', 'WORST valid acc 0.9283')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2235', 'MIN valid acc 0.9283')\n",
      "('Epoch 00000050 ', 'test loss 0.6908', 'test acc 0.7546')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.6908', 'WORST test acc 0.6578')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.6908', 'MIN test acc 0.6578')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5582', 'avg train acc ', '0.9107')\n",
      "('Epoch 00000010 ', 'valid loss 0.3110', 'valid acc 0.9106')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.3110', 'WORST valid acc 0.8970')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.3048', 'MIN valid acc 0.8931')\n",
      "('Epoch 00000010 ', 'test loss 0.6671', 'test acc 0.7461')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6671', 'WORST test acc 0.7060')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6671', 'MIN test acc 0.7060')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5265', 'avg train acc ', '0.9314')\n",
      "('Epoch 00000020 ', 'valid loss 0.2533', 'valid acc 0.9331')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2533', 'WORST valid acc 0.9186')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2533', 'MIN valid acc 0.9186')\n",
      "('Epoch 00000020 ', 'test loss 0.5950', 'test acc 0.7543')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5950', 'WORST test acc 0.7510')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5713', 'MIN test acc 0.7248')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5111', 'avg train acc ', '0.9254')\n",
      "('Epoch 00000030 ', 'valid loss 0.2634', 'valid acc 0.9098')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.2634', 'WORST valid acc 0.8788')\n",
      "('WORST ACC DOMAIN 00000007 ', 'WORST ACC valid loss 0.2581', 'MIN valid acc 0.8724')\n",
      "('Epoch 00000030 ', 'test loss 0.5725', 'test acc 0.7462')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5725', 'WORST test acc 0.7376')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5399', 'MIN test acc 0.6860')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5126', 'avg train acc ', '0.9203')\n",
      "('Epoch 00000040 ', 'valid loss 0.2335', 'valid acc 0.9268')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2335', 'WORST valid acc 0.9072')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2335', 'MIN valid acc 0.9072')\n",
      "('Epoch 00000040 ', 'test loss 0.7017', 'test acc 0.7579')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7017', 'WORST test acc 0.7158')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7017', 'MIN test acc 0.7158')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5116', 'avg train acc ', '0.9260')\n",
      "('Epoch 00000050 ', 'valid loss 0.2657', 'valid acc 0.9205')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2657', 'WORST valid acc 0.9157')\n",
      "('WORST ACC DOMAIN 00000006 ', 'WORST ACC valid loss 0.2569', 'MIN valid acc 0.9144')\n",
      "('Epoch 00000050 ', 'test loss 0.6183', 'test acc 0.7754')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6183', 'WORST test acc 0.7226')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6183', 'MIN test acc 0.7226')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5332', 'avg train acc ', '0.9242')\n",
      "('Epoch 00000010 ', 'valid loss 0.2946', 'valid acc 0.9126')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2946', 'WORST valid acc 0.9030')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.2414', 'MIN valid acc 0.9006')\n",
      "('Epoch 00000010 ', 'test loss 0.5982', 'test acc 0.7333')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5982', 'WORST test acc 0.6866')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5982', 'MIN test acc 0.6866')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5021', 'avg train acc ', '0.9331')\n",
      "('Epoch 00000020 ', 'valid loss 0.2504', 'valid acc 0.9311')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2504', 'WORST valid acc 0.9097')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2504', 'MIN valid acc 0.9097')\n",
      "('Epoch 00000020 ', 'test loss 0.5873', 'test acc 0.7104')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5873', 'WORST test acc 0.7016')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.4922', 'MIN test acc 0.6612')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4773', 'avg train acc ', '0.9445')\n",
      "('Epoch 00000030 ', 'valid loss 0.2116', 'valid acc 0.9462')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2116', 'WORST valid acc 0.9229')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2116', 'MIN valid acc 0.9229')\n",
      "('Epoch 00000030 ', 'test loss 0.5755', 'test acc 0.7374')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5755', 'WORST test acc 0.6952')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5755', 'MIN test acc 0.6952')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4743', 'avg train acc ', '0.9402')\n",
      "('Epoch 00000040 ', 'valid loss 0.2078', 'valid acc 0.9513')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2078', 'WORST valid acc 0.9378')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2078', 'MIN valid acc 0.9340')\n",
      "('Epoch 00000040 ', 'test loss 0.5763', 'test acc 0.7914')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5763', 'WORST test acc 0.7186')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5763', 'MIN test acc 0.7186')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4519', 'avg train acc ', '0.9428')\n",
      "('Epoch 00000050 ', 'valid loss 0.1968', 'valid acc 0.9426')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1968', 'WORST valid acc 0.9284')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1968', 'MIN valid acc 0.9284')\n",
      "('Epoch 00000050 ', 'test loss 0.6116', 'test acc 0.7669')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6116', 'WORST test acc 0.7196')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6116', 'MIN test acc 0.7196')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5726', 'avg train acc ', '0.9049')\n",
      "('Epoch 00000010 ', 'valid loss 0.2925', 'valid acc 0.9250')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2925', 'WORST valid acc 0.9040')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2925', 'MIN valid acc 0.9040')\n",
      "('Epoch 00000010 ', 'test loss 0.6639', 'test acc 0.7428')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6639', 'WORST test acc 0.6792')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6639', 'MIN test acc 0.6792')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5462', 'avg train acc ', '0.9253')\n",
      "('Epoch 00000020 ', 'valid loss 0.2526', 'valid acc 0.9363')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2526', 'WORST valid acc 0.9209')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2500', 'MIN valid acc 0.9208')\n",
      "('Epoch 00000020 ', 'test loss 0.7175', 'test acc 0.7531')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7175', 'WORST test acc 0.6922')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7175', 'MIN test acc 0.6922')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5263', 'avg train acc ', '0.9223')\n",
      "('Epoch 00000030 ', 'valid loss 0.2565', 'valid acc 0.9173')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2565', 'WORST valid acc 0.8951')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2552', 'MIN valid acc 0.8892')\n",
      "('Epoch 00000030 ', 'test loss 0.6372', 'test acc 0.7534')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6372', 'WORST test acc 0.6820')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6372', 'MIN test acc 0.6820')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5072', 'avg train acc ', '0.9236')\n",
      "('Epoch 00000040 ', 'valid loss 0.2056', 'valid acc 0.9364')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2056', 'WORST valid acc 0.9293')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2022', 'MIN valid acc 0.9254')\n",
      "('Epoch 00000040 ', 'test loss 0.8187', 'test acc 0.7130')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8187', 'WORST test acc 0.6840')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC test loss 0.4682', 'MIN test acc 0.6576')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.5176', 'avg train acc ', '0.9292')\n",
      "('Epoch 00000050 ', 'valid loss 0.2531', 'valid acc 0.9405')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2531', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2531', 'MIN valid acc 0.9272')\n",
      "('Epoch 00000050 ', 'test loss 0.6619', 'test acc 0.7537')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6619', 'WORST test acc 0.7036')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6619', 'MIN test acc 0.7036')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5410', 'avg train acc ', '0.9103')\n",
      "('Epoch 00000010 ', 'valid loss 0.3161', 'valid acc 0.8668')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.3161', 'WORST valid acc 0.8615')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.3105', 'MIN valid acc 0.8485')\n",
      "('Epoch 00000010 ', 'test loss 0.6150', 'test acc 0.7450')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6150', 'WORST test acc 0.7172')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6040', 'MIN test acc 0.6920')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5522', 'avg train acc ', '0.9284')\n",
      "('Epoch 00000020 ', 'valid loss 0.3026', 'valid acc 0.9291')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.3026', 'WORST valid acc 0.9486')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2668', 'MIN valid acc 0.9019')\n",
      "('Epoch 00000020 ', 'test loss 0.6378', 'test acc 0.7548')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6378', 'WORST test acc 0.6916')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6378', 'MIN test acc 0.6916')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.5202', 'avg train acc ', '0.9252')\n",
      "('Epoch 00000030 ', 'valid loss 0.2540', 'valid acc 0.9368')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2540', 'WORST valid acc 0.9111')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2447', 'MIN valid acc 0.9100')\n",
      "('Epoch 00000030 ', 'test loss 0.6747', 'test acc 0.7530')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6747', 'WORST test acc 0.7026')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6747', 'MIN test acc 0.7026')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.5131', 'avg train acc ', '0.9316')\n",
      "('Epoch 00000040 ', 'valid loss 0.2650', 'valid acc 0.9275')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2650', 'WORST valid acc 0.9038')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2650', 'MIN valid acc 0.9038')\n",
      "('Epoch 00000040 ', 'test loss 0.7108', 'test acc 0.7251')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7108', 'WORST test acc 0.7216')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5955', 'MIN test acc 0.6650')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4816', 'avg train acc ', '0.9299')\n",
      "('Epoch 00000050 ', 'valid loss 0.2323', 'valid acc 0.9336')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2323', 'WORST valid acc 0.9166')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2286', 'MIN valid acc 0.9047')\n",
      "('Epoch 00000050 ', 'test loss 0.6542', 'test acc 0.7499')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6542', 'WORST test acc 0.7618')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5844', 'MIN test acc 0.6916')\n",
      "===FINAL RESULTS WITH NODE 5===\n",
      "('VALID: acc 0.9336', 'accs sd 0.0098', 'loss 0.2380', 'loss sd 0.0202')\n",
      "('TEST: acc 0.7533', 'accs sd 0.0128', 'loss 0.6449', 'loss sd 0.0339')\n",
      "('WORST VALID: acc 0.9194', 'accs sd 0.0192', 'loss 0.2380', 'loss sd 0.0202')\n",
      "WORST VALID DOMAINS: [0, 0, 9, 8, 0, 3, 9, 1, 3, 1]\n",
      "('WORST TEST: acc 0.7001', 'accs sd 0.0446', 'loss 0.6449', 'loss sd 0.0339')\n",
      "WORST TEST DOMAINS: [2, 2, 1, 2, 0, 4, 2, 2, 2, 2]\n",
      "('MIN VALID: acc 0.9156', 'accs sd 0.0172', 'loss 0.2351', 'loss sd 0.0203')\n",
      "MIN VALID DOMAINS: [1, 0, 9, 1, 5, 3, 6, 1, 3, 4]\n",
      "('MIN TEST: acc 0.6840', 'accs sd 0.0398', 'loss 0.6070', 'loss sd 0.0534')\n",
      "MIN TEST DOMAINS: [1, 2, 1, 4, 2, 4, 2, 2, 2, 1]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5084', 'avg train acc ', '0.9206')\n",
      "('Epoch 00000010 ', 'valid loss 0.2362', 'valid acc 0.9210')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2362', 'WORST valid acc 0.9009')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2294', 'MIN valid acc 0.8966')\n",
      "('Epoch 00000010 ', 'test loss 0.6919', 'test acc 0.7536')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6919', 'WORST test acc 0.7220')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6919', 'MIN test acc 0.7220')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4672', 'avg train acc ', '0.9328')\n",
      "('Epoch 00000020 ', 'valid loss 0.1974', 'valid acc 0.9473')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1974', 'WORST valid acc 0.9346')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1974', 'MIN valid acc 0.9346')\n",
      "('Epoch 00000020 ', 'test loss 0.6044', 'test acc 0.8002')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6044', 'WORST test acc 0.7496')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6044', 'MIN test acc 0.7496')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4642', 'avg train acc ', '0.9439')\n",
      "('Epoch 00000030 ', 'valid loss 0.2133', 'valid acc 0.9400')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2133', 'WORST valid acc 0.9274')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2133', 'MIN valid acc 0.9274')\n",
      "('Epoch 00000030 ', 'test loss 0.5754', 'test acc 0.7815')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5754', 'WORST test acc 0.7650')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5451', 'MIN test acc 0.7348')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4490', 'avg train acc ', '0.9447')\n",
      "('Epoch 00000040 ', 'valid loss 0.2019', 'valid acc 0.9438')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2019', 'WORST valid acc 0.9262')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2019', 'MIN valid acc 0.9262')\n",
      "('Epoch 00000040 ', 'test loss 0.5938', 'test acc 0.7828')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5938', 'WORST test acc 0.7514')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5639', 'MIN test acc 0.7086')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4714', 'avg train acc ', '0.9341')\n",
      "('Epoch 00000050 ', 'valid loss 0.1864', 'valid acc 0.9411')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1864', 'WORST valid acc 0.9367')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1834', 'MIN valid acc 0.9303')\n",
      "('Epoch 00000050 ', 'test loss 0.5501', 'test acc 0.8210')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5501', 'WORST test acc 0.7982')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.4928', 'MIN test acc 0.7668')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5140', 'avg train acc ', '0.9220')\n",
      "('Epoch 00000010 ', 'valid loss 0.2368', 'valid acc 0.9299')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2368', 'WORST valid acc 0.9038')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2337', 'MIN valid acc 0.9030')\n",
      "('Epoch 00000010 ', 'test loss 0.6805', 'test acc 0.7426')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6805', 'WORST test acc 0.7032')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6805', 'MIN test acc 0.7032')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4513', 'avg train acc ', '0.9434')\n",
      "('Epoch 00000020 ', 'valid loss 0.2080', 'valid acc 0.9442')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.2080', 'WORST valid acc 0.9257')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2080', 'MIN valid acc 0.9257')\n",
      "('Epoch 00000020 ', 'test loss 0.8073', 'test acc 0.7440')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8073', 'WORST test acc 0.6770')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8073', 'MIN test acc 0.6770')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4781', 'avg train acc ', '0.9420')\n",
      "('Epoch 00000030 ', 'valid loss 0.2213', 'valid acc 0.9411')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2213', 'WORST valid acc 0.9166')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2213', 'MIN valid acc 0.9166')\n",
      "('Epoch 00000030 ', 'test loss 0.6810', 'test acc 0.7526')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6810', 'WORST test acc 0.6808')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6810', 'MIN test acc 0.6808')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4248', 'avg train acc ', '0.9518')\n",
      "('Epoch 00000040 ', 'valid loss 0.1949', 'valid acc 0.9425')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1949', 'WORST valid acc 0.9304')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1895', 'MIN valid acc 0.9195')\n",
      "('Epoch 00000040 ', 'test loss 0.7691', 'test acc 0.7641')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7691', 'WORST test acc 0.7102')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7691', 'MIN test acc 0.7102')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4243', 'avg train acc ', '0.9465')\n",
      "('Epoch 00000050 ', 'valid loss 0.1740', 'valid acc 0.9515')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1740', 'WORST valid acc 0.9367')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1740', 'MIN valid acc 0.9367')\n",
      "('Epoch 00000050 ', 'test loss 0.8365', 'test acc 0.7627')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8365', 'WORST test acc 0.7328')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8365', 'MIN test acc 0.7328')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5044', 'avg train acc ', '0.9286')\n",
      "('Epoch 00000010 ', 'valid loss 0.2822', 'valid acc 0.9156')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2822', 'WORST valid acc 0.8935')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2822', 'MIN valid acc 0.8935')\n",
      "('Epoch 00000010 ', 'test loss 0.5896', 'test acc 0.7769')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5896', 'WORST test acc 0.7096')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5896', 'MIN test acc 0.7096')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4830', 'avg train acc ', '0.9308')\n",
      "('Epoch 00000020 ', 'valid loss 0.2291', 'valid acc 0.9383')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2291', 'WORST valid acc 0.9346')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2240', 'MIN valid acc 0.9235')\n",
      "('Epoch 00000020 ', 'test loss 0.7353', 'test acc 0.7480')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7353', 'WORST test acc 0.6752')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7353', 'MIN test acc 0.6752')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4774', 'avg train acc ', '0.9376')\n",
      "('Epoch 00000030 ', 'valid loss 0.2298', 'valid acc 0.9417')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2298', 'WORST valid acc 0.9188')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2298', 'MIN valid acc 0.9188')\n",
      "('Epoch 00000030 ', 'test loss 0.6898', 'test acc 0.7604')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6898', 'WORST test acc 0.7380')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5999', 'MIN test acc 0.7006')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4340', 'avg train acc ', '0.9453')\n",
      "('Epoch 00000040 ', 'valid loss 0.2113', 'valid acc 0.9314')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.2113', 'WORST valid acc 0.9219')\n",
      "('WORST ACC DOMAIN 00000007 ', 'WORST ACC valid loss 0.2113', 'MIN valid acc 0.9219')\n",
      "('Epoch 00000040 ', 'test loss 0.5337', 'test acc 0.7806')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5337', 'WORST test acc 0.6802')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5337', 'MIN test acc 0.6802')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4144', 'avg train acc ', '0.9540')\n",
      "('Epoch 00000050 ', 'valid loss 0.1780', 'valid acc 0.9575')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.1780', 'WORST valid acc 0.9629')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1592', 'MIN valid acc 0.9433')\n",
      "('Epoch 00000050 ', 'test loss 0.6907', 'test acc 0.8036')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6907', 'WORST test acc 0.7838')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.4539', 'MIN test acc 0.7430')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4944', 'avg train acc ', '0.9265')\n",
      "('Epoch 00000010 ', 'valid loss 0.2300', 'valid acc 0.9320')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2300', 'WORST valid acc 0.9318')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2210', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000010 ', 'test loss 0.5765', 'test acc 0.7430')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5765', 'WORST test acc 0.7412')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5616', 'MIN test acc 0.6918')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4893', 'avg train acc ', '0.9275')\n",
      "('Epoch 00000020 ', 'valid loss 0.2526', 'valid acc 0.9411')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2526', 'WORST valid acc 0.9498')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2430', 'MIN valid acc 0.9264')\n",
      "('Epoch 00000020 ', 'test loss 0.5307', 'test acc 0.7672')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.5307', 'WORST test acc 0.6922')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5307', 'MIN test acc 0.6922')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4939', 'avg train acc ', '0.9312')\n",
      "('Epoch 00000030 ', 'valid loss 0.2410', 'valid acc 0.9171')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2410', 'WORST valid acc 0.9008')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2390', 'MIN valid acc 0.8979')\n",
      "('Epoch 00000030 ', 'test loss 0.5180', 'test acc 0.7674')\n",
      "('WORST DOMAIN 00000004 ', 'MAX test loss 0.5180', 'WORST test acc 0.7390')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.4940', 'MIN test acc 0.7012')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4838', 'avg train acc ', '0.9190')\n",
      "('Epoch 00000040 ', 'valid loss 0.2195', 'valid acc 0.9374')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2195', 'WORST valid acc 0.9078')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2195', 'MIN valid acc 0.9078')\n",
      "('Epoch 00000040 ', 'test loss 0.5828', 'test acc 0.7615')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5828', 'WORST test acc 0.7268')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5828', 'MIN test acc 0.7268')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4325', 'avg train acc ', '0.9425')\n",
      "('Epoch 00000050 ', 'valid loss 0.1834', 'valid acc 0.9383')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1834', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1834', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000050 ', 'test loss 0.7221', 'test acc 0.7100')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7221', 'WORST test acc 0.6866')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.4796', 'MIN test acc 0.6802')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4856', 'avg train acc ', '0.9321')\n",
      "('Epoch 00000010 ', 'valid loss 0.2225', 'valid acc 0.9415')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2225', 'WORST valid acc 0.9154')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2225', 'MIN valid acc 0.9154')\n",
      "('Epoch 00000010 ', 'test loss 0.7043', 'test acc 0.7644')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7043', 'WORST test acc 0.6964')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7043', 'MIN test acc 0.6964')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4750', 'avg train acc ', '0.9431')\n",
      "('Epoch 00000020 ', 'valid loss 0.1932', 'valid acc 0.9474')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1932', 'WORST valid acc 0.9293')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1932', 'MIN valid acc 0.9293')\n",
      "('Epoch 00000020 ', 'test loss 0.7278', 'test acc 0.7538')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7278', 'WORST test acc 0.6920')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7278', 'MIN test acc 0.6920')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4566', 'avg train acc ', '0.9502')\n",
      "('Epoch 00000030 ', 'valid loss 0.2277', 'valid acc 0.9497')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2277', 'WORST valid acc 0.9303')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2277', 'MIN valid acc 0.9303')\n",
      "('Epoch 00000030 ', 'test loss 0.6369', 'test acc 0.7274')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6369', 'WORST test acc 0.6982')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5987', 'MIN test acc 0.6668')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4556', 'avg train acc ', '0.9512')\n",
      "('Epoch 00000040 ', 'valid loss 0.2162', 'valid acc 0.9509')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2162', 'WORST valid acc 0.9411')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2085', 'MIN valid acc 0.9352')\n",
      "('Epoch 00000040 ', 'test loss 0.7802', 'test acc 0.7259')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7802', 'WORST test acc 0.6950')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7324', 'MIN test acc 0.6488')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4478', 'avg train acc ', '0.9546')\n",
      "('Epoch 00000050 ', 'valid loss 0.1934', 'valid acc 0.9536')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1934', 'WORST valid acc 0.9443')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1865', 'MIN valid acc 0.9420')\n",
      "('Epoch 00000050 ', 'test loss 0.7387', 'test acc 0.7314')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.7387', 'WORST test acc 0.6370')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7387', 'MIN test acc 0.6370')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4852', 'avg train acc ', '0.9332')\n",
      "('Epoch 00000010 ', 'valid loss 0.2017', 'valid acc 0.9435')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.2017', 'WORST valid acc 0.9308')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1994', 'MIN valid acc 0.9304')\n",
      "('Epoch 00000010 ', 'test loss 0.6063', 'test acc 0.7756')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6063', 'WORST test acc 0.7220')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6063', 'MIN test acc 0.7220')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4752', 'avg train acc ', '0.9392')\n",
      "('Epoch 00000020 ', 'valid loss 0.2689', 'valid acc 0.9409')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2689', 'WORST valid acc 0.9264')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2689', 'MIN valid acc 0.9264')\n",
      "('Epoch 00000020 ', 'test loss 0.6197', 'test acc 0.7612')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6197', 'WORST test acc 0.7274')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.4680', 'MIN test acc 0.7052')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4711', 'avg train acc ', '0.9341')\n",
      "('Epoch 00000030 ', 'valid loss 0.2126', 'valid acc 0.9343')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2126', 'WORST valid acc 0.9215')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2114', 'MIN valid acc 0.9167')\n",
      "('Epoch 00000030 ', 'test loss 0.6550', 'test acc 0.7701')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6550', 'WORST test acc 0.7128')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6550', 'MIN test acc 0.7128')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4547', 'avg train acc ', '0.9432')\n",
      "('Epoch 00000040 ', 'valid loss 0.2134', 'valid acc 0.9416')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2134', 'WORST valid acc 0.9188')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2134', 'MIN valid acc 0.9188')\n",
      "('Epoch 00000040 ', 'test loss 0.6192', 'test acc 0.7798')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6192', 'WORST test acc 0.7106')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6192', 'MIN test acc 0.7106')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4278', 'avg train acc ', '0.9412')\n",
      "('Epoch 00000050 ', 'valid loss 0.1790', 'valid acc 0.9425')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1790', 'WORST valid acc 0.9342')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1759', 'MIN valid acc 0.9248')\n",
      "('Epoch 00000050 ', 'test loss 0.7061', 'test acc 0.6943')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7061', 'WORST test acc 0.6666')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC test loss 0.5429', 'MIN test acc 0.5530')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5013', 'avg train acc ', '0.9308')\n",
      "('Epoch 00000010 ', 'valid loss 0.2272', 'valid acc 0.9383')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2272', 'WORST valid acc 0.9399')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2062', 'MIN valid acc 0.9300')\n",
      "('Epoch 00000010 ', 'test loss 0.6064', 'test acc 0.7634')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6064', 'WORST test acc 0.6998')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6064', 'MIN test acc 0.6998')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5115', 'avg train acc ', '0.9175')\n",
      "('Epoch 00000020 ', 'valid loss 0.2254', 'valid acc 0.9264')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2254', 'WORST valid acc 0.9177')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2159', 'MIN valid acc 0.9139')\n",
      "('Epoch 00000020 ', 'test loss 0.7382', 'test acc 0.7606')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7382', 'WORST test acc 0.7012')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7382', 'MIN test acc 0.7012')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4799', 'avg train acc ', '0.9361')\n",
      "('Epoch 00000030 ', 'valid loss 0.2485', 'valid acc 0.9391')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2485', 'WORST valid acc 0.9325')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.2043', 'MIN valid acc 0.9280')\n",
      "('Epoch 00000030 ', 'test loss 0.6632', 'test acc 0.7708')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6632', 'WORST test acc 0.7338')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5159', 'MIN test acc 0.7166')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4765', 'avg train acc ', '0.9397')\n",
      "('Epoch 00000040 ', 'valid loss 0.2391', 'valid acc 0.9293')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2391', 'WORST valid acc 0.9346')\n",
      "('WORST ACC DOMAIN 00000007 ', 'WORST ACC valid loss 0.1641', 'MIN valid acc 0.9130')\n",
      "('Epoch 00000040 ', 'test loss 0.6672', 'test acc 0.7602')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6672', 'WORST test acc 0.6936')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6672', 'MIN test acc 0.6936')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4611', 'avg train acc ', '0.9408')\n",
      "('Epoch 00000050 ', 'valid loss 0.1996', 'valid acc 0.9285')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1996', 'WORST valid acc 0.9219')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1977', 'MIN valid acc 0.9146')\n",
      "('Epoch 00000050 ', 'test loss 0.7103', 'test acc 0.7481')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7103', 'WORST test acc 0.7106')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.7103', 'MIN test acc 0.7106')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5145', 'avg train acc ', '0.9233')\n",
      "('Epoch 00000010 ', 'valid loss 0.2494', 'valid acc 0.9244')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2494', 'WORST valid acc 0.9101')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2494', 'MIN valid acc 0.9101')\n",
      "('Epoch 00000010 ', 'test loss 0.7534', 'test acc 0.7446')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7534', 'WORST test acc 0.6944')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7534', 'MIN test acc 0.6944')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4996', 'avg train acc ', '0.9347')\n",
      "('Epoch 00000020 ', 'valid loss 0.2889', 'valid acc 0.9267')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2889', 'WORST valid acc 0.9048')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2889', 'MIN valid acc 0.9048')\n",
      "('Epoch 00000020 ', 'test loss 0.7453', 'test acc 0.7476')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7453', 'WORST test acc 0.6796')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7453', 'MIN test acc 0.6796')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4947', 'avg train acc ', '0.9337')\n",
      "('Epoch 00000030 ', 'valid loss 0.2102', 'valid acc 0.9342')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2102', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2102', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000030 ', 'test loss 0.6918', 'test acc 0.7477')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6918', 'WORST test acc 0.6968')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6918', 'MIN test acc 0.6968')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4810', 'avg train acc ', '0.9326')\n",
      "('Epoch 00000040 ', 'valid loss 0.2236', 'valid acc 0.9359')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2236', 'WORST valid acc 0.9198')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2236', 'MIN valid acc 0.9198')\n",
      "('Epoch 00000040 ', 'test loss 0.6571', 'test acc 0.7805')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6571', 'WORST test acc 0.7180')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6571', 'MIN test acc 0.7180')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4396', 'avg train acc ', '0.9485')\n",
      "('Epoch 00000050 ', 'valid loss 0.1889', 'valid acc 0.9334')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1889', 'WORST valid acc 0.9136')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1889', 'MIN valid acc 0.9136')\n",
      "('Epoch 00000050 ', 'test loss 0.6936', 'test acc 0.7750')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6936', 'WORST test acc 0.7132')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6936', 'MIN test acc 0.7132')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4930', 'avg train acc ', '0.9266')\n",
      "('Epoch 00000010 ', 'valid loss 0.2184', 'valid acc 0.9326')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2184', 'WORST valid acc 0.9156')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2184', 'MIN valid acc 0.9156')\n",
      "('Epoch 00000010 ', 'test loss 0.6551', 'test acc 0.7558')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.6551', 'WORST test acc 0.7010')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6551', 'MIN test acc 0.7010')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4769', 'avg train acc ', '0.9296')\n",
      "('Epoch 00000020 ', 'valid loss 0.2036', 'valid acc 0.9406')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2036', 'WORST valid acc 0.9388')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1936', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000020 ', 'test loss 0.6954', 'test acc 0.7660')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6954', 'WORST test acc 0.7012')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6954', 'MIN test acc 0.7012')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4839', 'avg train acc ', '0.9426')\n",
      "('Epoch 00000030 ', 'valid loss 0.2214', 'valid acc 0.9466')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2214', 'WORST valid acc 0.9274')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2214', 'MIN valid acc 0.9274')\n",
      "('Epoch 00000030 ', 'test loss 0.5939', 'test acc 0.7631')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5939', 'WORST test acc 0.7336')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5678', 'MIN test acc 0.7052')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4648', 'avg train acc ', '0.9381')\n",
      "('Epoch 00000040 ', 'valid loss 0.1947', 'valid acc 0.9451')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1947', 'WORST valid acc 0.9399')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.1868', 'MIN valid acc 0.9307')\n",
      "('Epoch 00000040 ', 'test loss 0.6161', 'test acc 0.7678')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6161', 'WORST test acc 0.7156')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6161', 'MIN test acc 0.7156')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4935', 'avg train acc ', '0.9262')\n",
      "('Epoch 00000050 ', 'valid loss 0.2265', 'valid acc 0.9241')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2265', 'WORST valid acc 0.8903')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2265', 'MIN valid acc 0.8903')\n",
      "('Epoch 00000050 ', 'test loss 0.6483', 'test acc 0.7655')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6483', 'WORST test acc 0.7346')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6346', 'MIN test acc 0.6946')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5037', 'avg train acc ', '0.9254')\n",
      "('Epoch 00000010 ', 'valid loss 0.2298', 'valid acc 0.9292')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2298', 'WORST valid acc 0.9270')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2271', 'MIN valid acc 0.9215')\n",
      "('Epoch 00000010 ', 'test loss 0.8054', 'test acc 0.7580')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8054', 'WORST test acc 0.6908')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8054', 'MIN test acc 0.6908')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4656', 'avg train acc ', '0.9476')\n",
      "('Epoch 00000020 ', 'valid loss 0.2104', 'valid acc 0.9475')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2104', 'WORST valid acc 0.9314')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2064', 'MIN valid acc 0.9261')\n",
      "('Epoch 00000020 ', 'test loss 0.6506', 'test acc 0.7764')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6506', 'WORST test acc 0.7310')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6506', 'MIN test acc 0.7310')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4828', 'avg train acc ', '0.9427')\n",
      "('Epoch 00000030 ', 'valid loss 0.2129', 'valid acc 0.9437')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2129', 'WORST valid acc 0.9333')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2129', 'MIN valid acc 0.9333')\n",
      "('Epoch 00000030 ', 'test loss 0.6345', 'test acc 0.7459')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6345', 'WORST test acc 0.7000')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6345', 'MIN test acc 0.7000')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4668', 'avg train acc ', '0.9435')\n",
      "('Epoch 00000040 ', 'valid loss 0.2313', 'valid acc 0.9441')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2313', 'WORST valid acc 0.9185')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2313', 'MIN valid acc 0.9185')\n",
      "('Epoch 00000040 ', 'test loss 0.8848', 'test acc 0.7531')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8848', 'WORST test acc 0.6788')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8848', 'MIN test acc 0.6788')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4574', 'avg train acc ', '0.9407')\n",
      "('Epoch 00000050 ', 'valid loss 0.2222', 'valid acc 0.9393')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2222', 'WORST valid acc 0.9254')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.2215', 'MIN valid acc 0.9170')\n",
      "('Epoch 00000050 ', 'test loss 0.7017', 'test acc 0.7741')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7017', 'WORST test acc 0.7194')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7017', 'MIN test acc 0.7194')\n",
      "===FINAL RESULTS WITH NODE 10===\n",
      "('VALID: acc 0.9410', 'accs sd 0.0103', 'loss 0.1931', 'loss sd 0.0172')\n",
      "('TEST: acc 0.7586', 'accs sd 0.0372', 'loss 0.6998', 'loss sd 0.0678')\n",
      "('WORST VALID: acc 0.9282', 'accs sd 0.0187', 'loss 0.1931', 'loss sd 0.0172')\n",
      "WORST VALID DOMAINS: [0, 0, 9, 1, 3, 1, 0, 1, 0, 1]\n",
      "('WORST TEST: acc 0.7183', 'accs sd 0.0464', 'loss 0.6998', 'loss sd 0.0678')\n",
      "WORST TEST DOMAINS: [0, 2, 0, 2, 1, 2, 0, 2, 2, 2]\n",
      "('MIN VALID: acc 0.9228', 'accs sd 0.0153', 'loss 0.1897', 'loss sd 0.0197')\n",
      "MIN VALID DOMAINS: [1, 0, 3, 1, 0, 2, 1, 1, 0, 5]\n",
      "('MIN TEST: acc 0.6951', 'accs sd 0.0581', 'loss 0.6285', 'loss sd 0.1225')\n",
      "MIN TEST DOMAINS: [2, 2, 2, 4, 1, 4, 0, 2, 1, 2]\n",
      "===ITERATION 1===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5258', 'avg train acc ', '0.9210')\n",
      "('Epoch 00000010 ', 'valid loss 0.2404', 'valid acc 0.9345')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2404', 'WORST valid acc 0.9328')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2097', 'MIN valid acc 0.9219')\n",
      "('Epoch 00000010 ', 'test loss 0.6902', 'test acc 0.7432')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6902', 'WORST test acc 0.7286')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5425', 'MIN test acc 0.7078')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5013', 'avg train acc ', '0.9244')\n",
      "('Epoch 00000020 ', 'valid loss 0.2318', 'valid acc 0.9326')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2318', 'WORST valid acc 0.9168')\n",
      "('WORST ACC DOMAIN 00000009 ', 'WORST ACC valid loss 0.2318', 'MIN valid acc 0.9168')\n",
      "('Epoch 00000020 ', 'test loss 0.5959', 'test acc 0.7487')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.5959', 'WORST test acc 0.6792')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5959', 'MIN test acc 0.6792')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4579', 'avg train acc ', '0.9429')\n",
      "('Epoch 00000030 ', 'valid loss 0.1983', 'valid acc 0.9465')\n",
      "('WORST DOMAIN 00000002 ', 'MAX valid loss 0.1983', 'WORST valid acc 0.9386')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1921', 'MIN valid acc 0.9358')\n",
      "('Epoch 00000030 ', 'test loss 0.6391', 'test acc 0.7509')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6391', 'WORST test acc 0.7106')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6205', 'MIN test acc 0.6966')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4311', 'avg train acc ', '0.9460')\n",
      "('Epoch 00000040 ', 'valid loss 0.1738', 'valid acc 0.9442')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1738', 'WORST valid acc 0.9408')\n",
      "('WORST ACC DOMAIN 00000006 ', 'WORST ACC valid loss 0.1577', 'MIN valid acc 0.9397')\n",
      "('Epoch 00000040 ', 'test loss 0.7084', 'test acc 0.7684')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7084', 'WORST test acc 0.7464')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.5404', 'MIN test acc 0.7390')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4440', 'avg train acc ', '0.9402')\n",
      "('Epoch 00000050 ', 'valid loss 0.1802', 'valid acc 0.9432')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1802', 'WORST valid acc 0.9230')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1802', 'MIN valid acc 0.9230')\n",
      "('Epoch 00000050 ', 'test loss 0.6603', 'test acc 0.7740')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6603', 'WORST test acc 0.7292')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6603', 'MIN test acc 0.7292')\n",
      "===ITERATION 2===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5127', 'avg train acc ', '0.9290')\n",
      "('Epoch 00000010 ', 'valid loss 0.2028', 'valid acc 0.9414')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.2028', 'WORST valid acc 0.9338')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2003', 'MIN valid acc 0.9283')\n",
      "('Epoch 00000010 ', 'test loss 0.7711', 'test acc 0.7641')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7711', 'WORST test acc 0.7234')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7711', 'MIN test acc 0.7234')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.5068', 'avg train acc ', '0.9315')\n",
      "('Epoch 00000020 ', 'valid loss 0.2471', 'valid acc 0.9215')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2471', 'WORST valid acc 0.9244')\n",
      "('WORST ACC DOMAIN 00000008 ', 'WORST ACC valid loss 0.2007', 'MIN valid acc 0.9025')\n",
      "('Epoch 00000020 ', 'test loss 0.7594', 'test acc 0.7234')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7594', 'WORST test acc 0.6820')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7594', 'MIN test acc 0.6820')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4529', 'avg train acc ', '0.9430')\n",
      "('Epoch 00000030 ', 'valid loss 0.2261', 'valid acc 0.9224')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.2261', 'WORST valid acc 0.8758')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2261', 'MIN valid acc 0.8758')\n",
      "('Epoch 00000030 ', 'test loss 0.8402', 'test acc 0.7488')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8402', 'WORST test acc 0.6876')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8402', 'MIN test acc 0.6876')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4096', 'avg train acc ', '0.9511')\n",
      "('Epoch 00000040 ', 'valid loss 0.1790', 'valid acc 0.9451')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1790', 'WORST valid acc 0.9313')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1790', 'MIN valid acc 0.9313')\n",
      "('Epoch 00000040 ', 'test loss 0.7637', 'test acc 0.7646')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7637', 'WORST test acc 0.7060')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7637', 'MIN test acc 0.7060')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4198', 'avg train acc ', '0.9514')\n",
      "('Epoch 00000050 ', 'valid loss 0.1895', 'valid acc 0.9569')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.1895', 'WORST valid acc 0.9594')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1719', 'MIN valid acc 0.9441')\n",
      "('Epoch 00000050 ', 'test loss 0.7687', 'test acc 0.7754')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7687', 'WORST test acc 0.7504')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5769', 'MIN test acc 0.7196')\n",
      "===ITERATION 3===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4984', 'avg train acc ', '0.9332')\n",
      "('Epoch 00000010 ', 'valid loss 0.2619', 'valid acc 0.9246')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.2619', 'WORST valid acc 0.9110')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2581', 'MIN valid acc 0.9068')\n",
      "('Epoch 00000010 ', 'test loss 0.6197', 'test acc 0.7615')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6197', 'WORST test acc 0.7062')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6197', 'MIN test acc 0.7062')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4832', 'avg train acc ', '0.9298')\n",
      "('Epoch 00000020 ', 'valid loss 0.2024', 'valid acc 0.9349')\n",
      "('WORST DOMAIN 00000007 ', 'MAX valid loss 0.2024', 'WORST valid acc 0.9377')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1955', 'MIN valid acc 0.9240')\n",
      "('Epoch 00000020 ', 'test loss 0.6935', 'test acc 0.7712')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6935', 'WORST test acc 0.7112')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6935', 'MIN test acc 0.7112')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4478', 'avg train acc ', '0.9458')\n",
      "('Epoch 00000030 ', 'valid loss 0.1735', 'valid acc 0.9453')\n",
      "('WORST DOMAIN 00000006 ', 'MAX valid loss 0.1735', 'WORST valid acc 0.9407')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1723', 'MIN valid acc 0.9378')\n",
      "('Epoch 00000030 ', 'test loss 0.7997', 'test acc 0.7780')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7997', 'WORST test acc 0.7220')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7997', 'MIN test acc 0.7220')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4807', 'avg train acc ', '0.9413')\n",
      "('Epoch 00000040 ', 'valid loss 0.2557', 'valid acc 0.9279')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2557', 'WORST valid acc 0.9114')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2433', 'MIN valid acc 0.9078')\n",
      "('Epoch 00000040 ', 'test loss 0.6446', 'test acc 0.7625')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6446', 'WORST test acc 0.7118')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6446', 'MIN test acc 0.7118')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4328', 'avg train acc ', '0.9524')\n",
      "('Epoch 00000050 ', 'valid loss 0.1765', 'valid acc 0.9575')\n",
      "('WORST DOMAIN 00000003 ', 'MAX valid loss 0.1765', 'WORST valid acc 0.9454')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1733', 'MIN valid acc 0.9451')\n",
      "('Epoch 00000050 ', 'test loss 0.9247', 'test acc 0.7681')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9247', 'WORST test acc 0.6984')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9247', 'MIN test acc 0.6984')\n",
      "===ITERATION 4===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4812', 'avg train acc ', '0.9259')\n",
      "('Epoch 00000010 ', 'valid loss 0.2201', 'valid acc 0.9358')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2201', 'WORST valid acc 0.9205')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2201', 'MIN valid acc 0.9205')\n",
      "('Epoch 00000010 ', 'test loss 0.7996', 'test acc 0.7692')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7996', 'WORST test acc 0.7204')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7996', 'MIN test acc 0.7204')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4632', 'avg train acc ', '0.9342')\n",
      "('Epoch 00000020 ', 'valid loss 0.2166', 'valid acc 0.9403')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2166', 'WORST valid acc 0.9219')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC valid loss 0.2052', 'MIN valid acc 0.9208')\n",
      "('Epoch 00000020 ', 'test loss 0.6060', 'test acc 0.7744')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6060', 'WORST test acc 0.7220')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6060', 'MIN test acc 0.7220')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4301', 'avg train acc ', '0.9366')\n",
      "('Epoch 00000030 ', 'valid loss 0.1703', 'valid acc 0.9437')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1703', 'WORST valid acc 0.9308')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1703', 'MIN valid acc 0.9308')\n",
      "('Epoch 00000030 ', 'test loss 0.7517', 'test acc 0.7824')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7517', 'WORST test acc 0.7222')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7517', 'MIN test acc 0.7222')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4403', 'avg train acc ', '0.9449')\n",
      "('Epoch 00000040 ', 'valid loss 0.1930', 'valid acc 0.9479')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.1930', 'WORST valid acc 0.9599')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1621', 'MIN valid acc 0.9325')\n",
      "('Epoch 00000040 ', 'test loss 0.6491', 'test acc 0.7675')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.6491', 'WORST test acc 0.7456')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5453', 'MIN test acc 0.7200')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4052', 'avg train acc ', '0.9552')\n",
      "('Epoch 00000050 ', 'valid loss 0.1426', 'valid acc 0.9600')\n",
      "('WORST DOMAIN 00000008 ', 'MAX valid loss 0.1426', 'WORST valid acc 0.9545')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1240', 'MIN valid acc 0.9515')\n",
      "('Epoch 00000050 ', 'test loss 0.9358', 'test acc 0.7655')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9358', 'WORST test acc 0.7024')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9358', 'MIN test acc 0.7024')\n",
      "===ITERATION 5===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4779', 'avg train acc ', '0.9341')\n",
      "('Epoch 00000010 ', 'valid loss 0.2196', 'valid acc 0.9363')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2196', 'WORST valid acc 0.9283')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2039', 'MIN valid acc 0.9261')\n",
      "('Epoch 00000010 ', 'test loss 0.6959', 'test acc 0.7389')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6959', 'WORST test acc 0.7044')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6959', 'MIN test acc 0.7044')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4553', 'avg train acc ', '0.9386')\n",
      "('Epoch 00000020 ', 'valid loss 0.2039', 'valid acc 0.9435')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2039', 'WORST valid acc 0.9357')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1937', 'MIN valid acc 0.9308')\n",
      "('Epoch 00000020 ', 'test loss 0.7515', 'test acc 0.7609')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7515', 'WORST test acc 0.7078')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7515', 'MIN test acc 0.7078')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4403', 'avg train acc ', '0.9456')\n",
      "('Epoch 00000030 ', 'valid loss 0.2060', 'valid acc 0.9487')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2060', 'WORST valid acc 0.9251')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2060', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000030 ', 'test loss 0.8303', 'test acc 0.7586')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.8303', 'WORST test acc 0.7084')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.8303', 'MIN test acc 0.7084')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4260', 'avg train acc ', '0.9433')\n",
      "('Epoch 00000040 ', 'valid loss 0.1774', 'valid acc 0.9308')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1774', 'WORST valid acc 0.9114')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1729', 'MIN valid acc 0.9036')\n",
      "('Epoch 00000040 ', 'test loss 0.6104', 'test acc 0.7669')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6104', 'WORST test acc 0.7304')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6104', 'MIN test acc 0.7304')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4188', 'avg train acc ', '0.9449')\n",
      "('Epoch 00000050 ', 'valid loss 0.1838', 'valid acc 0.9449')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1838', 'WORST valid acc 0.9146')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1838', 'MIN valid acc 0.9146')\n",
      "('Epoch 00000050 ', 'test loss 0.6998', 'test acc 0.7536')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6998', 'WORST test acc 0.7122')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6998', 'MIN test acc 0.7122')\n",
      "===ITERATION 6===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5212', 'avg train acc ', '0.9246')\n",
      "('Epoch 00000010 ', 'valid loss 0.2212', 'valid acc 0.9386')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2212', 'WORST valid acc 0.9438')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2121', 'MIN valid acc 0.9262')\n",
      "('Epoch 00000010 ', 'test loss 0.7208', 'test acc 0.7435')\n",
      "('WORST DOMAIN 00000001 ', 'MAX test loss 0.7208', 'WORST test acc 0.6876')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.7208', 'MIN test acc 0.6876')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4810', 'avg train acc ', '0.9356')\n",
      "('Epoch 00000020 ', 'valid loss 0.2068', 'valid acc 0.9319')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2068', 'WORST valid acc 0.9272')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.2062', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000020 ', 'test loss 0.6499', 'test acc 0.7458')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6499', 'WORST test acc 0.7250')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC test loss 0.6179', 'MIN test acc 0.7192')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4631', 'avg train acc ', '0.9401')\n",
      "('Epoch 00000030 ', 'valid loss 0.1934', 'valid acc 0.9436')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1934', 'WORST valid acc 0.9304')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1918', 'MIN valid acc 0.9240')\n",
      "('Epoch 00000030 ', 'test loss 0.7059', 'test acc 0.7712')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7059', 'WORST test acc 0.7292')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7059', 'MIN test acc 0.7292')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4415', 'avg train acc ', '0.9496')\n",
      "('Epoch 00000040 ', 'valid loss 0.1803', 'valid acc 0.9480')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.1803', 'WORST valid acc 0.9418')\n",
      "('WORST ACC DOMAIN 00000003 ', 'WORST ACC valid loss 0.1725', 'MIN valid acc 0.9400')\n",
      "('Epoch 00000040 ', 'test loss 0.6735', 'test acc 0.7699')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6735', 'WORST test acc 0.7308')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6735', 'MIN test acc 0.7308')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4166', 'avg train acc ', '0.9505')\n",
      "('Epoch 00000050 ', 'valid loss 0.1806', 'valid acc 0.9501')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1806', 'WORST valid acc 0.9399')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1806', 'MIN valid acc 0.9399')\n",
      "('Epoch 00000050 ', 'test loss 0.7603', 'test acc 0.7426')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7603', 'WORST test acc 0.6788')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7603', 'MIN test acc 0.6788')\n",
      "===ITERATION 7===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4818', 'avg train acc ', '0.9326')\n",
      "('Epoch 00000010 ', 'valid loss 0.2095', 'valid acc 0.9396')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2095', 'WORST valid acc 0.9177')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2095', 'MIN valid acc 0.9177')\n",
      "('Epoch 00000010 ', 'test loss 0.5955', 'test acc 0.7599')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.5955', 'WORST test acc 0.7468')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5711', 'MIN test acc 0.6980')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4354', 'avg train acc ', '0.9502')\n",
      "('Epoch 00000020 ', 'valid loss 0.1671', 'valid acc 0.9494')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1671', 'WORST valid acc 0.9409')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1671', 'MIN valid acc 0.9409')\n",
      "('Epoch 00000020 ', 'test loss 0.7307', 'test acc 0.7640')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7307', 'WORST test acc 0.6986')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7307', 'MIN test acc 0.6986')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4525', 'avg train acc ', '0.9404')\n",
      "('Epoch 00000030 ', 'valid loss 0.2022', 'valid acc 0.9387')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.2022', 'WORST valid acc 0.9408')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2019', 'MIN valid acc 0.9230')\n",
      "('Epoch 00000030 ', 'test loss 0.6426', 'test acc 0.7849')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6426', 'WORST test acc 0.7324')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6426', 'MIN test acc 0.7324')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4212', 'avg train acc ', '0.9504')\n",
      "('Epoch 00000040 ', 'valid loss 0.1585', 'valid acc 0.9542')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1585', 'WORST valid acc 0.9494')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1574', 'MIN valid acc 0.9450')\n",
      "('Epoch 00000040 ', 'test loss 0.7653', 'test acc 0.7550')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7653', 'WORST test acc 0.7258')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7412', 'MIN test acc 0.6886')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4264', 'avg train acc ', '0.9400')\n",
      "('Epoch 00000050 ', 'valid loss 0.1655', 'valid acc 0.9441')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1655', 'WORST valid acc 0.9303')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1654', 'MIN valid acc 0.9268')\n",
      "('Epoch 00000050 ', 'test loss 0.6373', 'test acc 0.8032')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6373', 'WORST test acc 0.7508')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6373', 'MIN test acc 0.7508')\n",
      "===ITERATION 8===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.4706', 'avg train acc ', '0.9299')\n",
      "('Epoch 00000010 ', 'valid loss 0.2082', 'valid acc 0.9295')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2082', 'WORST valid acc 0.9087')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.2082', 'MIN valid acc 0.9087')\n",
      "('Epoch 00000010 ', 'test loss 0.7215', 'test acc 0.7496')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7215', 'WORST test acc 0.6806')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7215', 'MIN test acc 0.6806')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4350', 'avg train acc ', '0.9462')\n",
      "('Epoch 00000020 ', 'valid loss 0.2009', 'valid acc 0.9370')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2009', 'WORST valid acc 0.9325')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.1946', 'MIN valid acc 0.9278')\n",
      "('Epoch 00000020 ', 'test loss 0.5900', 'test acc 0.7743')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5900', 'WORST test acc 0.7114')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5900', 'MIN test acc 0.7114')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4139', 'avg train acc ', '0.9515')\n",
      "('Epoch 00000030 ', 'valid loss 0.1603', 'valid acc 0.9456')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1603', 'WORST valid acc 0.9323')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1603', 'MIN valid acc 0.9323')\n",
      "('Epoch 00000030 ', 'test loss 0.7539', 'test acc 0.7587')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7539', 'WORST test acc 0.7362')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7539', 'MIN test acc 0.7362')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4192', 'avg train acc ', '0.9506')\n",
      "('Epoch 00000040 ', 'valid loss 0.1609', 'valid acc 0.9507')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1609', 'WORST valid acc 0.9367')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1609', 'MIN valid acc 0.9367')\n",
      "('Epoch 00000040 ', 'test loss 0.6805', 'test acc 0.7554')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6805', 'WORST test acc 0.7192')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.6757', 'MIN test acc 0.7124')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4060', 'avg train acc ', '0.9523')\n",
      "('Epoch 00000050 ', 'valid loss 0.1751', 'valid acc 0.9595')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1751', 'WORST valid acc 0.9450')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1751', 'MIN valid acc 0.9450')\n",
      "('Epoch 00000050 ', 'test loss 0.7370', 'test acc 0.7699')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7370', 'WORST test acc 0.7178')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7370', 'MIN test acc 0.7178')\n",
      "===ITERATION 9===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5064', 'avg train acc ', '0.9319')\n",
      "('Epoch 00000010 ', 'valid loss 0.2711', 'valid acc 0.9406')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2711', 'WORST valid acc 0.9293')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2583', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000010 ', 'test loss 0.6080', 'test acc 0.7444')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6080', 'WORST test acc 0.6822')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6080', 'MIN test acc 0.6822')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4598', 'avg train acc ', '0.9344')\n",
      "('Epoch 00000020 ', 'valid loss 0.2075', 'valid acc 0.9323')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.2075', 'WORST valid acc 0.9205')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2030', 'MIN valid acc 0.9198')\n",
      "('Epoch 00000020 ', 'test loss 0.9090', 'test acc 0.7554')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.9090', 'WORST test acc 0.6710')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.9090', 'MIN test acc 0.6710')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4482', 'avg train acc ', '0.9432')\n",
      "('Epoch 00000030 ', 'valid loss 0.1955', 'valid acc 0.9403')\n",
      "('WORST DOMAIN 00000001 ', 'MAX valid loss 0.1955', 'WORST valid acc 0.9205')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1955', 'MIN valid acc 0.9205')\n",
      "('Epoch 00000030 ', 'test loss 0.6476', 'test acc 0.7636')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6476', 'WORST test acc 0.7236')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6476', 'MIN test acc 0.7236')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4595', 'avg train acc ', '0.9442')\n",
      "('Epoch 00000040 ', 'valid loss 0.1851', 'valid acc 0.9441')\n",
      "('WORST DOMAIN 00000005 ', 'MAX valid loss 0.1851', 'WORST valid acc 0.9320')\n",
      "('WORST ACC DOMAIN 00000005 ', 'WORST ACC valid loss 0.1851', 'MIN valid acc 0.9320')\n",
      "('Epoch 00000040 ', 'test loss 0.7350', 'test acc 0.7430')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7350', 'WORST test acc 0.6942')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7350', 'MIN test acc 0.6942')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.4814', 'avg train acc ', '0.9404')\n",
      "('Epoch 00000050 ', 'valid loss 0.2411', 'valid acc 0.9465')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2411', 'WORST valid acc 0.9251')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2411', 'MIN valid acc 0.9251')\n",
      "('Epoch 00000050 ', 'test loss 0.5430', 'test acc 0.7603')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.5430', 'WORST test acc 0.7260')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.5430', 'MIN test acc 0.7260')\n",
      "===ITERATION 10===\n",
      "('Epoch 00000010 ', 'avg train loss over', 800, ' batches ', '0.5105', 'avg train acc ', '0.9201')\n",
      "('Epoch 00000010 ', 'valid loss 0.2361', 'valid acc 0.9228')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.2361', 'WORST valid acc 0.8871')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.2361', 'MIN valid acc 0.8871')\n",
      "('Epoch 00000010 ', 'test loss 0.7323', 'test acc 0.7595')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7323', 'WORST test acc 0.7152')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7323', 'MIN test acc 0.7152')\n",
      "('Epoch 00000020 ', 'avg train loss over', 800, ' batches ', '0.4765', 'avg train acc ', '0.9342')\n",
      "('Epoch 00000020 ', 'valid loss 0.1975', 'valid acc 0.9316')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1975', 'WORST valid acc 0.9219')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1975', 'MIN valid acc 0.9219')\n",
      "('Epoch 00000020 ', 'test loss 0.7409', 'test acc 0.7709')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7409', 'WORST test acc 0.6984')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7409', 'MIN test acc 0.6984')\n",
      "('Epoch 00000030 ', 'avg train loss over', 800, ' batches ', '0.4516', 'avg train acc ', '0.9382')\n",
      "('Epoch 00000030 ', 'valid loss 0.2011', 'valid acc 0.9375')\n",
      "('WORST DOMAIN 00000004 ', 'MAX valid loss 0.2011', 'WORST valid acc 0.9318')\n",
      "('WORST ACC DOMAIN 00000004 ', 'WORST ACC valid loss 0.2011', 'MIN valid acc 0.9318')\n",
      "('Epoch 00000030 ', 'test loss 0.7184', 'test acc 0.7637')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.7184', 'WORST test acc 0.7552')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC test loss 0.5594', 'MIN test acc 0.7322')\n",
      "('Epoch 00000040 ', 'avg train loss over', 800, ' batches ', '0.4250', 'avg train acc ', '0.9419')\n",
      "('Epoch 00000040 ', 'valid loss 0.1628', 'valid acc 0.9437')\n",
      "('WORST DOMAIN 00000009 ', 'MAX valid loss 0.1628', 'WORST valid acc 0.9448')\n",
      "('WORST ACC DOMAIN 00000001 ', 'WORST ACC valid loss 0.1543', 'MIN valid acc 0.9303')\n",
      "('Epoch 00000040 ', 'test loss 0.6420', 'test acc 0.7892')\n",
      "('WORST DOMAIN 00000002 ', 'MAX test loss 0.6420', 'WORST test acc 0.7224')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.6420', 'MIN test acc 0.7224')\n",
      "('Epoch 00000050 ', 'avg train loss over', 800, ' batches ', '0.3987', 'avg train acc ', '0.9475')\n",
      "('Epoch 00000050 ', 'valid loss 0.1574', 'valid acc 0.9527')\n",
      "('WORST DOMAIN 00000000 ', 'MAX valid loss 0.1574', 'WORST valid acc 0.9367')\n",
      "('WORST ACC DOMAIN 00000000 ', 'WORST ACC valid loss 0.1574', 'MIN valid acc 0.9367')\n",
      "('Epoch 00000050 ', 'test loss 0.7844', 'test acc 0.7859')\n",
      "('WORST DOMAIN 00000000 ', 'MAX test loss 0.7844', 'WORST test acc 0.7720')\n",
      "('WORST ACC DOMAIN 00000002 ', 'WORST ACC test loss 0.7128', 'MIN test acc 0.7252')\n",
      "===FINAL RESULTS WITH NODE 15===\n",
      "('VALID: acc 0.9515', 'accs sd 0.0063', 'loss 0.1792', 'loss sd 0.0245')\n",
      "('TEST: acc 0.7698', 'accs sd 0.0159', 'loss 0.7451', 'loss sd 0.1152')\n",
      "('WORST VALID: acc 0.9374', 'accs sd 0.0136', 'loss 0.1792', 'loss sd 0.0245')\n",
      "WORST VALID DOMAINS: [0, 7, 3, 8, 1, 0, 1, 1, 0, 0]\n",
      "('WORST TEST: acc 0.7238', 'accs sd 0.0266', 'loss 0.7451', 'loss sd 0.1152')\n",
      "WORST TEST DOMAINS: [2, 0, 2, 2, 2, 2, 2, 2, 2, 0]\n",
      "('MIN VALID: acc 0.9352', 'accs sd 0.0114', 'loss 0.1753', 'loss sd 0.0274')\n",
      "MIN VALID DOMAINS: [0, 0, 0, 0, 1, 0, 4, 1, 0, 0]\n",
      "('MIN TEST: acc 0.7160', 'accs sd 0.0187', 'loss 0.7188', 'loss sd 0.1237')\n",
      "MIN TEST DOMAINS: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "num_trials = 10\n",
    "\n",
    "for loss in [True, False]:\n",
    "    if loss:\n",
    "        print(\"===AVERAGE LOSS FUNCTION===\")\n",
    "    else:\n",
    "        print(\"===MAXIMUM LOSS FUNCTION===\")\n",
    "\n",
    "    for num_nodes in [1, 2, 5, 10, 15]:\n",
    "        v_accs = []\n",
    "        v_ls = []\n",
    "        t_accs = []\n",
    "        t_ls = []\n",
    "        worst_v_accs = []\n",
    "        worst_v_ls = []\n",
    "        worst_v_domains = []\n",
    "        worst_t_accs = []\n",
    "        worst_t_ls = []\n",
    "        worst_t_domains = []\n",
    "        \n",
    "        min_v_accs = []\n",
    "        worst_v_accs_ls = []\n",
    "        worst_v_acc_domains = []\n",
    "        min_t_accs = []\n",
    "        worst_t_accs_ls = []\n",
    "        worst_t_acc_domains = []\n",
    "\n",
    "        for i in range(1, num_trials+1):\n",
    "            print(\"===ITERATION %d===\" % i)\n",
    "            results = run_experiment(num_nodes, num_nodes, avg_loss=loss, training_epochs=50)\n",
    "\n",
    "            v_accs.append(results[0])\n",
    "            v_ls.append(results[1])\n",
    "            t_accs.append(results[2])\n",
    "            t_ls.append(results[3])\n",
    "            \n",
    "            worst_v_accs.append(results[4])\n",
    "            worst_v_ls.append(results[5])\n",
    "            worst_v_domains.append(results[6])\n",
    "            worst_t_accs.append(results[7])\n",
    "            worst_t_ls.append(results[8])\n",
    "            worst_t_domains.append(results[9])\n",
    "            \n",
    "            min_v_accs.append(results[10])\n",
    "            worst_v_accs_ls.append(results[11])\n",
    "            worst_v_acc_domains.append(results[12])\n",
    "            min_t_accs.append(results[13])\n",
    "            worst_t_accs_ls.append(results[14])\n",
    "            worst_t_acc_domains.append(results[15])\n",
    "\n",
    "        print(\"===FINAL RESULTS WITH NODE %d===\" % num_nodes)\n",
    "        print (\"VALID: acc %.4f\" % np.average(v_accs), \"accs sd %.4f\" % np.std(v_accs), \"loss %.4f\" % np.average(v_ls), \"loss sd %.4f\" % np.std(v_ls))\n",
    "        print (\"TEST: acc %.4f\" % np.average(t_accs), \"accs sd %.4f\" % np.std(t_accs), \"loss %.4f\" % np.average(t_ls), \"loss sd %.4f\" % np.std(t_ls))\n",
    "        \n",
    "        print (\"WORST VALID: acc %.4f\" % np.average(worst_v_accs), \"accs sd %.4f\" % np.std(worst_v_accs), \"loss %.4f\" % np.average(worst_v_ls), \"loss sd %.4f\" % np.std(worst_v_ls))\n",
    "        print (\"WORST VALID DOMAINS: \" + str(worst_v_domains))\n",
    "        print (\"WORST TEST: acc %.4f\" % np.average(worst_t_accs), \"accs sd %.4f\" % np.std(worst_t_accs), \"loss %.4f\" % np.average(worst_t_ls), \"loss sd %.4f\" % np.std(worst_t_ls))\n",
    "        print (\"WORST TEST DOMAINS: \" + str(worst_t_domains))\n",
    "        \n",
    "        print (\"MIN VALID: acc %.4f\" % np.average(min_v_accs), \"accs sd %.4f\" % np.std(min_v_accs), \"loss %.4f\" % np.average(worst_v_accs_ls), \"loss sd %.4f\" % np.std(worst_v_accs_ls))\n",
    "        print (\"MIN VALID DOMAINS: \" + str(worst_v_acc_domains))\n",
    "        print (\"MIN TEST: acc %.4f\" % np.average(min_t_accs), \"accs sd %.4f\" % np.std(min_t_accs), \"loss %.4f\" % np.average(worst_t_accs_ls), \"loss sd %.4f\" % np.std(worst_t_accs_ls))\n",
    "        print (\"MIN TEST DOMAINS: \" + str(worst_t_acc_domains))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
