{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.linalg import eigh\n",
    "import csv\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % dica - supervised domain-invariant component analysis on colored MNIST\n",
    "# %\n",
    "# % Synopsis\n",
    "# %   [V,D,X,Xt] = dica(Kx, Ky, Kt, groupIdx, lambda, epsilon, M)\n",
    "# %\n",
    "# % Description\n",
    "# %   Domain-invariant component analysis (DICA) finds a low dimensional\n",
    "# %   subspace of data points from several distributions so as to minimize \n",
    "# %   the variance among the distributions of projected data points. It also\n",
    "# %   takes into account the affinity in the output space.\n",
    "# % \n",
    "# %\n",
    "# % Inputs ([]s are optional)\n",
    "# %   (matrix) Kx         NxN kernel matrix between data points\n",
    "# %   (matrix) Ky         NxN kernel matrix between outputs\n",
    "# %   (matrix) Kt         NtxN kernel matrix between test samples and\n",
    "# %                           training samples\n",
    "# %   (vector) groupIdx   Nx1 vector of group membership of data points\n",
    "# %   (scalar) lambda     The regularization parameter (input)\n",
    "# %   (scalar) epsilon    The regularization parameter (output)\n",
    "# %   (scalar) M          The dimensionality of subspace (M < N)\n",
    "# %\n",
    "# % Outputs ([]s are optional)\n",
    "# %   (matrix) V          Nxdim matrix in which each column is the\n",
    "# %                       eigenvector\n",
    "# %   (matrix) D          MxM diagonal matrix in which the diagonal elements\n",
    "# %                       are eigenvalues associated with the eigenvectors in\n",
    "# %                       the matrix V\n",
    "# %   (matrix) X          MxN matrix in which each column is the projection\n",
    "# %                       of original data point onto the subspace spanned by\n",
    "# %                       the eigenvectors in the matrix V\n",
    "# %   (matrix) Xt         MxNt matrix in which each column is the projection\n",
    "# %                       of test data point onto the subspace spanned by\n",
    "# %                       the eigenvectors in the matrix V\n",
    "\n",
    "# % References\n",
    "# %   K. Muandet, D.Balduzzi,and B.SchÃ¶lkopf, Domain Generalization via \n",
    "# %   Invariant Feature Representation. The 30th International Conference on \n",
    "# %   Machine Learning (ICML 2013), pages 10?18, Atlanta, Georgia.\n",
    "# %\n",
    "# % DICA Code Reference from\n",
    "# %   Krikamol Muandet <krikamol@tuebingen.mpg.de>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfilename = \"mnist_digit100_color90flipped_testpurple_022120.npz\"\n",
    "data = np.load(myfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2352)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 1000\n",
    "x_train = data['x_train'][data['train_inds']][:sample]\n",
    "y_train = data['y_train'][data['train_inds']][:sample]\n",
    "a_train = data['attr_train'][data['train_inds']][:sample]\n",
    "x_test = data['x_train'][data['valid_inds']][:sample]\n",
    "y_test = data['y_train'][data['valid_inds']][:sample]\n",
    "# x_test = data['x_test'][:sample]\n",
    "# y_test = data['y_test'][:sample]\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507, 2352)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_1_arr = []\n",
    "y_train_1_arr = []\n",
    "x_train_2_arr = []\n",
    "y_train_2_arr = []\n",
    "for i in range(len(x_train)):\n",
    "    if np.all(a_train[i] == [1.,0.,0.]): # study 1\n",
    "        x_train_1_arr.append(x_train[i])\n",
    "        y_train_1_arr.append(y_train[i])\n",
    "    elif np.all(a_train[i] == [0.,1.,0.]): # study 2\n",
    "        x_train_2_arr.append(x_train[i])\n",
    "        y_train_2_arr.append(y_train[i])\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "x_train_1 = np.asarray(x_train_1_arr)\n",
    "y_train_1 = np.asarray(y_train_1_arr)\n",
    "x_train_2 = np.asarray(x_train_2_arr)\n",
    "y_train_2 = np.asarray(y_train_2_arr)\n",
    "x_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variance_x():\n",
    "    variance_sum = 0\n",
    "    for j in range(len(x_train[0])):\n",
    "        variance_sum += np.var(x_train[:,j])\n",
    "#     for j in range(len(x_train_2[0])):\n",
    "#         variance_sum += np.var(x_train_2[:,j])\n",
    "\n",
    "    return 1.0 * variance_sum / (len(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbda = 0.1\n",
    "eps = 0.001\n",
    "sigma_x = 5.0 # get_variance_x()\n",
    "M = 600\n",
    "sigma_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# define kernels\n",
    "\n",
    "def g_kernel_x(x_p, x_q): # x_p, x_q are images (encoded as 3*28*28 vectors) in i'th domain\n",
    "    dist = np.linalg.norm(x_p-x_q)**2\n",
    "#     print(dist)\n",
    "    power = -1.0/(2.0*(sigma_x**2)) * dist\n",
    "#     print(power)\n",
    "    return math.exp(power)\n",
    "\n",
    "def g_kernel_y(a, b):\n",
    "    if np.all(a == b):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "x_p = np.asarray([1]*28 + [1]*(3*28-1)*28)\n",
    "x_q = np.ones(3*28*28)\n",
    "print(g_kernel_y(x_p, x_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create groupIdx\n",
    "study_1s = np.asarray([1]*len(x_train_1))\n",
    "study_2s = np.asarray([2]*len(x_train_2))\n",
    "groupIdx = np.concatenate((study_1s, study_2s), axis=None)\n",
    "# groupIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(x_train)\n",
    "s_1 = len(x_train_1)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create k_x\n",
    "\n",
    "k_x = np.zeros((n, n))\n",
    "k_x.shape\n",
    "\n",
    "for i in range(n):\n",
    "    if i < s_1:\n",
    "        x_p = x_train_1[i]\n",
    "    else:\n",
    "        x_p = x_train_2[i-s_1]\n",
    "        \n",
    "    for j in range(n):\n",
    "        if j < s_1:\n",
    "            x_q = x_train_1[j]\n",
    "        else:\n",
    "            x_q = x_train_2[j-s_1]\n",
    "        k_x[i][j] = g_kernel_x(x_p, x_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create k_y\n",
    "\n",
    "k_y = np.zeros((n, n))\n",
    "k_y.shape\n",
    "\n",
    "for i in range(n):\n",
    "    if i < s_1:\n",
    "        y_p = y_train_1[i]\n",
    "    else:\n",
    "        y_p = y_train_2[i-s_1]\n",
    "        \n",
    "    for j in range(n):\n",
    "        if j < s_1:\n",
    "            y_q = y_train_1[j]\n",
    "        else:\n",
    "            y_q = y_train_2[j-s_1]\n",
    "        k_y[i][j] = g_kernel_y(y_p, y_q)\n",
    "# k_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create k_t\n",
    "\n",
    "n_t = len(x_test)\n",
    "k_t = np.zeros((n_t, n))\n",
    "k_t.shape\n",
    "\n",
    "for i in range(n_t):\n",
    "    x_pt = x_test[i]\n",
    "#     print(x_pt)\n",
    "        \n",
    "    for j in range(n):\n",
    "        if j < s_1:\n",
    "            x_q = x_train_1[j]\n",
    "        else:\n",
    "            x_q = x_train_2[j-s_1]\n",
    "        k_t[i][j] = g_kernel_x(x_pt, x_q)\n",
    "# np.all(k_t == np.zeros((n_t, n)))\n",
    "# print(k_t[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"training SVM on kernel x...\")\n",
    "# X_train = k_x\n",
    "# X_test = k_t\n",
    "# print(\"scaling data...\")\n",
    "# scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "# X_train = scaling.transform(X_train)\n",
    "# X_test = scaling.transform(X_test)\n",
    "\n",
    "# y_train_labels = y_train[:,0]\n",
    "# y_test_labels = y_test[:,0]\n",
    "# svclassifier = SVC(kernel='linear')\n",
    "# svclassifier.fit(X_train, y_train_labels)\n",
    "\n",
    "# print(\"evaluating SVM on kernel x...\")\n",
    "# y_pred = svclassifier.predict(X_test)\n",
    "# print(confusion_matrix(y_test_labels,y_pred))\n",
    "# print(classification_report(y_test_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"training SVM on regular X...\")\n",
    "# X_train = x_train\n",
    "# X_test = x_test\n",
    "# print(\"scaling data...\")\n",
    "# scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "# X_train = scaling.transform(X_train)\n",
    "# X_test = scaling.transform(X_test)\n",
    "\n",
    "# y_train_labels = y_train[:,0]\n",
    "# y_test_labels = y_test[:,0]\n",
    "# svclassifier = SVC(kernel='linear')\n",
    "# svclassifier.fit(X_train, y_train_labels)\n",
    "\n",
    "# print(\"evaluating SVM on regular x...\")\n",
    "# y_pred = svclassifier.predict(X_test)\n",
    "# print(confusion_matrix(y_test_labels,y_pred))\n",
    "# print(classification_report(y_test_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dica(Kx, Ky, Kt, groupIdx, lmbda, eps, M):\n",
    "    N = len(Kx[0])\n",
    "    Nt = len(Kt[0])\n",
    "    uniqueGroupIdx = np.unique(groupIdx)\n",
    "    G = len(uniqueGroupIdx)\n",
    "    NG = [s_1, n-s_1]\n",
    "\n",
    "\n",
    "    H = 1.0*np.identity(N)-1.0*np.ones(N)/N\n",
    "\n",
    "    L = np.zeros((N, N))\n",
    "    \n",
    "\n",
    "    for i in range(0, N):\n",
    "        for j in range(0,N):\n",
    "            if groupIdx[i] == groupIdx[j]:\n",
    "                groupSize = NG[groupIdx[i]-1]\n",
    "                L[i][j] = 1/(G*groupSize*groupSize) - 1/(G*G*groupSize*groupSize)\n",
    "            else: \n",
    "                groupSize_i = NG[groupIdx[i]-1]\n",
    "                groupSize_j = NG[groupIdx[j]-1]\n",
    "                L[i][j] = -1.0/(G*G*groupSize_i*groupSize_j)\n",
    "\n",
    "\n",
    "    Ky = H @ Ky @ H\n",
    "    Kx = H @ Kx @ H\n",
    "\n",
    "    B = Ky @ inv(Ky + N*eps*np.identity(N)) @ (Kx @ Kx)\n",
    "    A = inv(Kx @ L @ Kx + Kx + lmbda*np.identity(N)) @ (B)\n",
    "\n",
    "    eigenValues, eigenVectors = eigh(A)  # w is the eigenvalues and v are the eigenmatrix, increasing order\n",
    "    idx = eigenValues.argsort()[::-1] \n",
    "    w = eigenValues[idx]\n",
    "    v = eigenVectors[:,idx]\n",
    "\n",
    "    print(w)\n",
    "    V = v[:, :M]\n",
    "#     print(V)\n",
    "    D = np.diag(w[:M])\n",
    "    Evals = np.real(D)\n",
    "\n",
    "#     print(\"HULLO \" + str((Evals[0][0])))\n",
    "#     print(V[:,0])\n",
    "    for i in range(0,M):\n",
    "        V[:,i] = V[:,i]/(Evals[i,i]**0.5)\n",
    "\n",
    "#     print(V[:,-1])\n",
    "\n",
    "    X = V.T @ Kx\n",
    "\n",
    "    Ht = np.identity(Nt)-np.ones(Nt)/Nt\n",
    "    Kt = Ht @ Kt @ H\n",
    "    Xt = V.T @ Kt.T\n",
    "    return (V, D, X, Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nt = 100\n",
    "# N = 160\n",
    "# H = 1.0*np.identity(N)-1.0*np.ones(N)/N\n",
    "# Ht = np.identity(Nt)-np.ones(Nt)/Nt\n",
    "# Kt = np.zeros((Nt, N))\n",
    "# Kt.shape\n",
    "# Kt = np.dot(np.dot(Ht,Kt),H)\n",
    "# np.dot(Ht,Kt).shape\n",
    "# H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.81678168e+01  2.00230790e+01  1.33240628e+01  9.22748851e+00\n",
      "  7.14746380e+00  5.89644837e+00  4.71089563e+00  4.28544444e+00\n",
      "  3.61904975e+00  3.18282231e+00  3.00186478e+00  2.70170108e+00\n",
      "  2.54598635e+00  2.34802633e+00  2.17134107e+00  2.10443493e+00\n",
      "  1.91806012e+00  1.76963302e+00  1.67579327e+00  1.66141410e+00\n",
      "  1.59498283e+00  1.48593981e+00  1.40353964e+00  1.36618651e+00\n",
      "  1.33854191e+00  1.28711994e+00  1.25195068e+00  1.13156761e+00\n",
      "  1.09062641e+00  1.06537927e+00  1.02476159e+00  1.00602912e+00\n",
      "  9.83822311e-01  9.04543784e-01  8.97762112e-01  8.86257658e-01\n",
      "  8.67486793e-01  8.26286061e-01  8.03604620e-01  7.62169075e-01\n",
      "  7.42288143e-01  7.35203236e-01  7.12163365e-01  6.71282669e-01\n",
      "  6.63551636e-01  6.53313816e-01  6.43759973e-01  6.29091061e-01\n",
      "  6.13622984e-01  5.87890128e-01  5.78953111e-01  5.72343295e-01\n",
      "  5.59849010e-01  5.52083890e-01  5.51578839e-01  5.49396159e-01\n",
      "  5.26446886e-01  5.14336356e-01  5.07544123e-01  4.97869540e-01\n",
      "  4.97069540e-01  4.92260765e-01  4.89001793e-01  4.88321171e-01\n",
      "  4.66718132e-01  4.56246945e-01  4.53007357e-01  4.42057142e-01\n",
      "  4.33557679e-01  4.30005669e-01  4.26446042e-01  4.18432718e-01\n",
      "  4.15224843e-01  4.06686333e-01  3.94380006e-01  3.87648756e-01\n",
      "  3.86738968e-01  3.77065924e-01  3.74790605e-01  3.74513531e-01\n",
      "  3.72599287e-01  3.64634496e-01  3.52098994e-01  3.42270150e-01\n",
      "  3.36088377e-01  3.29170586e-01  3.25054783e-01  3.11184608e-01\n",
      "  3.07350054e-01  3.05952211e-01  3.03042803e-01  3.00328301e-01\n",
      "  2.97789818e-01  2.94943705e-01  2.94573774e-01  2.90465478e-01\n",
      "  2.90220147e-01  2.87970054e-01  2.81860836e-01  2.74177496e-01\n",
      "  2.69225832e-01  2.64273457e-01  2.63025646e-01  2.56967395e-01\n",
      "  2.56080414e-01  2.55816780e-01  2.53447447e-01  2.52909670e-01\n",
      "  2.51821098e-01  2.51068678e-01  2.49588249e-01  2.45680060e-01\n",
      "  2.44817738e-01  2.35037425e-01  2.31735748e-01  2.31666030e-01\n",
      "  2.26073223e-01  2.25935575e-01  2.19444852e-01  2.18779291e-01\n",
      "  2.18374215e-01  2.17036138e-01  2.12158118e-01  2.09355326e-01\n",
      "  2.09295455e-01  2.08284833e-01  2.06935215e-01  2.05037844e-01\n",
      "  2.02189430e-01  1.94549800e-01  1.89638594e-01  1.86156008e-01\n",
      "  1.85976354e-01  1.85786266e-01  1.84787406e-01  1.79964216e-01\n",
      "  1.78760340e-01  1.74915191e-01  1.71067818e-01  1.66699835e-01\n",
      "  1.65747709e-01  1.65061190e-01  1.63754354e-01  1.60079251e-01\n",
      "  1.59909931e-01  1.58616374e-01  1.56902058e-01  1.56191165e-01\n",
      "  1.54627910e-01  1.54147107e-01  1.51745721e-01  1.51149902e-01\n",
      "  1.47173786e-01  1.46332814e-01  1.42984771e-01  1.42005830e-01\n",
      "  1.41953015e-01  1.41626226e-01  1.40639782e-01  1.39133123e-01\n",
      "  1.37772828e-01  1.36991045e-01  1.35706171e-01  1.32045089e-01\n",
      "  1.31885046e-01  1.30076497e-01  1.28046769e-01  1.26777684e-01\n",
      "  1.26349463e-01  1.25660855e-01  1.23567947e-01  1.20215287e-01\n",
      "  1.19898237e-01  1.19007946e-01  1.17440364e-01  1.16855590e-01\n",
      "  1.15746799e-01  1.15592307e-01  1.14340214e-01  1.11843573e-01\n",
      "  1.10002506e-01  1.09852751e-01  1.08598942e-01  1.07770419e-01\n",
      "  1.06412447e-01  1.06252077e-01  1.02735206e-01  9.94769688e-02\n",
      "  9.92579317e-02  9.82379875e-02  9.75638411e-02  9.74246262e-02\n",
      "  9.72086920e-02  9.66768819e-02  9.53863388e-02  9.51284792e-02\n",
      "  9.46370373e-02  9.45209765e-02  9.40032038e-02  9.38977496e-02\n",
      "  9.37091546e-02  9.35930717e-02  9.35221281e-02  9.13955382e-02\n",
      "  9.05157187e-02  8.94469816e-02  8.92812729e-02  8.72890340e-02\n",
      "  8.68283459e-02  8.64178834e-02  8.51482846e-02  8.39285060e-02\n",
      "  8.36107868e-02  8.21716459e-02  8.15506227e-02  8.11780426e-02\n",
      "  8.03885392e-02  7.98184919e-02  7.92169968e-02  7.89722019e-02\n",
      "  7.86466483e-02  7.72898652e-02  7.50058165e-02  7.43225383e-02\n",
      "  7.42496715e-02  7.27484468e-02  7.07307964e-02  7.01690780e-02\n",
      "  6.99933950e-02  6.97764321e-02  6.85651383e-02  6.84376946e-02\n",
      "  6.83283349e-02  6.79361144e-02  6.76872044e-02  6.76735356e-02\n",
      "  6.69802293e-02  6.64057019e-02  6.59332105e-02  6.52388023e-02\n",
      "  6.48413551e-02  6.41537614e-02  6.23593781e-02  5.90531698e-02\n",
      "  5.90207399e-02  5.71583796e-02  5.66277826e-02  5.63385799e-02\n",
      "  5.60640574e-02  5.56541355e-02  5.46657676e-02  5.45164439e-02\n",
      "  5.44844779e-02  5.34020978e-02  5.30916724e-02  5.28980796e-02\n",
      "  5.28117382e-02  5.27329840e-02  5.23231748e-02  5.19505906e-02\n",
      "  5.14716452e-02  5.10262698e-02  5.02873104e-02  4.86448168e-02\n",
      "  4.83945990e-02  4.76773165e-02  4.75176288e-02  4.71008349e-02\n",
      "  4.70481442e-02  4.68588916e-02  4.68379405e-02  4.66484829e-02\n",
      "  4.61474716e-02  4.60439581e-02  4.50810864e-02  4.50045754e-02\n",
      "  4.49019007e-02  4.43918625e-02  4.42787398e-02  4.40485975e-02\n",
      "  4.34383218e-02  4.29572060e-02  4.28405357e-02  4.18843828e-02\n",
      "  4.11453865e-02  4.10369044e-02  3.95174450e-02  3.84909324e-02\n",
      "  3.76538419e-02  3.74483673e-02  3.71575464e-02  3.71136798e-02\n",
      "  3.67502987e-02  3.61443860e-02  3.58829211e-02  3.56703628e-02\n",
      "  3.55256873e-02  3.53087056e-02  3.53048424e-02  3.52454683e-02\n",
      "  3.49987106e-02  3.47256664e-02  3.46691002e-02  3.44968922e-02\n",
      "  3.43132589e-02  3.42995371e-02  3.40182004e-02  3.37210645e-02\n",
      "  3.31795477e-02  3.29843793e-02  3.25964648e-02  3.24297803e-02\n",
      "  3.24168700e-02  3.23384504e-02  3.17180947e-02  3.07269013e-02\n",
      "  3.04041609e-02  3.02417613e-02  3.01828934e-02  2.96855922e-02\n",
      "  2.87820165e-02  2.84209852e-02  2.81747924e-02  2.80874592e-02\n",
      "  2.80360158e-02  2.78313021e-02  2.75154173e-02  2.69517353e-02\n",
      "  2.62656800e-02  2.53711336e-02  2.52186749e-02  2.47205757e-02\n",
      "  2.43043042e-02  2.40687609e-02  2.36837199e-02  2.34390973e-02\n",
      "  2.34102881e-02  2.33590795e-02  2.31416840e-02  2.30283593e-02\n",
      "  2.28346767e-02  2.22236243e-02  2.19095865e-02  2.18564246e-02\n",
      "  2.16900095e-02  2.16776230e-02  2.13033851e-02  2.12715481e-02\n",
      "  2.12066604e-02  2.10896334e-02  2.09623190e-02  2.05819767e-02\n",
      "  2.03846005e-02  2.00996187e-02  1.98058087e-02  1.94978530e-02\n",
      "  1.92898991e-02  1.89704468e-02  1.85717460e-02  1.84053092e-02\n",
      "  1.81797876e-02  1.80476733e-02  1.80304230e-02  1.76822134e-02\n",
      "  1.69759347e-02  1.68655797e-02  1.68555865e-02  1.66922214e-02\n",
      "  1.57720445e-02  1.50440614e-02  1.48697294e-02  1.48636512e-02\n",
      "  1.45810154e-02  1.45377270e-02  1.42272760e-02  1.41608138e-02\n",
      "  1.41036224e-02  1.36602935e-02  1.36272235e-02  1.31748948e-02\n",
      "  1.30264158e-02  1.29069586e-02  1.28276068e-02  1.28178224e-02\n",
      "  1.27969648e-02  1.25317606e-02  1.24898085e-02  1.24153006e-02\n",
      "  1.23980244e-02  1.23973414e-02  1.23968841e-02  1.22298345e-02\n",
      "  1.21298564e-02  1.18498582e-02  1.15817950e-02  1.15109281e-02\n",
      "  1.14642949e-02  1.14522262e-02  1.13150739e-02  1.11281023e-02\n",
      "  1.11060298e-02  1.09493668e-02  1.06263624e-02  1.06057983e-02\n",
      "  1.05942442e-02  1.05137743e-02  1.04833603e-02  1.02044160e-02\n",
      "  9.55506078e-03  9.28859764e-03  9.12464379e-03  9.04562740e-03\n",
      "  8.66877501e-03  8.64968275e-03  8.43346176e-03  8.42211787e-03\n",
      "  8.18935113e-03  8.15076286e-03  8.09496365e-03  7.80793989e-03\n",
      "  7.76275884e-03  7.70980958e-03  7.63399824e-03  7.59606699e-03\n",
      "  7.56580092e-03  7.55343474e-03  7.25374524e-03  7.13329928e-03\n",
      "  7.01062536e-03  6.98639968e-03  6.50632400e-03  6.09775043e-03\n",
      "  5.99154730e-03  5.96647979e-03  5.70485342e-03  5.67614405e-03\n",
      "  5.60579266e-03  5.35147872e-03  5.29869945e-03  5.16577109e-03\n",
      "  4.71202093e-03  4.69507448e-03  4.68913442e-03  4.57608198e-03\n",
      "  4.56447132e-03  4.47075207e-03  4.46671687e-03  4.02916038e-03\n",
      "  4.01827319e-03  4.00063067e-03  3.94715926e-03  3.94672045e-03\n",
      "  3.89888763e-03  3.87019116e-03  3.85315919e-03  3.64423762e-03\n",
      "  3.39235708e-03  3.36905571e-03  3.33217488e-03  3.23131493e-03\n",
      "  3.03354951e-03  2.89380931e-03  2.85417392e-03  2.84203066e-03\n",
      "  2.83738526e-03  2.62888848e-03  2.60492040e-03  2.52439368e-03\n",
      "  2.48870488e-03  2.48236411e-03  2.42107430e-03  2.35864752e-03\n",
      "  2.33192465e-03  2.26733814e-03  2.23079918e-03  2.21892133e-03\n",
      "  2.11204196e-03  2.03798642e-03  1.92127226e-03  1.87647532e-03\n",
      "  1.86164753e-03  1.85634863e-03  1.84790590e-03  1.21515767e-03\n",
      "  1.20180743e-03  1.20148317e-03  1.14844110e-03  1.07942087e-03\n",
      "  9.81446841e-04  9.66448290e-04  9.40282550e-04  8.66379934e-04\n",
      "  8.28197112e-04  4.01402219e-04  3.66510647e-04  3.39936247e-04\n",
      "  3.28703813e-04  1.99795614e-04  1.74357702e-04  1.03143617e-04\n",
      "  9.01039765e-05  8.78919672e-05  2.83087277e-05  1.70905679e-05\n",
      " -3.42235375e-05 -1.34773806e-04 -1.49271927e-04 -2.21442102e-04\n",
      " -2.69079548e-04 -3.35101885e-04 -4.05699286e-04 -6.02400270e-04\n",
      " -6.77472033e-04 -7.71298648e-04 -7.88144878e-04 -8.18583284e-04\n",
      " -8.42187849e-04 -9.00566368e-04 -9.66720080e-04 -1.02394203e-03\n",
      " -1.10909448e-03 -1.14713122e-03 -1.15450824e-03 -1.17168353e-03\n",
      " -1.33365931e-03 -1.49290507e-03 -1.54564726e-03 -1.78354730e-03\n",
      " -1.85507586e-03 -1.99398069e-03 -2.23129460e-03 -2.25275101e-03\n",
      " -2.26195053e-03 -2.37121668e-03 -2.51612978e-03 -2.62805693e-03\n",
      " -2.83561940e-03 -2.94522596e-03 -2.97800602e-03 -2.99810996e-03\n",
      " -3.13532933e-03 -3.17348155e-03 -3.28937721e-03 -3.50110200e-03\n",
      " -3.50765080e-03 -3.58431083e-03 -3.87981490e-03 -4.16214178e-03\n",
      " -4.18176248e-03 -4.21366878e-03 -4.26396060e-03 -4.29471256e-03\n",
      " -4.35379573e-03 -4.44138557e-03 -4.49533581e-03 -4.89184739e-03\n",
      " -4.89381696e-03 -4.91416148e-03 -5.01674303e-03 -5.08331185e-03\n",
      " -5.16386002e-03 -5.33772539e-03 -5.36471602e-03 -5.44920867e-03\n",
      " -5.53602368e-03 -5.57882194e-03 -5.71169948e-03 -5.78508753e-03\n",
      " -5.92765988e-03 -6.02657594e-03 -6.03620166e-03 -6.18705591e-03\n",
      " -6.22352355e-03 -6.32127106e-03 -6.57818274e-03 -6.58231116e-03\n",
      " -6.77652332e-03 -6.81512667e-03 -6.91498030e-03 -7.18024605e-03\n",
      " -7.23206690e-03 -7.31742675e-03 -7.41129987e-03 -7.58401771e-03\n",
      " -7.81950564e-03 -8.24952922e-03 -8.33083183e-03 -8.60978238e-03\n",
      " -8.69525148e-03 -9.04159528e-03 -9.19842323e-03 -9.26431396e-03\n",
      " -9.40784943e-03 -9.47255091e-03 -9.59278844e-03 -9.69084018e-03\n",
      " -9.85290996e-03 -1.11415020e-02 -1.14837233e-02 -1.15661010e-02\n",
      " -1.21464318e-02 -1.24711641e-02 -1.27275655e-02 -1.27962391e-02\n",
      " -1.29413390e-02 -1.30186226e-02 -1.32443897e-02 -1.35758083e-02\n",
      " -1.36930564e-02 -1.37454157e-02 -1.37819233e-02 -1.41259930e-02\n",
      " -1.42072764e-02 -1.42119832e-02 -1.42747546e-02 -1.53358926e-02\n",
      " -1.54615361e-02 -1.56528254e-02 -1.59158598e-02 -1.59257709e-02\n",
      " -1.60840268e-02 -1.61405270e-02 -1.61452120e-02 -1.61531668e-02\n",
      " -1.62370647e-02 -1.62746639e-02 -1.63831465e-02 -1.70364332e-02\n",
      " -1.72343015e-02 -1.73539471e-02 -1.73699572e-02 -1.74582468e-02\n",
      " -1.74751517e-02 -1.76876863e-02 -1.80265249e-02 -1.81193105e-02\n",
      " -1.82997610e-02 -1.83226481e-02 -1.90497642e-02 -1.90858670e-02\n",
      " -1.93347923e-02 -1.99498614e-02 -2.02292852e-02 -2.06724070e-02\n",
      " -2.09767431e-02 -2.10726855e-02 -2.10842553e-02 -2.16821777e-02\n",
      " -2.18829769e-02 -2.20307368e-02 -2.20988718e-02 -2.24831668e-02\n",
      " -2.25577182e-02 -2.27081769e-02 -2.30267077e-02 -2.44502145e-02\n",
      " -2.44589227e-02 -2.53150857e-02 -2.56562038e-02 -2.63777048e-02\n",
      " -2.65143893e-02 -2.66925264e-02 -2.67603299e-02 -2.68926588e-02\n",
      " -2.73096904e-02 -2.77993065e-02 -2.81184765e-02 -2.84669634e-02\n",
      " -2.85163403e-02 -2.88685041e-02 -2.91891360e-02 -2.96406844e-02\n",
      " -2.96635689e-02 -2.98221641e-02 -2.98556110e-02 -3.00040401e-02\n",
      " -3.00810106e-02 -3.03377695e-02 -3.03991025e-02 -3.08512768e-02\n",
      " -3.12071847e-02 -3.13526319e-02 -3.17065797e-02 -3.20963733e-02\n",
      " -3.26809136e-02 -3.37800818e-02 -3.46499961e-02 -3.47429967e-02\n",
      " -3.51345668e-02 -3.54217155e-02 -3.54883229e-02 -3.57516672e-02\n",
      " -3.62103311e-02 -3.64547726e-02 -3.71108838e-02 -3.73584369e-02\n",
      " -3.78222745e-02 -3.80767624e-02 -3.84596018e-02 -3.87812442e-02\n",
      " -3.91886980e-02 -3.93807355e-02 -3.95042245e-02 -3.96957100e-02\n",
      " -3.97671774e-02 -3.98992428e-02 -4.01312757e-02 -4.05736955e-02\n",
      " -4.06843069e-02 -4.14785330e-02 -4.16544948e-02 -4.18121890e-02\n",
      " -4.26939406e-02 -4.28485642e-02 -4.28554977e-02 -4.32504528e-02\n",
      " -4.33277053e-02 -4.34642242e-02 -4.36657441e-02 -4.46910790e-02\n",
      " -4.47966864e-02 -4.53185469e-02 -4.53702142e-02 -4.54385377e-02\n",
      " -4.57949920e-02 -4.58660177e-02 -4.69123286e-02 -4.72761146e-02\n",
      " -4.73729308e-02 -4.74409088e-02 -4.85396884e-02 -4.86094988e-02\n",
      " -4.86470618e-02 -4.88636130e-02 -5.03578030e-02 -5.06234157e-02\n",
      " -5.07998908e-02 -5.08300382e-02 -5.09013083e-02 -5.11710582e-02\n",
      " -5.15404002e-02 -5.18351915e-02 -5.23064641e-02 -5.24537551e-02\n",
      " -5.52589135e-02 -5.52946727e-02 -5.53584005e-02 -5.60463573e-02\n",
      " -5.64424706e-02 -5.65135199e-02 -5.69585732e-02 -5.77540988e-02\n",
      " -5.86255631e-02 -5.86493791e-02 -5.89783279e-02 -5.91912154e-02\n",
      " -6.07703918e-02 -6.08016044e-02 -6.18230946e-02 -6.20805134e-02\n",
      " -6.23019210e-02 -6.23529586e-02 -6.30885733e-02 -6.32349918e-02\n",
      " -6.33658117e-02 -6.38875157e-02 -6.45195578e-02 -6.49531343e-02\n",
      " -6.54986443e-02 -6.58986623e-02 -6.64851314e-02 -6.87111708e-02\n",
      " -6.98664676e-02 -7.03778247e-02 -7.22503727e-02 -7.29686486e-02\n",
      " -7.35110685e-02 -7.46969736e-02 -7.49949204e-02 -7.54701882e-02\n",
      " -7.56665835e-02 -7.63611492e-02 -7.65629080e-02 -7.68225814e-02\n",
      " -7.71277170e-02 -7.71750376e-02 -7.84056602e-02 -7.88588143e-02\n",
      " -8.02572751e-02 -8.21442818e-02 -8.22628042e-02 -8.33470258e-02\n",
      " -8.35876475e-02 -8.51405877e-02 -8.89438801e-02 -8.98495363e-02\n",
      " -9.01453124e-02 -9.07248301e-02 -9.18392737e-02 -9.22124883e-02\n",
      " -9.42218611e-02 -9.51909707e-02 -9.52027901e-02 -9.59899595e-02\n",
      " -9.62753736e-02 -9.71156682e-02 -9.80951988e-02 -9.81054947e-02\n",
      " -9.83351536e-02 -9.86599775e-02 -1.01403334e-01 -1.02457650e-01\n",
      " -1.03300772e-01 -1.03654362e-01 -1.03910018e-01 -1.05102140e-01\n",
      " -1.06458369e-01 -1.08428534e-01 -1.08506270e-01 -1.10101711e-01\n",
      " -1.13386133e-01 -1.14273848e-01 -1.15581977e-01 -1.16074064e-01\n",
      " -1.16077118e-01 -1.17059362e-01 -1.17423689e-01 -1.17903860e-01\n",
      " -1.19604655e-01 -1.20429033e-01 -1.24153172e-01 -1.25413567e-01\n",
      " -1.25785226e-01 -1.26826656e-01 -1.28566311e-01 -1.28586753e-01\n",
      " -1.31758231e-01 -1.31784575e-01 -1.36470262e-01 -1.37573828e-01\n",
      " -1.37598052e-01 -1.40677964e-01 -1.41255257e-01 -1.42207058e-01\n",
      " -1.42643296e-01 -1.44955790e-01 -1.45165728e-01 -1.45401403e-01\n",
      " -1.47313962e-01 -1.47326799e-01 -1.47620356e-01 -1.47781673e-01\n",
      " -1.50374200e-01 -1.51149967e-01 -1.52418002e-01 -1.53315878e-01\n",
      " -1.53387851e-01 -1.55553550e-01 -1.61705935e-01 -1.61864602e-01\n",
      " -1.67101227e-01 -1.68118088e-01 -1.69116182e-01 -1.69723196e-01\n",
      " -1.70363936e-01 -1.70472914e-01 -1.70517496e-01 -1.73928260e-01\n",
      " -1.74130592e-01 -1.76649422e-01 -1.77358918e-01 -1.79072029e-01\n",
      " -1.81832926e-01 -1.84044510e-01 -1.84238187e-01 -1.86588327e-01\n",
      " -1.88744483e-01 -1.90675320e-01 -1.92933694e-01 -1.93132160e-01\n",
      " -1.93970908e-01 -1.94430519e-01 -1.95341056e-01 -1.99775366e-01\n",
      " -2.02820135e-01 -2.03458655e-01 -2.07059417e-01 -2.08447023e-01\n",
      " -2.15153328e-01 -2.15209878e-01 -2.17635196e-01 -2.26689583e-01\n",
      " -2.41671137e-01 -2.42818302e-01 -2.43683050e-01 -2.46547602e-01\n",
      " -2.48221161e-01 -2.48753092e-01 -2.50624555e-01 -2.51500159e-01\n",
      " -2.53014120e-01 -2.56367760e-01 -2.56524544e-01 -2.59607309e-01\n",
      " -2.61982202e-01 -2.66788915e-01 -2.76441639e-01 -2.81362721e-01\n",
      " -2.86911574e-01 -3.01176493e-01 -3.01335313e-01 -3.03587163e-01\n",
      " -3.05749785e-01 -3.13042384e-01 -3.29081810e-01 -3.29522817e-01\n",
      " -3.30901892e-01 -3.38630761e-01 -3.52787942e-01 -3.56685285e-01\n",
      " -3.61259012e-01 -3.65074041e-01 -3.69527957e-01 -3.69568748e-01\n",
      " -3.87577548e-01 -3.97157517e-01 -4.03641410e-01 -4.07773203e-01\n",
      " -4.21115582e-01 -4.27596514e-01 -4.33876719e-01 -4.45185844e-01\n",
      " -4.46796134e-01 -4.49641561e-01 -4.59945423e-01 -4.60393808e-01\n",
      " -4.63667940e-01 -4.84924736e-01 -4.93736533e-01 -5.00080461e-01\n",
      " -5.02937433e-01 -5.30868436e-01 -5.39637302e-01 -5.42292245e-01\n",
      " -5.62529264e-01 -5.73298938e-01 -5.75153273e-01 -5.76408681e-01\n",
      " -5.93480767e-01 -6.00134491e-01 -6.27743315e-01 -6.55905191e-01\n",
      " -6.59428190e-01 -6.67144856e-01 -6.69463174e-01 -6.75514671e-01\n",
      " -7.13904550e-01 -7.15426131e-01 -7.17621057e-01 -7.58837303e-01\n",
      " -7.66757221e-01 -7.73198169e-01 -7.82362128e-01 -8.41673083e-01\n",
      " -8.90801029e-01 -9.01003059e-01 -9.14927503e-01 -9.45415202e-01\n",
      " -1.00414271e+00 -1.01433894e+00 -1.01540992e+00 -1.17100035e+00\n",
      " -1.20508572e+00 -1.21897744e+00 -1.23062167e+00 -1.24706890e+00\n",
      " -1.29377508e+00 -1.35386536e+00 -1.50502698e+00 -1.59407191e+00\n",
      " -1.63804321e+00 -1.73212397e+00 -1.84963687e+00 -1.91099263e+00\n",
      " -1.96615376e+00 -2.13883228e+00 -2.32048890e+00 -2.47148334e+00\n",
      " -2.73032764e+00 -3.16974948e+00 -3.46785483e+00 -3.85997303e+00\n",
      " -4.17191460e+00 -4.83257889e+00 -5.81050741e+00 -7.23471728e+00\n",
      " -9.09871369e+00 -1.22131835e+01 -2.21697926e+01 -7.28212496e+01]\n"
     ]
    }
   ],
   "source": [
    "# run DICA to get X and Xt\n",
    "(V, D, X, Xt) = dica(k_x, k_y, k_t, groupIdx, lmbda, eps, M=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.85084518e-03 -5.26235457e-03 -5.26907439e-03 ...  1.06623380e-11\n",
      "   1.48621319e-11  5.95872663e-11]\n",
      " [ 9.68003609e-04 -1.75920005e-03 -1.74274654e-03 ... -1.08361915e-10\n",
      "  -1.51729358e-10 -6.08695800e-10]\n",
      " [-1.05258115e-03  1.89176795e-03  1.85958185e-03 ... -5.72273728e-11\n",
      "  -7.98493444e-11 -3.20562711e-10]\n",
      " ...\n",
      " [ 9.78868781e-04  2.10853826e-03 -3.16770441e-03 ... -9.81361082e-13\n",
      "  -3.72793925e-13  2.62203183e-12]\n",
      " [-4.23081970e-03 -9.22289981e-03  1.39691950e-02 ... -5.62278844e-11\n",
      "  -1.69522100e-11 -1.56216399e-11]\n",
      " [-1.06087925e-03 -2.31294934e-03  3.50355282e-03 ...  1.15252766e-10\n",
      "   3.55242752e-11  3.50695440e-11]]\n",
      "(400, 1000)\n"
     ]
    }
   ],
   "source": [
    "# input_file = '/Users/rachelh/Programs/rvr/dica_output.npz'\n",
    "# data = np.load(input_file)\n",
    "# V = data[\"V\"]\n",
    "# D = data[\"D\"]\n",
    "# X = data[\"X\"]\n",
    "# Xt = data[\"Xt\"]\n",
    "print(V)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling data...\n",
      "X_train.shape: (1000, 400)\n",
      "X_test.shape:(1000, 400)\n",
      "training SVM...\n",
      "Y_train.shape: (1000,)\n",
      "evaluating SVM...\n",
      "[[230 273]\n",
      " [280 217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.46      0.45       503\n",
      "           1       0.44      0.44      0.44       497\n",
      "\n",
      "    accuracy                           0.45      1000\n",
      "   macro avg       0.45      0.45      0.45      1000\n",
      "weighted avg       0.45      0.45      0.45      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train SVM on X and Xt\n",
    "small = 1000\n",
    "X_train = np.transpose(X)[:small]\n",
    "X_test = np.transpose(Xt)[:small]\n",
    "print(\"scaling data...\")\n",
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "X_train = scaling.transform(X_train)\n",
    "X_test = scaling.transform(X_test)\n",
    "print(\"X_train.shape: \" + str(X_train.shape))\n",
    "# print(X_train)\n",
    "print(\"X_test.shape:\" + str(X_test.shape))\n",
    "# print(X_test)\n",
    "\n",
    "print(\"training SVM...\")\n",
    "y_train_labels = y_train[:,0]\n",
    "print(\"Y_train.shape: \" + str(y_train_labels.shape))\n",
    "# print(y_train_labels)\n",
    "y_test_labels = y_test[:,0]\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train_labels)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# evaluate SVM\n",
    "print(\"evaluating SVM...\")\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test_labels,y_pred))\n",
    "print(classification_report(y_test_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 6000)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = 5000\n",
    "x_train.shape\n",
    "X = np.zeros((6000, 16000))\n",
    "np.transpose(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325 131]\n",
      " [132 412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       456\n",
      "           1       0.76      0.76      0.76       544\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.73      0.74      0.73      1000\n",
      "weighted avg       0.74      0.74      0.74      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train[:small], y_train_labels[:small])\n",
    "y_pred = svclassifier.predict(x_test[:small])\n",
    "print(confusion_matrix(y_test_labels[:small],y_pred))\n",
    "print(classification_report(y_test_labels[:small],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train SVM on X and Xt?\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X, y_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate SVM?\n",
    "\n",
    "y_pred = svclassifier.predict(Xt)\n",
    "print(confusion_matrix(y_test_labels,y_pred))\n",
    "print(classification_report(y_test_labels,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
